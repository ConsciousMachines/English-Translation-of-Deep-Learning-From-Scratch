

[[[00000000000000000000---26c6ff2fad7c7e7f39253adc724df20238ba4686447a74fc14408027340d7a52]]]Chapter 6

[[[00000000000000000001---eee14059eea891cecdb816ea0f5d5506bca3a06da07859da9c286fe2ed242fdd]]]learning techniques

[[[00000000000000000002---0bad9bc8c74b7d2b13c17e7ffb73e28c93124888ee00e4316c2a01bfa5765f61]]]In this chapter, we will discuss some key ideas in neural network training. The themes covered in this chapter are all important themes in neural network learning, such as optimization methods for searching for optimal weight parameters, initial values for weight parameters, and methods for setting hyperparameters. In addition, as countermeasures against overfitting, regularization methods such as weight decay and dropout will be outlined and implemented. Finally, I will briefly explain a technique called Batch Normalization, which has been used in many studies in recent years. By using the method described in this chapter, the neural network (deep learning) can be trained efficiently and the recognition accuracy can be improved. So let's move on.

[[[00000000000000000003---9f0e03522ee57a4ddd2338d569d0764d45f0775b645441fc8b5148b79a1efc51]]]parameter update

[[[00000000000000000004---97a274ae6a4c0af1c8b50a399b390b49d59c74b5e3b9c22d3d1116114c933255]]]The goal of training a neural network is to find the parameters that make the value of the loss function as small as possible. This is the problem of finding the optimal parameters, and solving such a problem is called optimization. Unfortunately, optimizing neural networks is a very difficult problem. This is because the parameter space is very complicated and it is not easy to find the optimal solution (it is not possible to solve a formula and find the minimum value in an instant). Moreover, in deep networks, the number of parameters becomes huge and things get more serious.

[[[00000000000000000005---a9162915624bd26423b68b1f210a94146a276f37fc24027fd04168b073efc523]]]So far, we've used gradients (derivatives) of parameters as clues to find the optimal parameters. Using the gradient of the parameters, we repeated the step of updating the parameters in the direction of the gradient over and over again, gradually getting closer to the optimal parameters. It's called stochastic gradient descent -- SGD for short -- and it's a simple method, but 'smarter' than scouring the parameter space. However, SGD is a simple method, and (for some problems) there are even smarter approaches than SGD. Here, we point out the shortcomings of SGD and introduce alternative optimization techniques.

[[[00000000000000000006---37b92b158195d5625e13594f1170e0336730d2e7e1b7abda4d0b6ca9ff4512e8]]]adventurer's story

[[[00000000000000000007---a3b64f1f0918ef7487475967c78030e26d664390d385becce56788cc3b5f1f6a]]]Before we get to the main story, let's start with a 'parable' analogy to our optimization situation.

[[[00000000000000000008---09f47ac043afe533d4d255fbd5e6b52170a7ccba1f04c119746ddd2e2d7020c8]]]Here is an eccentric adventurer. He continues his journey in search of deep valleys every day while traveling through vast arid regions. His goal is to reach the deepest and lowest ravine, which he calls 'The Deep Place'. That is the purpose of his travels. Moreover, he imposes two strict “constraints” on himself. One is not to look at the map, the other is to wear a blindfold. So he doesn't know where the lowest valley lies in the vastness of land. And you can't see anything outside. In such harsh conditions, how should this adventurer aim for 'deep places'? How can we proceed to find the 'deep place' efficiently?

[[[00000000000000000009---9c0419967135904717b9477972836153ceaa5a8bcd78d73ced2615e60a02c0c9]]]When searching for optimal parameters, we find ourselves in the same dark world as this adventurer. You have to search for 'deep places' in vast and complex terrain without a map, blindfolded. You can imagine that this is a very difficult problem.

[[[00000000000000000010---010bb7f587e93527c21847c90ce43453eddbe40fd52f8155bf9e58e009de7e71]]]What is important in this difficult situation is the 'slope' of the ground. Adventurers can't see their surroundings, but they know the slope of the ground where they are (the slope of the ground is transmitted through the soles of their feet). So, SGD's strategy is to go in the steepest direction where you are. If you keep repeating this, you may one day reach the 'deep place' - a brave adventurer may think so.

[[[00000000000000000011---af0d8f7ca19f089cd99f37ac1c17bb287c84ad8b82c516cb6bfc069fd07d3877]]]Now that you have experienced the difficulty of optimization problems, let's start by reviewing SGD again. As soon as possible, SGD can be written as formula (6.1).

[[[00000000000000000012---236a1ac2e17b5b02a531e02e52ef09519435532c6c77d9411ffc23680ed7f879]]]Equation (6.1)

[[[00000000000000000013---76ca5db1b341c8fa3eda173e1c593b17e696108ee3298830af01dd026b466b50]]]Here, let W be the weight parameter to be updated, and the gradient of the loss function with respect to W. represents the learning coefficient, which in practice is a predetermined value such as 0.01 or 0.001. Also, in the expression indicates that the value on the left side is updated with the value on the right side. SGD is a simple method of advancing a certain distance in the direction of the gradient, as expressed in equation (6.1). Now, I would like to implement this SGD as a Python class (I will implement it in a class named SGD for ease of use later).

[[[00000000000000000014---32f8447f3b27dc129e577b27c9805a4f9c562b14cdb08235d74c7b44e4d53866]]]Here, lr, which is an argument during initialization, represents the learning rate (learning coefficient). This learning factor is held as an instance variable. We also define a method called update(params, grads), which in SGD will be called repeatedly. The arguments params and grads are dictionary variables (as in previous neural network implementations). Params['W1'], grads['W1'], etc. store weight parameters and gradients respectively.

[[[00000000000000000015---a4c67d6b3106e3e49c2d3b2d58faae6910909ce07466618f60f2e4ff79509119]]]Using this SGD class, updating the parameters of a neural network can be done like this (the code below is pseudocode that doesn't actually work):

[[[00000000000000000016---3ec24f6d03f6cab180fee081eef491886685931e5e861bb4184af9afd702287d]]]# minibatch

[[[00000000000000000017---65e356de3140f8897ad7103bb2181dd2e510d0ba16baafe4d30b776ac5c7afe0]]]The variable name optimizer that appears here is a word that means 'a person who optimizes'. SGD has a role to play here. Updating parameters is the responsibility of the optimizer. All we have to do here is pass parameter and gradient information to the optimizer.

[[[00000000000000000018---42f7bb008422616218455e79381d0671e2a22f8b61d4da49e93c9267324cd0d3]]]By separating the implementation of the class that performs the optimization in this way, modularization of functionality becomes easier. For example, we will soon implement another optimization technique called Momentum, which will also have a common method called update(params, grads). Then you can switch SGD to Momentum by simply changing the sentence optimizer = SGD() to optimizer = Momentum().

[[[00000000000000000019---71219b30869d65b2c30de8e40a758e233043f0b0c061ab107c98a7c5ee125445]]]Many deep learning frameworks implement different optimization techniques and provide mechanisms to easily switch between them. For example, in the deep learning framework Lasagne, optimization methods are implemented together as functions in a file called updates.py (see link below). Users can choose which optimization method they want to use.

[[[00000000000000000020---c1bb4accfc5e09a92c0e013a10eac0bfc61cc96c7a1a11a88944258e38058792]]]Disadvantages of SGD

[[[00000000000000000021---f443743d8e6c509e5e0b98cae020c9ab91bc39689e093fbd106b7af36465cffb]]]SGD is simple and easy to implement, but it can be inefficient for some problems. Here, in pointing out the shortcomings of SGD, I would like to consider the problem of finding the minimum value of the following function.

[[[00000000000000000022---d2ec3c7f8a774e82339f222594b655df29bebf4356c68ceebb6bc7e22dec4ec1]]]Equation (6.2)

[[[00000000000000000023---c63d88744a90aef327c59f60fcf50b0d6a9c251d3176d3a83ea5ba8e178f6eb8]]]As shown in Figure 6-1, the function expressed by Equation (6.2) is shaped like a 'bowl' extended in the x-axis direction. In fact, the contour lines of equation (6.2) are ellipses extending along the x-axis.

[[[00000000000000000024---217fe096e8cae23a631f82607e177f7a43226b6930110335845dad0e9ede5e4e]]]
Graph of Figure 6-1 (left) and its contour line (right)


[[[00000000000000000025---7fd14ce1c83a8b49e651eda0255868664d05fee1d5c402b04d67a7d3970eee3a]]]Now let's look at the gradient of the function expressed by equation (6.2). A graphical representation of the gradient is shown in Figure 6-2. This gradient is characterized by being large along the y-axis and small along the x-axis. In other words, the y-axis is steep, but the x-axis is gradual. Also note that the location of the minimum value in equation (6.2) is (x, y) = (0, 0), but the gradient represented in Figure 6-2 is at many locations ( 0, 0) does not point.

[[[00000000000000000026---aabdfe73c95f2308412dd89e2430c3e637987dd8f4edd3427e5780161fb9f35c]]]
Gradient in Figure 6-2


[[[00000000000000000027---56b1167b013fde7ffba75d3c94a71ac218c8229d137f3d121c992172eb1158af]]]Let's apply SGD to the shape function in Figure 6-1. The search start position (initial value) starts from (x, y) = (−7.0, 2.0). The result should look like Figure 6-3.

[[[00000000000000000028---5aa8e3cce781fae0f349b930399198c9c8ad037993c546f0218ad1145ef99ca2]]]
Figure 6-3 SGD optimization update path: inefficient due to zigzag movement to minimum value (0, 0)


[[[00000000000000000029---9d7c33962ab59232cf443251bcad4feea4732b0c1840f8c88bbda3ed8b4304b4]]]SGD has a zigzag motion as shown in Figure 6-3. This is a rather inefficient route. So the downside of SGD is that if the shape of the function is not isotropic—it's a stretched function—it will take inefficient paths. So we need a smarter way than just going in the direction of the gradient like we did with SGD. Note that the root cause of SGD's inefficient search path is that the direction of the gradient points in a direction other than the true minimum.

[[[00000000000000000030---eaa2d675cb2b7e86ab71b777538182668dcec17c275f45db82cc8072d64f5229]]]In order to improve this shortcoming of SGD, we will introduce three alternatives to SGD: Momentum, AdaGrad, and Adam. A brief description of each is given, along with the formulas and Python implementation.

[[[00000000000000000031---dd86baee9822d5f4665ef285a6343d3e0626f6c412dfe6a6707c6ad39258a364]]]Momentum is a word that means 'momentum' and is related to physics. The Momentum technique is expressed in mathematical formulas as follows:

[[[00000000000000000032---296884e669c867dd8db15e1a5ffa1ea5fdff3c42a58804db7dfe8ce7c9e9120e]]]Equation (6.3)

[[[00000000000000000033---fdb97b10484d805e94924e72dedc69359032659ba13aa0208ed06b814407a8ac]]]Equation (6.4)

[[[00000000000000000034---def1cbe122fe3bbfaee59ad78cb9103e53ab4d4ed8dc51bf71ad2d166b2cdfbc]]]As with the previous SGD, W is the weight parameter to update, is the gradient of the loss function with respect to W, and is the learning factor. Here, a new variable called v appears, and this v corresponds to 'velocity' in physics. Equation (6.3) expresses the physical law that an object receives a force in the direction of the gradient, and the force adds to the object's velocity. The image of Momentum is the motion of a ball rolling on the ground, as shown in Figure 6-4.

[[[00000000000000000035---9450afe3b91071d15fdb9948d7d5b3dcb7ed1974924d56ea56e5f39ec6e408d0]]]
Figure 6-4 Image of Momentum: Ball moves like rolling on the slope of the ground


[[[00000000000000000036---7338e9b55fbb388c0e4626ec2452286aefd3a7c21e97409919b6bf2e25c14b2f]]]Also, in equation (6.3), there is a term αv, which plays the role of gradually decelerating the object when it is not subjected to any force (α is set to a value such as 0.9 ). In physics, it corresponds to ground friction and air resistance. Below is the Momentum implementation (source code is in common/optimizer.py).

[[[00000000000000000037---1c8247ed9131e31ecc2c78405c3b3b982a9d1a6a573119887ac98b497a788172]]]The instance variable v holds the velocity of the object. When v is initialized, it holds nothing, but when update() is first called, it holds data with the same structure as the parameter as a dictionary variable. The rest of the implementation is a simple implementation that just writes expressions (6.3) and (6.4).

[[[00000000000000000038---1eb9e6910e3cf5d8f85d9044ac23c76f6a37fcc5e9cfd8a15208fedd44130400]]]Now, let's use Momentum to solve the optimization problem of equation (6.2). The result should look like Figure 6-5.

[[[00000000000000000039---1bd6e1135062c36b2af4212ef2479a37965b3d57c1e80173dd0e335502507efb]]]
Figure 6-5 Momentum optimization update path


[[[00000000000000000040---3d1a6f61bd0e90a9f4eefafa414ac41288645391893e77c0ac7410c528396547]]]The update path behaves like a ball rolling in a bowl, as shown in Figure 6-5. Compared to SGD, you can see that the 'zigzag degree' is reduced. This is because although the force applied in the x-axis direction is very small, it always receives the same force, so the acceleration is constant in the same direction. Conversely, although the force received in the y-axis direction is large, the forces in the positive and negative directions are alternately received, so they cancel each other out, and the velocity in the y-axis direction is unstable. This allows us to approach the x-axis faster than in SGD, reducing the zigzag motion.

[[[00000000000000000041---d06a0a02deebe76d8614c9644e8da2b8649f30eeada547dd76da0b5609f2155a]]]In neural network training, the value of the learning coefficient—notated in mathematical formulas—is important. If the learning coefficient is too small, learning will take too long.

[[[00000000000000000042---ab5a83483579951b1aeca4107bbd7741e18fa83e2b313df7a9add0c0898a15af]]]A useful technique for this learning factor is learning rate decay. This is a method of decreasing the learning coefficient as learning progresses. It is a method of learning 'big' at first and learning 'small' gradually, and it is actually often used in neural network training.

[[[00000000000000000043---7a64a943b281a4885c5587fe73f12aa723eb943bc1a72cf5c27bf088648f74f5]]]The idea of gradually lowering the learning coefficient is equivalent to lowering the value of the learning coefficient of the 'whole' parameter all at once. AdaGrad [6] is a further development of this. AdaGrad creates “bespoke” values for “one by one” parameters.

[[[00000000000000000044---a2d3d8150e6d8eeca001613ae779daf5636d217a9453f2f8266320e2c9ea6cf3]]]AdaGrad is a method of learning while adaptively adjusting the learning coefficient for each parameter element (Ada in AdaGrad comes from Adaptive, which means 'adaptive'). Now let's formulate how AdaGrad updates.

[[[00000000000000000045---a50f4805c619a9d73a566b09ce0ae0253ee69aec0cd53d6cda67ebe7d950164f]]]Equation (6.5)

[[[00000000000000000046---e97d9ba7172639a1955941837585a03d670d7bc70e3b91eb9c10c00d460c5285]]]Equation (6.6)

[[[00000000000000000047---c991b86409b7e4a2b5301126b0ea9e1b2b273df4376fbbd766d9b4def08f9259]]]As in the previous SGD, W is the weight parameter to update, is the gradient of the loss function with respect to W, and is the learning factor. Here we have a new variable called h. This h holds the value of the gradient experienced so far as a sum of squares, as shown in Eq. (6.5) (where Eq. Then, when updating the parameters, adjust the learning scale by multiplying by . This means that the learning coefficients of the elements that moved well (updated greatly) among the parameter elements are small. In other words, it is possible to perform the attenuation of the learning coefficient, that is, the learning coefficient of the parameter that moves well, gradually decreases for each element of the parameter.

[[[00000000000000000048---8064774be2fd1fd9bbbbe4d12c299f22e24560d31798313e473f6b5f65af4f5d]]]AdaGrad records all past gradients as sums of squares. Therefore, the more advanced the learning, the smaller the update rate. In fact, if you train infinitely, the amount of updates will be 0, and nothing will be updated. There is a method called RMSProp [7] that has improved this problem. The RMSProp method does not uniformly add all past gradients, but gradually forgets the past gradients and adds so that the new gradient information is largely reflected. Technically known as an 'exponential moving average', it exponentially reduces the scale of the past slope.

[[[00000000000000000049---87ad52f0472ea1f1f22ac61dd131abe1f71bdc8167844102ae01c87df8cf2cb2]]]Now for the AdaGrad implementation. AdaGrad can be implemented like this (source code is in common/optimizer.py):

[[[00000000000000000050---e0d450f52ade5adb8c08cb18efde41046726c61aff93fa51b994b118e06c46b3]]]Note that the last line adds a small value of 1e-7. This is to prevent division by 0 if self.h[key] contains 0. Many deep learning frameworks allow this small value as a parameter, but here we use a fixed value of 1e-7.

[[[00000000000000000051---b06d2a148e393ac2005cd51b0a9784fac44e07f97770b358e0db51a1f7128737]]]Now, let's use AdaGrad to solve the optimization problem of equation (6.2). The result should look like Figure 6-6.

[[[00000000000000000052---72670f7debdfb8c595d9102f16150cd67e5cee7a85e7a6747465584349c5d1e2]]]
Figure 6-6 Optimization update path by AdaGrad


[[[00000000000000000053---33c233a9bc228b8871c196bf7a3315030479641f71da4dbc8c1ab338a07ac037]]]Looking at the results in Figure 6-6, we can see that we are effectively moving towards the minimum. Since the gradient in the y-axis direction is large, it moves a lot at first, but in proportion to that large movement, adjustments are made so that the update step becomes smaller. Therefore, the degree of update in the y-axis direction is weakened, and the zigzag movement is reduced.

[[[00000000000000000054---71fdc31732653765f352d8f9bd4bb26ef4110f43392c1beb95fcf0d1f6747a29]]]Momentum behaved according to the laws of physics like a ball rolling in a bowl. AdaGrad adaptively adjusted the update steps for each element of the parameters. So what happens when you combine the two techniques—Momentum and AdaGrad—? That is the idea upon which the method Adam [8] is based †1.

[[[00000000000000000055---1f6216826c181a6bdc11787401ecbfdf6a2768f2f8494f330b3dffc802cbd16b]]][†1] Adam's description of the method here is intuitive and not entirely correct. Please refer to the original paper for details.

[[[00000000000000000056---3cc24bbbc5429d4687edac449022ea7ca515be46114ff920df3a0cc9d1202363]]]Adam is a new technique proposed in 2015. The theory is a bit complicated, but intuitively it's a combination of Momentum and AdaGrad. By combining the advantages of the previous two methods, we can expect to search the parameter space efficiently. Another feature of Adam is that 'bias correction (bias correction)' of hyperparameters is performed. I won't go into too much detail here. See the original paper [8] for details. Also, regarding the Python implementation, it is implemented in common/optimizer.py with a class called Adam, so if you are interested, please refer to it.

[[[00000000000000000057---2a5f147c3c6bd4cad5ce32fee0b1126000d3a93a460a007117cf8fdd8b444a96]]]Now let's use Adam to solve the optimization problem of equation (6.2). The result should look like Figure 6-7.

[[[00000000000000000058---ce1b6d3544b0ad6213ecd4fdc022e1de43f1612f1c3531c9da211e68df29ec32]]]
Figure 6-7 Adam's optimization update path


[[[00000000000000000059---11888941ca6e6eae5b34da37a3df9d90e693d14a9f731e7468d740d66248b4a5]]]As shown in Figure 6-7, Adam's update process behaves like a ball rolling over a bowl. Momentum had a similar movement, but the ball swayed left and right less than Momentum. This is the benefit that comes from adaptively adjusting the learning update rate.

[[[00000000000000000060---cbb48f8f328db898094fe2407bee85bb88ddab5d6d94ca1e51a801f2ac83d640]]]Adam sets three hyperparameters. One is the learning coefficient so far (appeared as α in the paper). The latter two are coefficient β1 for the first moment and coefficient β2 for the second moment. According to the paper, standard settings are 0.9 for β1 and 0.999 for β2, and these settings seem to work well in most cases.

[[[00000000000000000061---31b2f500048c3b0873481f4c5cfef6eb38f9cd15d7e2413db8c5c0b9c3786ede]]]Which update method to use?

[[[00000000000000000062---376ccfcf86a4ee09a39a7eb4fbfbcf3c4dea92451dec8c23706d43812ea35647]]]So far we have seen four techniques for updating parameters. Here we compare the results of these four methods (the source code is in ch06/optimizer_compare_naive.py).

[[[00000000000000000063---c8f2e76bb4574dbdc71ea9d82b0863c6c82c715763e3a876fa342fdb73176835]]]
Figure 6-8 Comparing Optimization Techniques: SGD, Momentum, AdaGrad and Adam


[[[00000000000000000064---79771469fbe5a969c420562d9c98400be4c4e549ce6de19ec7f4b80b5e6d1bea]]]As shown in Figure 6-8, you can see that the update takes different paths depending on the method used. Looking at this figure alone, AdaGrad seems to be the best, but you need to be careful because the result will change depending on the problem to be solved. Also, as a matter of course, the results will change depending on the setting values of hyperparameters (learning coefficients, etc.).

[[[00000000000000000065---a6e42266084644ead487f99014acd63377f92115c652ae4ad6962199bc33a6f0]]]I have explained SGD, Momentum, AdaGrad, and Adam, but which one should I use? Unfortunately, there is no (yet) good technique for all problems. Each has its own characteristics, pros and cons.

[[[00000000000000000066---629193a3fe5c35fd01f8c40ebc2a889f03ef11150f28b3055e615a980851c090]]]Many studies still use SGD. Momentum and AdaGrad are also techniques worth trying. These days, many researchers and engineers seem to prefer Adam. In this book, we will mainly use SGD and Adam, but readers are encouraged to experiment as they see fit.

[[[00000000000000000067---387362aab4847c734fb961dc9d666463e5f5675a35ac9dbdffcb8c9fa669ea34]]]Comparison of update methods with MNIST dataset

[[[00000000000000000068---b94632c19c36095a6701bad41ab5b57e1a156200d4867b949d917829b4e6255b]]]For handwritten digit recognition, let's compare the four methods discussed so far—SGD, Momentum, AdaGrad, and Adam. Let's check how different the progress of learning is by each method. I'll show you the results soon. The result looks like Figure 6-9 (the source code is in ch06/optimizer_compare_mnist.py).

[[[00000000000000000069---a4309ed73bfba8e888ea511dabc6eff3a9daf947c53f7d9b8fda37558b3e642b]]]
Figure 6-9 Comparison of the four update methods for the MNIST dataset: horizontal axis is the number of learning iterations (iterations), vertical axis is the value of the loss function (loss)


[[[00000000000000000070---aac4b5bfed5688a7b8dcef1c1fa0de57da2cfc19addec2b618ae2838a97f70e2]]]In this experiment, we targeted a 5-layer neural network with 100 neurons in each layer. We also used ReLU as the activation function.

[[[00000000000000000071---07a2fb8ccd53e6f65e0a54e153256c374cddfa78ee73f2bf1791bad082745f88]]]Looking at the results in Figure 6-9, we can see that other methods can learn faster than SGD. The remaining three methods seem to be learned in the same way. If you look closely, AdaGrad seems to be learning a little faster. A caveat to this experiment is that the results will vary depending on the hyperparameters of the learning coefficient and the structure of the neural network (how many layers deep, etc.). However, the other three methods generally train faster than SGD, and sometimes yield better final recognition performance.

[[[00000000000000000072---ce7cc8ac9a06612414a29e0ea70a9297aa099de7b1e3c06017278a0cf88d72b2]]]initial weight

[[[00000000000000000073---3557c288f668b5a3b84085be6ee61216323fe683f99980554410f39f80f99534]]]Initial values of weights are particularly important in neural network training. In practice, the success or failure of neural network learning often depends on what initial values are set for the weights. In this section, we discuss the recommended initial weight values and experiment to confirm that the neural network actually learns quickly.

[[[00000000000000000074---88ed2b1c9fb442bd3dbfd21ff90d545de836d6a06223db0375971f5ab33d875f]]]Initialize weights to 0?

[[[00000000000000000075---add213ce6351cf37f399e2d9f44f321d2c3a995bbaecd1d44bb303957bc3394c]]]As a technique to suppress overfitting and improve generalization performance, we will introduce a method called weight decay later. Weight decay is, simply put, a method that aims to learn so that the value of the weight parameter becomes smaller. By reducing the weight value, overfitting is less likely to occur.

[[[00000000000000000076---69a3b9cf74f0e49a6b12a77a1eece60363454bed42bb6735b4772e11039a04f7]]]If you want the weights to be small, the best way to start is to start with the smallest possible initial value. In fact, until now, the initial values of the weights have been small values that are 0.01 times the value generated from a Gaussian -- a Gaussian with a standard deviation of 0.01 -- such as 0.01 * np.random.randn(10, 100). — was used.

[[[00000000000000000077---b815f38acaa3818153bdc7c411a0f17feeecad99439d45fa13c7ca34381044ad]]]If you want the weights to be small, why not set the initial weights all to 0? To answer first, starting the weights to 0 is a bad idea. In fact, if the initial value of the weight is set to 0, correct learning cannot be performed.

[[[00000000000000000078---8df9a4c9182ebcab0db94bfce78b6e1d689eeb62a3e3acd448ffd71a5edd5647]]]Why can't we start the weights at 0—or, more precisely, set the weights to a uniform value? This is because in backpropagation, all weight values are updated uniformly (in the same way). For example, in a two-layer neural network, suppose the weights in the first and second layers are 0. Then, during forward propagation, the weight in the input layer is 0, so the same value is transmitted to all neurons in the second layer. The fact that all neurons in the second layer have the same input means that all the weights in the second layer are updated in the same way during backpropagation (remember 'backpropagation of multiplication nodes'). will do). Therefore, the weights are updated with uniform values and the weights have symmetrical values (duplicate values). This defeats the purpose of having a lot of weights. To prevent this 'uniformity of weights'—more precisely, to break the symmetrical structure of the weights—we need a random starting value.

[[[00000000000000000079---3e881152f061c2ce6485fcee4bd3f3dcda6a2ae20c3819eb74ad070b84ff8e0f]]]hidden layer activation distribution

[[[00000000000000000080---df6429a2d7168672c7faa80bc4428b51a181c3155048508055b8cce893a8adc0]]]Much insight can be gained by observing the distribution of hidden layer activations†2 (the output data after the activation function). Let's do a simple experiment to see how the activation of the hidden layer changes depending on the initial weights. In this experiment, randomly generated input data is passed through a 5-layer neural network (using a sigmoid function as the activation function), and the distribution of activation data for each layer is drawn as a histogram. This experiment is based on the Stanford University class 'CS231n'[5].

[[[00000000000000000081---973f3c0d7624ddfb4bc81358d5170f5016e43a1c2d8f95806f89a7fe9b69c534]]][†2] Here, the output data after the activation function is called 'activation', but depending on the literature, the data flowing between layers is also called 'activation'.

[[[00000000000000000082---b51fa4dedeb7a53deab3724acd02231f0bc337dc7a67a9bd46721ae0c8af3417]]]The source code for our experiments can be found in ch06/weight_init_activation_histogram.py. Here is part of that code.

[[[00000000000000000083---8de20dfe0176aa170bb4a55e43d536abb9d922b6bac0d0b8c4662a76be87a73f]]]# 1000 data

[[[00000000000000000084---e18d1e0eae57e01a30a57467004c401cbfaedc9869c86a2cf781e4a9670cb270]]]# number of nodes (neurons) in each hidden layer

[[[00000000000000000085---3badb7165658bc1d462d7be4bb05dd57d5ce5d88d82e43371e8f0cd72b38b947]]]# 5 hidden layers

[[[00000000000000000086---127d551e7850d741ec5b1eb701bcc5e78e18dcc331965dc5ed4b17967a428c06]]]# store the activation result here

[[[00000000000000000087---deae499b787b24cf7a85220582a2674bac084b690cc310dbdf70713aba3ba904]]]# Sigmoid function!

[[[00000000000000000088---56dd2a777b661a9b63335dde9cf37c3ae0ab90e2bcd81ca1987b66bd900af1e8]]]Let's say we have 5 layers and each layer has 100 neurons. Then, as input data, 1,000 pieces of data are randomly generated with a Gaussian distribution and fed to a 5-layer neural network. A sigmoid function is used as the activation function, and the activation result of each layer is stored in a variable called activations. One thing to note about this code is the scale of the weights. This time, we use a Gaussian distribution with a standard deviation of 1, but the purpose of this experiment is to observe how the distribution of activation changes by changing this scale (standard deviation). Now let's plot the data for each layer stored in activations as a histogram.

[[[00000000000000000089---a7a9de70f4ed81be0bb5fca9a4603bad5996360e31b7f27e685b93a845345f10]]]# draw a histogram

[[[00000000000000000090---68b9113f8eeb06a3ab871779013a23dc347b653fd2e259762aacc820b362c686]]]Running this code gives the histogram in Figure 6-10.

[[[00000000000000000091---57f24419148dccc5b9694e3cf553b756e17e89a7aa1fac3db57ac5d1a522cdde]]]
Figure 6-10 Distribution of activations in each layer when using a Gaussian distribution with standard deviation 1 as the initial weights


[[[00000000000000000092---4898108763f03fb34d074fef5e40d1fbb5984d41969de2acfbaeeddffb8e3aaf]]]Looking at Figure 6-10, we can see that the distribution of activations in each layer is skewed toward 0 and 1. The sigmoid function we are using here is an S-curve function, but as the output of the sigmoid function approaches 0 (or approaches 1), the value of its derivative approaches 0. Therefore, in a data distribution skewed toward 0s and 1s, the gradient value in backpropagation becomes smaller and smaller and disappears. This is a problem called gradient vanishing. In layer deep learning, gradient vanishing can become an even more serious problem.

[[[00000000000000000093---34b434156adb03b36a1ce84e01e3dd3dca68ab0ad28efe2b7579f128c1bac340]]]Next, we will perform the same experiment with the standard deviation of the weights set to 0.01. In the code for the experiment, just replace the place where the weights are initialized with the following code:

[[[00000000000000000094---b3960717e8fd3e329b7c47b727481094464fba132c5544905ddf0ee2a4db78f0]]]Now let's see the results. For a Gaussian distribution with a standard deviation of 0.01, the distribution of activations in each layer is shown in Figure 6-11.

[[[00000000000000000095---32094175d962acbf732062d4055f8eb5a3e1a2c9d6775db15938985acc6f42f5]]]
Figure 6-11 Distribution of activations in each layer when using a Gaussian distribution with a standard deviation of 0.01 as the initial weights


[[[00000000000000000096---e1349ad1afb520c18a7727dd1e9341080defa5d074973bfc7b4122b13a7f59b9]]]Now we have a distribution centered around 0.5. Since there is no bias towards 0 and 1 as in the previous example, there is no vanishing gradient problem. However, biased activation poses a major problem in terms of expressiveness. This is because if multiple neurons output almost the same value, there is no point in having multiple neurons. For example, if 100 neurons output approximately the same value, it can be expressed approximately the same by 1 neuron. Therefore, activation bias becomes a problem in terms of 'restricted expressiveness'.

[[[00000000000000000097---032060c8b322a3746c349db59f1314ba1e7d798580dc0f336ad3b6f4b3a05e63]]]The distribution of activations in each layer is expected to have a moderate spread. This is because the neural network can learn efficiently by having moderately diverse data flowing through each layer. Conversely, if biased data flows, gradient vanishing or 'limitation of expressive power' may become a problem, and learning may not go well.

[[[00000000000000000098---857bee6182c3a50ec080fc926503daf6fe0a857c19e9ff83d61719a589d2cce0]]]Next, I would like to use the initial weights recommended in the paper by Xavier Glorot et al. Currently, 'Xavier's initial value' is standardly used in general deep learning frameworks. For example, in the Caffe framework, you can use the 'initial value of Xavier' by giving the argument xavier to the weight initial value setting.

[[[00000000000000000099---5fee9c176519913c6b13c6ea15b1e4115eec3cec56d09f0818d7d4be3a2394d1]]]Now, in Xavier's paper, he derived an appropriate scale of weights with the aim of coextensively distributing the activations in each layer. The conclusion that was drawn is that, when the number of nodes in the previous layer is n, use a distribution with a standard deviation of †3 (Fig. 6-12).

[[[00000000000000000100---a4b121dbe84a490d76fa3f7872b4524596037926203f614219f53946d3b01bd9]]][†3] In Xavier's paper, in addition to the number of input nodes in the previous layer, a setting value that considers the number of output nodes in the next layer is proposed. However, implementations of frameworks such as Caffe make the simplification described here by computing only from the input nodes of the previous layer.

[[[00000000000000000101---b62f18b0f35c5a30e5ba0eb777475eea26c4e7c5930decfd3384b085f40908b5]]]
Figure 6-12 Initial value of Xavier: When there are connections of n nodes from the previous layer, use distribution with standard deviation of as the initial value


[[[00000000000000000102---aaca1f97ea8025910bd1b32e2f60034e53e681bf272fbd9e767234b9ac57d1cf]]]When using 'Xavier's initial value', the larger the number of nodes in the previous layer, the smaller the scale of the weight set as the initial value of the target node. Now, let's experiment with 'Xavier initial values'. The implementation of the experimental code simply rewrites the initial weight settings as follows (the implementation here is simplified because the number of nodes is 100 in all layers).

[[[00000000000000000103---731dadb5de6ad586dc6d646a5c36bd2230f9a23b3357d6cbf601715b30a1f22c]]]# number of nodes in previous layer

[[[00000000000000000104---58ce6fab02605f3c47305ed1bc19850247ee458088233cc3f9476497ace7eb3d]]]
Figure 6-13 Distribution of activations in each layer when 'Xavier's initial value' is used as the initial weight value


[[[00000000000000000105---36a3c14c57f37b85b8776862fda1ea7251c2a764d6080b6e089273e4eeec8341]]]The result of using Xavier Initial Values is shown in Figure 6-13. Looking at the results, the higher the layers, the more distorted the shape becomes, but we can see that the distribution is more spread out than before. Since the data flowing to each layer has a moderate spread, it can be expected that efficient learning can be performed without limiting the expressive power of the sigmoid function.

[[[00000000000000000106---f84904b71570b6c8fc83771e889774296eb1493070a8aa3c367f37cf0a4af11b]]]The distribution in Figure 6-13 has a slightly distorted shape in the upper layer distribution. This somewhat distorted shape can be improved by using the tanh function (hyperbolic function) instead of the sigmoid function. In fact, using the tanh function results in a nice bell-shaped distribution. The tanh function is the same S-curve function as the sigmoid function, but while the tanh function is a symmetrical S-curve at the origin (0, 0), the sigmoid function is (x, y) = (0, 0.5) is a symmetrical S-curve. It is known that the function used for the activation function should be symmetric with respect to the origin.

[[[00000000000000000107---6878cfc6aa966f64229687764679c81492291aa7fd54fd40b196ab6252875f37]]]initial weights for ReLU

[[[00000000000000000108---3703d06ae1164bca2107e11d0abe78c0046a41afcc07b5308f4f960f90c46bb3]]]'Xavier's initial value' is a result derived on the assumption that the activation function is linear. Since the sigmoid function and tanh function are symmetrical and can be regarded as a linear function near the center, 'Xavier's initial value' is suitable. On the other hand, when using ReLU, it is recommended to use a ReLU-specific initial value. It is the initial value recommended by Kaiming He et al. For 'initial value of He', Gaussian distribution with standard deviation is used when the number of nodes in the previous layer is n. Considering that the 'initial value of Xavier' was , the negative area becomes 0 in the case of ReLU, so it can be interpreted (intuitively) that a double factor is required to make it more spread. increase.

[[[00000000000000000109---45880c0e13c0e5ddc20d62c2d47e886a1e4d226919cb0ea680f6fdb138c31878]]]Let's take a look at the activation distribution when using ReLU as the activation function. First, we show three experimental results for a Gaussian distribution with a standard deviation of 0.01 (hereinafter abbreviated as 'std=0.01'), then 'Xavier's initial value', and 'He's initial value' for ReLU. (Figure 6-14).

[[[00000000000000000110---79bad58bff007ef3ce2a5d14afaccbbcb83ea3362cff656a9e309080f4d9351f]]]
Figure 6-14 Changes in activation distribution due to initial weight values when ReLU is used as the activation function


[[[00000000000000000111---db455ad414bc1a1a513eb099822fc1cdcf6750d1bc27cbab427da677795df1fb]]]Looking at the results of the experiment, when 'std=0.01', the activation of each layer is a very small value†4. The fact that very little data flows through the neural network means that the gradient of the weights during backpropagation is similarly small. This is a serious problem, and in practice it will make little progress in learning.

[[[00000000000000000112---a08fcf28e7276d8adfb0bd76ec8798841285414747e343523681804abb4a8b75]]][†4] The average distribution of activations for each layer is 1st layer: 0.0396, 2nd layer: 0.00290, 3rd layer: 0.000197, 4th layer: 1.32e-5, 5th layer: 9.46e-7

[[[00000000000000000113---8e98c25f111c44dd74c9f8c918cd2f419da4190da9f68bdd45989f97e856d0c7]]]Next is the result of 'initial value of Xavier'. Here, the bias gradually increases as the layer gets deeper. In fact, the deeper the layers, the greater the bias in activation, and the more “vanishing gradients” become a problem during learning. On the other hand, the 'initial value of He' spreads evenly in each layer. Since the spread of the data remains uniform even with deeper layers, we can expect good values to flow during backpropagation.

[[[00000000000000000114---3b5600c248cce007f524bc6ff16fc80b80cef27c65bd63e88b4e262eeec87621]]]As a summary of the above, when using ReLU as the activation function, use 'initial value of He', and when using S-curves such as sigmoid and tanh, use 'initial value of Xavier' -- this is the current best practice. It will be.

[[[00000000000000000115---3df6f82435b12d512f4d71828eb6557904fe128a4ec2e6dba94481c368d43a7d]]]Comparison of initial weights with MNIST dataset

[[[00000000000000000116---cedee3178f0aa73e2b4447ea536eb9000e88f4d1d4b5e02cee4a8e2add761e15]]]Let's use actual data to see how different ways of giving initial weights affect neural network learning. Here we experiment with three cases -- 'std=0.01', 'initial value of Xavier', 'initial value of He' (source code is in ch06/weight_init_compare.py). I'll show you the results soon. The result should look like Figure 6-15 below.

[[[00000000000000000117---0b22e3196c5ed18dfdf6fcaf266e113ffa8dced555a087a1a9cb3dac6040d85f]]]
Fig. 6-15 Comparison by 'initial value of weight' for MNIST dataset: horizontal axis is number of learning iterations (iterations), vertical axis is value of loss function (loss)


[[[00000000000000000118---9370c47bbe993d711d4c63ad94bde64830bc95521019df49a42b74ca00da0035]]]In this experiment, we use ReLU as the activation function in a 5-layer neural network (100 neurons in each layer). As you can see from the results in Figure 6-15, learning is not possible at all when 'std=0.01'. This is because, as we observed the distribution of activations earlier, forward propagation allows small values (data concentrated at 0) to flow. As a result, the gradient obtained during backpropagation is also small, and the weights are rarely updated. Conversely, for the initial values of Xavier and He, learning is progressing smoothly. And you can see that learning progresses faster with the 'initial value of He'.

[[[00000000000000000119---3ab8ec230753a1a07b68ccceac513e6f64a3cba0b56765a23bc4137e3d4f1262]]]As we have seen above, the initial value of weights is a very important point in neural network learning. Initial weights often determine the success or failure of neural network learning. The importance of initial weights is often overlooked, but it's all about starting. I would like to conclude this section by re-emphasizing the importance of initial weights.

[[[00000000000000000120---d677187c474ed857adf1cfaa21290183b7996f5379d7b5268eb7a4d0958171c6]]]In the previous section ``6.2 Initial weights'', we observed the distribution of activations in each layer. What I learned there was that if the initial values of the weights were set appropriately, the distribution of activations in each layer would have a moderate spread, and learning would proceed smoothly. Then, how about 'forcing' the distribution of activations to have a moderate spread in each layer? In fact, a method based on such an idea is Batch Normalization [11].

[[[00000000000000000121---99294864de4419e694457118a5ad018a413d950d8a162f45ffb87890fc343a43]]]Algorithm of Batch Normalization

[[[00000000000000000122---8a7c52f7d1760e3dec8b0b2e39bbc110840bf4a328c5a224a1bfebb3f874159c]]]Batch Normalization (hereinafter abbreviated as Batch Norm) is a method proposed in 2015. Batch Norm is widely used by many researchers and engineers, even though it is still a new method. In fact, looking at the results of machine learning competitions, we see many examples of people using this Batch Norm to achieve excellent results.

[[[00000000000000000123---3b21bcc7581c69409a16e014bbb3b770de0ca8c962ca6a3c62356d61a01572b8]]]The reason why Batch Norm is attracting so much attention is because Batch Norm has the following advantages.

[[[00000000000000000124---a901f61d88f2cf431b72feb53cf1f62b82ad2053a4689585dbd3caaac1330ff8]]]Learning can progress rapidly (Learning coefficient can be increased)

[[[00000000000000000125---b293d710eb87d8bfb99a1746f24ade2b9e9c7686286d21f2786d1ff731c67330]]]Less dependent on initial values (don't be too sensitive to initial values)

[[[00000000000000000126---12e1e88d8c68a7ed9af2b90f704c48b7ae71840b8588ffe8d8b71c03abda6ff0]]]Suppress overfitting (reduce the need for Dropout etc.)

[[[00000000000000000127---ff2c9a7c11e502dd47b7ffebb76562954a02c3e56c228edddcf17ff767fad95e]]]The first advantage is very pleasing considering that deep learning takes a lot of time to train. In addition, there is no need to worry about the initial value so much, and it also has the effect of suppressing overfitting, which eliminates headaches in deep learning training.

[[[00000000000000000128---e0c6ef0522a4c93f6ad342441141bde0b84ab111684bd748b24a8ff06719e322]]]Now, the idea of the Batch Norm, as I mentioned earlier, is to adjust the distribution of activations in each layer to have a reasonable spread. For this purpose, as shown in Figure 6-16, a layer that normalizes the data distribution is inserted into the neural network as a Batch Normalization layer (hereafter referred to as the 'Batch Norm layer').

[[[00000000000000000129---e17d3cfb546becfb5cf612eead8dba8e539f6de0a7ab52704b703238d585478c]]]
Figure 6-16 Neural network example using Batch Normalization (Batch Norm layer draws background in gray)


[[[00000000000000000130---09eb0ce2e5bceb96ece492c90bef5f76569119562aef59ddcbbd15fe264a47f4]]]Batch Norm, as its name suggests, performs normalization for each mini-batch in units of training mini-batches. Specifically, the distribution of the data is normalized so that the mean is 0 and the variance is 1. Expressed as a formula, it looks like this:

[[[00000000000000000131---54226409320746b783db867f3abdd6c2d6d88f7da97fd110e2c71989d62afac2]]]Equation (6.7)

[[[00000000000000000132---cd00823cda2ddb64c66b81c34bfdc553ebf0e0e3f2911d1011cb851bc6269fdd]]]Here, we find the mean μB and the variance σB2 for a set of m input data where B = {x1, x2, …, xm} as a mini-batch. Then normalize the input data to have a mean of 0 and a variance of 1—a good distribution. Note that ε in equation (6.7) is a small value (for example, 10e-7). This is to prevent division by 0.

[[[00000000000000000133---b79190d0c746c48039e54fad3593260961f42921b3586d5994aec1f15db911d6]]]What Eq. (6.7) does is simply transform the mini-batch input data {x1, x2, …, xm} into data with a mean of 0 and a variance of 1. By inserting this processing before (or after) the activation function†5, we can reduce the bias in the distribution of the data.

[[[00000000000000000134---a1cd44685699aa3cee5688ab635e3dca9c7031ac30b088570c31242dd32769dd]]][†5] Discussion (and experimentation) on whether to insert batch normalization before or after the activation function is done in [11] and [12], among others.

[[[00000000000000000135---61f76c03a981c6d7e82a2403203d6a9bf490601829c5344c00f60c37c710e194]]]In addition, the Batch Norm layer transforms this normalized data with its own scale and shift. The formula is represented as:

[[[00000000000000000136---153c134f406677b28e05e3d79426b1f2703963cd4e61f13c532552c3e68adfb3]]]Equation (6.8)

[[[00000000000000000137---470be4b098dc82a2b079565bbe6a2fef10a91a1626a4e2bd25f7f7a825c668bc]]]where γ and β are parameters. It starts with γ=1 and β=0, and is adjusted to suitable values through learning.

[[[00000000000000000138---e4436119758913ae60e8eb87204372fd4180a01f9d1fbe38dc949d9174038beb]]]The above is the Batch Norm algorithm. This algorithm is forward propagation on the neural network. By using the calculation graph explained in Chapter 5, the Batch Norm can be expressed as shown in Figure 6-17.

[[[00000000000000000139---62cff4618921dc73d133d951dbde0e8b407e30d95ba3b31c70f6b709cb4e1e6b]]]
Figure 6-17 Computational graph of batch normalization (cited from reference [13])


[[[00000000000000000140---8a23c781c40962d47ec1b2c99c72b75accb1ecf14c6fe0336a85dae3d4be69a9]]]Deriving the backpropagation of the Batch Norm is somewhat complicated, so we will omit the explanation here, but if we consider using a computational graph like Figure 6-17, the backpropagation of the Batch Norm can also be derived relatively easily. I guess. Frederik Kratzert's blog 'Understanding the backward pass through Batch Normalization Layer' [13] provides a detailed explanation. If you are interested, please refer to it.

[[[00000000000000000141---eddf6404a3514b42a4ad3db93ab19264b7463875c265c632fa5b28489114f42d]]]Batch normalization evaluation

[[[00000000000000000142---a0afa7b3925b26684b21ebfc07c18372fe4026f036d481d964cbd638d3574f8d]]]Let's experiment with the Batch Norm layer. First, let's use the MNIST dataset to see how the learning progresses with and without the Batch Norm layer (source code: ch06/batch_norm_test.py). The result should look like Figure 6-18.

[[[00000000000000000143---03fffff64e913acfd88c1da0c539f340f4f9d0d47bbf7da1730aaf2001627a3b]]]
Figure 6-18 Effect of Batch Norm: Batch Norm speeds up learning progress


[[[00000000000000000144---002dfc38b58b27cd939f5d5bd3ad1f002f2d3924416ab10bfb969ef1a00fd881]]]As the results in Figure 6-18 show, the Batch Norm makes learning progress faster. Then let's give different initial scales and see how the learning progresses. Figure 6-19 is a graph of learning progress when the standard deviation of the initial weight value is changed to various values.

[[[00000000000000000145---1d9b30adb11324f79a29e62eda973b168ffdfa2ae25eb1c424298a3efb0d02a5]]]
Figure 6-19 The solid line in the graph is the result when the Batch Norm is used, the dotted line is the result when the Batch Norm is not used: The title of the figure indicates the standard deviation of the initial weight values.


[[[00000000000000000146---51928bc827428363ddfe9c7b52fe064132087d7ea5af66b2632bae3c40466044]]]In almost all cases, we find that training progresses faster with the Batch Norm. In fact, without Batch Norm, we can see that learning does not progress at all unless a good initial scale is given.

[[[00000000000000000147---b998b94028c21f3906c9461b16d221b043fbef5ee7d3cf8ada1da8207263b3b9]]]As we have seen, using the Batch Norm can speed up the learning process and is robust to the initial values of the weights. means independent). Batch Norm has such nice properties that it will be useful in many situations.

[[[00000000000000000148---0aa017d4fc334ce18c4783ef0d05987a82a0432c0d373014b4e7ac7ab7b5a7c9]]]regularization

[[[00000000000000000149---632afde4c05dc6e4678b1b2662a091d1076e325e6063b0ebb546923c3fdf867a]]]Overfitting is a common problem in machine learning. Overfitting is a condition in which a model adapts too well to only the training data and does not respond well to other data not included in the training data. The goal of machine learning is generalization performance. We want a model that can correctly identify even unseen data that is not included in the training data. Although it is possible to create a complex and highly expressive model, a technique to suppress overfitting becomes important.

[[[00000000000000000150---5459b286f6491f15a570bce00827620623f870ba125eb2e20fad2e4ce3e496e4]]]overlearning

[[[00000000000000000151---ee1870269ed0de4db26825a490a52cc0b5aec2eccddbafe94bc9e0b1fac107ce]]]There are two main causes of overfitting:

[[[00000000000000000152---006630d0197e5e29445aa5e42c048a88ef20a5df8796555e2a5f8c5e1acb8ce7]]]A model with a large number of parameters and high expressiveness

[[[00000000000000000153---2cf007fcb701165161faf552ffb698db098fbd508baafd7f61ad6c2fbab2bc21]]]lack of training data

[[[00000000000000000154---2c319b04f6549c28d8dbe2b0b0060181a69e699b7b0022fb3b0d94ab30d19923]]]Here, I would like to intentionally satisfy these two requirements to cause overfitting. For this reason, we limited the training data of the MNIST dataset to only 300 instead of the original 60,000, and also increased the complexity of the network by using a 7-layer network—100 neurons in each layer and an activation function uses ReLU——.

[[[00000000000000000155---509f45c4b3f88f0303493d7fc035618c60ed258e8cc0a311dafaeceab5d33802]]]Here is an excerpt of the code for the experiment (corresponding file is ch06/overfit_weight_decay.py). First is the data loading code.

[[[00000000000000000156---0e682b6caa8eb47392cd94543e7423a4a288450be79f698efbeedfd001467f2f]]]# Reduce training data to reproduce overfitting

[[[00000000000000000157---35fa8329f729e624c48890ac25bd109c6b3b3ea9eaac298e4ebd987957bf0c21]]]Below is the code for training. Same as the previous code, but for each epoch, we calculate the recognition accuracy for all training data and all test data respectively.

[[[00000000000000000158---15d288ed4ee9a5a9497053b11da9f0443ad2c7f66a33a6cea1f4bd494cf0704f]]]# Update parameters with SGD with a learning factor of 0.01

[[[00000000000000000159---84d57882a3edf89b25af8643ff446d7dd078c15a15e6a463bfea0cbdd2142803]]]train_acc_list, test_acc_list store the recognition accuracy in epoch units — units after looking at all the training data. Now let's plot those lists (train_acc_list, test_acc_list) as a graph. The result should look like Figure 6-20 below.

[[[00000000000000000160---d6c14d679fee8fcc98397d983e75102a91857739cf39158e9c2888c0536979ed]]]
Figure 6-20 Changes in recognition accuracy for training data (train) and test data (test)


[[[00000000000000000161---8728a6581c123f16f1e15d088ddcbfa698b4e4638c961ed8cc43cc660d5f1f3c]]]The recognition accuracy measured using the training data is almost 100% after 100 epochs. However, it is far from 100% recognition accuracy on test data. Such large discrepancies in recognition accuracy are the result of too much adaptation to training data alone. From this graph, we can see that the general-purpose data (test data) that was not used during training was not handled well.

[[[00000000000000000162---965a953f3750d9e4efa290d2f455c5271e00616005489f8096ab0b5a11c7717d]]]A traditional technique for preventing overfitting is weight decay. This is an attempt to suppress overfitting by imposing a penalty for having large weights in the learning process. In the first place, overfitting often occurs when the weight parameter takes a large value.

[[[00000000000000000163---f1c66cfb7e693cc9c825715230d934e9a11ca29ba30bb7ac76a9fb3a3e9aca66]]]As a reminder, the purpose of training a neural network is to reduce the value of the loss function. Then, for example, add the squared norm of the weight (L2 norm) to the loss function. That way, you can keep the weight from increasing. Symbolically, if the weight is W, then the weight decay of the L2 norm is and we add this to the loss function. where λ is a hyperparameter that controls the strength of regularization. The higher you set λ, the stronger the penalty for taking large weights. Also, the head of is a constant for adjustment to make the result of differentiation of λW.

[[[00000000000000000164---471f671ef45a53c4bda96961f4bb8a090a4ce1e689d01cc0022bbb2139fc2b80]]]Weight decay adds to the loss function for all weights. Therefore, the weight gradient computation adds the derivative of the regularization term, λW, to the previous backpropagation result.

[[[00000000000000000165---aff38b3d7361807cbcadf92585c46ef77a64d52f72c10011bc8665955c2d0b2e]]]The L2 norm corresponds to the sum of squares for each element. Expressed mathematically, given the weights W = (w1, w2, …, wn), the L2 norm can be calculated by In addition to the L2 norm, there are also the L1 norm and the L∞ norm. The L1 norm corresponds to the sum of absolute values, that is, The L∞ norm, also known as the Max norm, corresponds to the largest absolute value of each element. Any of the L2 norm, L1 norm, and L∞ norm can be used as the regularization term. Each has its own characteristics, but here we implement only the commonly used L2 norm.

[[[00000000000000000166---0153e585c01465541c562ba5432225899d1cd2e98e9c8a39fad29d34e01ad223]]]Now let's do an experiment. Apply weight decay with λ=0.1 to the previous experiment. The result looks like Figure 6-21 below (the network with weight decay is in common/multi_layer_net.py and the experimental code is in ch06/overfit_weight_decay.py).

[[[00000000000000000167---1b931af801fa86bafea0efec396890ae087a4b75e4357c3ff889b1e9e994fc71]]]
Figure 6-21 Changes in recognition accuracy for training data (train) and test data (test) using weight decay


[[[00000000000000000168---67636f9313b06ff76bbf2dc489950c9ef5ae18d510cc6cf602cb6088b3a78aed]]]As shown in Figure 6-21, there is a 'gap' between the recognition accuracy of the training data and the recognition accuracy of the test data. . This means that overfitting is suppressed. It is also worth noting that the recognition accuracy on the training data did not reach 100% (1.0).

[[[00000000000000000169---19251c3cfcdaeea963195271a861c11b640db9a4cd1c87a7df01c60bc040cdb6]]]As a method to suppress overfitting, I explained a method called weight decay, which adds the L2 norm of the weight to the loss function. Weight decay is easy to implement and can suppress overfitting to some extent. However, as the neural network model becomes more complex, it becomes difficult to deal with weight decay alone. Therefore, a technique called Dropout [14] is often used.

[[[00000000000000000170---ce01adf5469528f4fcc933d2470ed06ef1e2e74dcf53a77592e06fd3c9d013b8]]]Dropout is a method of learning while randomly deleting neurons. Randomly select hidden layer neurons during training and delete the selected neurons. Erased neurons no longer transmit signals, as shown in Figure 6-22. During training, the neurons to be erased are randomly selected each time the data flows. Then, when testing, we pass the signal on to all neurons, but we multiply each neuron's output by the percentage it didn't erase during training.

[[[00000000000000000171---20033bb4e151a460b7d08903f0761c0786385b6a837204a7a38647d965d932af]]]
Fig. 6-22 Conceptual diagram of Dropout (quoted from Reference [14]): The left is a normal neural network, and the right is a network to which Dropout is applied. Dropout randomly selects a neuron and by erasing that neuron, stops the transmission of the signal ahead


[[[00000000000000000172---e7bcb4af9b6b017bc8bbd83c6e9e2c6355a96fc08c2209c5b8e9dece99f8d9eb]]]Next, implement Dropout. The implementation here is focused on clarity. However, if you perform appropriate calculations during training, forward propagation only needs to flow data (no need to multiply the percentage that was not erased), so in deep learning frameworks, such implementation is done. For efficient implementation, for example, Dropout implemented by Chainer will be helpful.

[[[00000000000000000173---fe8027a1953bd5fd59018f2f2072904ef70ecdcad7d31ade9bad3074f562721d]]]The point here is that for each forward propagation, we store the neurons to erase in self.mask as False. self.mask randomly generates an array of the same shape as x, and only elements whose value is greater than dropout_ratio are true. The behavior during backpropagation is the same as ReLU. In other words, the neuron that passed the signal in forward propagation passes the signal transmitted in backward propagation as it is, and the neuron that did not pass the signal in forward propagation stops the signal in backward propagation.

[[[00000000000000000174---c19a3970abf88b1198797c71f18f1d3e38ddb0c46d97c8ede7512c9e9b6758d3]]]Now, to confirm the effectiveness of Dropout, let's test it on the MNIST dataset. The source code is ch06/overfit_dropout.py. The source code uses a class called Trainer to simplify the implementation.

[[[00000000000000000175---4bade93bb8d1256926ede1e194a4f368ffa94a8097f1fe4743e4829ddcf8ffc8]]]common/trainer.py implements the Trainer class. By using this class, the Trainer class will do the training of the network that has been done so far instead. See common/trainer.py and ch06/overfit_dropout.py for details.

[[[00000000000000000176---f878c5b8154c9a24c42d9b28f2d281861aff05ea45bbc2d4f615e83f82280469]]]As for the Dropout experiment, as in the previous experiment, we used a 7-layer network (100 neurons in each layer and an activation function of ReLU). shall not be used. The result should look like Figure 6-23 below.

[[[00000000000000000177---eb9ade7867ca80858250d0f0db10dcb5024f0218a79e2991551ac6377cad10fb]]]
Figure 6-23 Left without Dropout, Right with Dropout (dropout_rate=0.15)


[[[00000000000000000178---b8c940526c72d770021737c16b61b92c37e0eed700320e5643e9b0a66d921a77]]]As shown in Figure 6-23, using Dropout narrowed the gap in recognition accuracy between training data and test data. Also, the training data no longer reaches 100% recognition accuracy. In this way, using Dropout makes it possible to suppress overfitting even in highly expressive networks.

[[[00000000000000000179---08ebd29b51c47d56df0d47427a34e19af8bd67a1182dadf432fcc7372650cf4d]]]Ensemble learning is often used in machine learning. Ensemble learning is to train multiple models individually and average the multiple outputs during inference. In the context of neural networks, let's say you have 5 networks with the same (or similar) structure, train each of them, and when testing, take the average of the 5 outputs as the answer. It is experimentally known that ensemble learning improves the recognition accuracy of neural networks by several percent.

[[[00000000000000000180---9261ead248115fd245274395f54b6ea439911a513ff99851a06ef22e3a14c5d9]]]This ensemble learning is closely related to Dropout. This is because Dropout can be interpreted as training a different model each time by randomly deleting neurons during training. Then, during inference, we average the model by multiplying the output of the neuron by the percentage that was not erased (say, 0.5). In other words, Dropout can be considered to achieve the same effect as ensemble learning (pseudo) with a single network.

[[[00000000000000000181---74f7ab47ad464866f7621ef7660eb65bb388b82f37fca4077101d6e3db7c7c6c]]]Hyperparameter validation

[[[00000000000000000182---093ea0032fc96a2ce0fefff804de485e4815cf910a702ad7c504ff87707c5a0d]]]In neural networks, there are many hyper-parameters apart from parameters such as weights and biases. The hyperparameters here are, for example, the number of neurons in each layer, batch size, learning coefficient and weight decay when updating parameters. Such hyperparameters can lead to poorly performing models unless they are set to appropriate values. Hyperparameter values are very important, but determining hyperparameters generally involves a lot of trial and error. Here we describe how to explore hyperparameter values as efficiently as possible.

[[[00000000000000000183---c23c61439852214a5c3a87f6239d45a4c59588e2e9f2ff3ad1a52fc690fd3058]]]Validation data

[[[00000000000000000184---576543250e8b0b7dcfc29cefd1b2c475b3ecf8b7fa29049ea22a7992a65d8e2a]]]The datasets we have used so far have been split into two parts, the training data and the test data. Train on training data and evaluate generalization performance on test data—that way, you can check whether you are overfitting only to the training data (whether you are overfitting or not) We were able to evaluate the degree of conversion performance.

[[[00000000000000000185---d2da4ead9f5cbf956d42c9584b2215b0155caa417c1b4a859ac0c53a700dcd2e]]]From now on, we will set the hyperparameters to various values and verify them, but the point to be noted here is that the performance of the hyperparameters should not be evaluated using test data. This is a very important but often overlooked point.

[[[00000000000000000186---4cd004b74a05cc62a1daaedcc0084823a810c59fa6ba4522bc1e81f8ba27a9c5]]]Why shouldn't we use test data to evaluate the performance of hyperparameters? This is because if you use test data to tune the hyperparameters, the hyperparameter values will overfit to the test data. In other words, you are using test data to check the 'goodness' of the hyperparameter values, so the hyperparameter values are adjusted to fit only the test data. This may result in a model with low generalization performance that cannot be applied to other data.

[[[00000000000000000187---9b9802762a0b9afbea944b2ec796dcbf7c6ea08eb28d99c423cff47b8b2ceff3]]]Therefore, when tuning hyperparameters, confirmation data specific to hyperparameters are required. Data for hyperparameter tuning is commonly referred to as validation data. Use this validation data to evaluate how good your hyperparameters are.

[[[00000000000000000188---84eab2d46bf738cf6c0ef68f01ae32430797b02236313369650150f1894865ef]]]Training data is used for learning parameters (weights and biases). Validation data are used to evaluate the performance of hyperparameters. Test data is used at the end (ideally only once) to check generalization performance.

[[[00000000000000000189---b46ec2c02fcf9cffa4b16b34c04b1b3b5a3f77f5b2bad1bc4385b3f181450fa1]]]Some datasets are pre-separated into training data, validation data, and test data. Also, some datasets are provided with only two separate training and test data sets, and some have no such separation. In that case, data isolation must be done by the user. For the MNIST dataset, the easiest way to get validation data is to first isolate about 20% of the training data as validation data. Written in code it looks like this:

[[[00000000000000000190---27d4c5968b6f8e4bcdac500664d152548c32c398981f7c084141639ae998e9c2]]]# shuffle the training data

[[[00000000000000000191---cd0908722ac23ac310f3e6aa5266f54c3e756e41188a48a0856fa3aae010bcad]]]# split validation data

[[[00000000000000000192---9ed69a51cbb0c6afa8d6b59bffc87343e7eca8ec6964b272d8cb1767e34deb10]]]Here, we shuffle the input data and teacher labels before separating the training data. This is because some data sets may have data biases (for example, the numbers '0' to '10' are ordered). The function shuffle_dataset used here uses np.random.shuffle, and its implementation is in common/util.py.

[[[00000000000000000193---bf7deadef9519230eb75bf2ad9647445a66ff25632664f3cf9d9e1279e7e16d1]]]Next, let's look at hyperparameter optimization techniques using validation data.

[[[00000000000000000194---5ee4b1dac9a66cf9a5151a88f0ee96be698869f280bf19d62a27ed758168de39]]]Hyperparameter optimization

[[[00000000000000000195---c15961fcefbad1db5ec732d0c0144c8eded59fe1c9e96a7be37b1e7c24c22fe4]]]An important point in optimizing hyperparameters is to gradually narrow down the range of “good” hyperparameter values. Gradually narrowing down the range means setting a rough range at first, randomly selecting (sampling) hyperparameters from within that range, and evaluating the recognition accuracy based on the sampled values. Then, we repeat this process multiple times, observe the results of recognition accuracy, and narrow the range of 'good values' for the hyperparameters based on the results. By doing this iteratively, you can gradually narrow the range of appropriate hyperparameters.

[[[00000000000000000196---9c5fea6059231b6b2976d350566768f3d237cf06d0496e3dce2c29f2ab694b29]]]In hyperparameter optimization of neural networks, it has been reported that random sampling search results are better than regular search such as grid search [15]. This is because among the multiple hyperparameters, each hyperparameter has a different degree of influence on the final recognition accuracy.

[[[00000000000000000197---f2e08a7188a121ba5104eca6ad7b551b2b8b9a419db7628e910f1c3cd44ca5e9]]]It is useful to specify the range of hyperparameters roughly “roughly”. To specify 'roughly' means to specify a range on a 'power of 10' scale, such as 0.001 (10-3) to 1,000 (103). (Also expressed as “to do”).

[[[00000000000000000198---d516f15a48975d2fc44cc392286107520b90f8e8c0de1656ffdf2cf9de8e5537]]]A caveat with hyperparameter optimization is that deep learning training requires a lot of time (e.g., days or weeks). Therefore, in hyperparameter exploration, it is necessary to give up on unsavory hyperparameters at an early stage. Therefore, in hyperparameter optimization, it is effective to reduce the time required for one evaluation by reducing the epoch for learning.

[[[00000000000000000199---817efbb9beedf13bf671e7f399ada92c3f3dd0a28c69392d575cf4271922842f]]]The above is hyperparameter optimization. The story so far can be summarized as follows.

[[[00000000000000000200---25613ea1ce325efa666319ef855adb547464933f11d6d17392491640ba80bbad]]]step 0

[[[00000000000000000201---34b17f9d0fd23e1d26aba2d84375e0f78efb6d65a6278ca8bba36cb999289946]]]Set hyperparameter bounds.

[[[00000000000000000202---e93fe08e7ccbc4c3536f1e40a309957727c2390e68e17ab4e1e7af83654bbc1a]]]step 1

[[[00000000000000000203---084df365ca8a4522eacae89d5b94f04d03f0eaadb50c97456d9361849ddce65b]]]Randomly sample from the set hyperparameter range.

[[[00000000000000000204---8e20d1d4524eac18dd0049c998d71cb63f6799bea0da7f697df3e314c6eb3e8f]]]step 2

[[[00000000000000000205---2edb46fa3a58f1168572088b990765ef73f40c9a26814557ba6d163c9374e315]]]Perform training using the hyperparameter values sampled in step 1, and evaluate recognition accuracy with validation data (however, epochs are set small).

[[[00000000000000000206---3201c4535a225da6767f4168a0dcc1e1993bb69c0dacf3cdf1cbbe8218953237]]]step 3

[[[00000000000000000207---cdc92c842309e975d477837b41995b1ed40ead301db84c4a143559bce6f3e2f1]]]Repeat steps 1 and 2 a certain number of times (e.g. 100 times) and narrow the range of the hyperparameters based on their recognition accuracy results.

[[[00000000000000000208---2c5f80116bdbbce9ab26e726ca22866e8500a31b315ef44913cb3b282b9968ee]]]Repeat the above steps to narrow down the range of hyperparameters, and when the range is narrowed down to some extent, select one hyperparameter value from the narrowed down range. This is one approach for hyperparameter optimization.

[[[00000000000000000209---f10818dc01da8bbf7679a6dedea99808489593698b67d67d761e7dcf3b74e0e2]]]The hyperparameter optimization approach described here is a practical one. However, this approach may feel more like the 'wisdom' of practitioners than science. A more sophisticated approach to hyperparameter optimization is Bayesian optimization. Bayesian optimization makes full use of mathematics (theory) centered on Bayes' theorem to optimize more precisely and efficiently. For details, see the paper “Practical Bayesian Optimization of Machine Learning Algorithms” [16].

[[[00000000000000000210---f8478874ad2c143f87ee24093969f1f08a3c5b8ef20ea327119e1aee3256d120]]]Implementing hyperparameter optimization

[[[00000000000000000211---d74a53c4e66dc41e11da22f1a6963b979e27b718fd6cc3250ddf7dd959ebc8d0]]]Now, I would like to perform hyperparameter optimization using the MNIST dataset. Here, we focus on the problem of searching for the learning rate and the coefficient that controls the strength of weight decay (hereafter referred to as the 'weight decay coefficient'). This problem setting and problem solving approach is based on the Stanford University class 'CS231n' [5].

[[[00000000000000000212---e5428c373acadfa932d77cef688f9c9027cb9a63df51d7ab6fb94809a19be26a]]]As mentioned earlier, hyperparameter validation is performed by randomly sampling from a log scale range such as 0.001 (10−3) to 1,000 (103). This can be written in Python as 10**np.random.uniform(-3, 3). In our experiments, we start with weight decay coefficients in the range 10-8 to 10-4 and learning coefficients in the range 10-6 to 10-2. Then the random sampling of the hyperparameters can be written as

[[[00000000000000000213---b4b81d70b65ff57ac8b56c7b43eee0799bf17b826860634a6d159d44b25de964]]]Randomly sample like this and use those values for learning. After that, we will repeat learning with various hyperparameter values multiple times and observe where the hyperparameters that seem to be reasonable exist. We omit the implementation details here and only show the results. The source code for hyperparameter optimization is in ch06/hyperparameter_optimization.py, so please refer to it accordingly.

[[[00000000000000000214---1424a5b1ed98c903ad743f0a9414f311a02c5aa5dbc571b4c3712952da222dc9]]]Now, if we conduct an experiment with the weight decay coefficient in the range of 10−8 to 10−4 and the learning coefficient in the range of 10−6 to 10−2, the results are shown in Figure 6-24 below.

[[[00000000000000000215---162e4b2930230326d028709c39778e30e8e618beccbfd9382c35cbd6952c9d02]]]
Figure 6-24 The solid line is the recognition accuracy of the validation data, and the dotted line is the recognition accuracy of the training data.


[[[00000000000000000216---61205079044807b00f919fc3d2d9c4200a96a3adf9f19f300f69e151d8f1ab85]]]In Figure 6-24, the changes in learning of the validation data are arranged in descending order of recognition accuracy. Looking at this, you can see that learning is progressing smoothly up to about 'Best-5'. So let's take a look at the hyperparameter values (learning coefficient and weight decay coefficient) up to 'Best-5'. The result looks like this:

[[[00000000000000000217---522afa2fc6a20f6108411dd84224e23e4546a05aaf68ea4290e9a367b7e4ccf8]]]Looking at these results, we can see that learning is progressing well when the learning coefficient is between 0.001 and 0.01, and the weight decay coefficient is between 10-8 and 10-6. In this way, observe the range of hyperparameters that seems to work well, and then reduce the range of values. Then, the same work is repeated in the reduced range. That way, we narrow the range of possible hyperparameters, and at some stage we pick up one final hyperparameter value.

[[[00000000000000000218---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000000219---3c21e98636eacd9b1bae9fcdfac78b8a398aad922bdc1e08c7007f476ef18dfc]]]In this chapter, we introduced some important techniques for training neural networks. Methods of updating parameters, giving initial values of weights, batch normalization, dropout, etc. are all indispensable technologies for modern neural networks. The techniques learned here are also frequently used in cutting-edge deep learning.

[[[00000000000000000220---19850c73ec605a12530fa271fcc972171b998181be314b2c4c58825fcf2e154b]]]What we learned in this chapter

[[[00000000000000000221---4f89c300163ae513f356b7e567978b26113b3d89624d66f42eea37de4bb1aa87]]]In addition to SGD, well-known methods of updating parameters include methods such as Momentum, AdaGrad, and Adam.

[[[00000000000000000222---a08f19c6be22adcab71a791147f7b93d892b718545627e69c03116e1c817f550]]]How to give initial values of weights is very important for correct learning.

[[[00000000000000000223---dd4be75a8c3015558fb4a2027274ac4cf805452d670f60fbbf1cbe26cf1429b6]]]'Initial value of Xavier', 'Initial value of He', etc. are effective as the initial value of the weight.

[[[00000000000000000224---32ce762c5696ee806c501db463ced5fe650309659acbac5197e074411691d639]]]By using batch normalization, learning can proceed quickly and is robust against initial values.

[[[00000000000000000225---682f24936223165337428185a86ebb37c657fdd872425842051a9eaee08b9c49]]]Weight decay and Dropout are known as regularization techniques for suppressing overfitting.

[[[00000000000000000226---cd0270f82a4a3c899b4fe8cbbd560527d206611939c55d40c4f92b27faa5ed8c]]]An efficient way to search for hyperparameters is to gradually narrow down the range in which good values exist.

[[[00000000000000000227---f38d5404a52e44f974500f76196c1d802178e13b6617ddbd703916329e976cb1]]]Chapter 4

[[[00000000000000000228---8b2a016745b9a6d8d52b88da26ed15e8f03f5cc04d2e5dc3d05b71130e063b97]]]Neural network training

[[[00000000000000000229---10202f4470e59b51b961848026d04ac614b40239ad70ebb300b631eafaaa7cf4]]]The topic of this chapter is neural network training. 'Learning' here means to automatically acquire the optimal weight parameter values from the training data. In this chapter, we introduce a “metric” called a loss function to enable the neural network to learn. The purpose of learning is to find the weight parameter whose value is the smallest, using this loss function as a reference. In this chapter, we will explain a method that uses the gradient of the function, called the gradient method, as a method for finding the value of the loss function that is as small as possible.

[[[00000000000000000230---f14b478c82feafdcf4d5892737ce70fa1488acd3b36be1a1a6c9477abb13ab3c]]]learn from data

[[[00000000000000000231---9f633a885481ab0e86e8e3affca3de137afb239595139d3cc81f2c32470e44a9]]]A feature of neural networks is that they can learn from data. Learning from data means that the weight parameter values can be automatically determined from the data. This is such great news! This is because if all the parameters were to be determined manually, it would be a very difficult task. For example, in the perceptron example we saw in Chapter 2, we set the parameter values manually while looking at the truth table, but the number of parameters was about three. However, actual neural networks have thousands or tens of thousands of parameters. Furthermore, deep learning with deeper layers can have hundreds of millions of parameters. Determining those parameters by hand would no longer be possible. In this chapter, we describe neural network training—how to determine parameter values from data—and implement a Python implementation for learning handwritten digits from the MNIST dataset.

[[[00000000000000000232---91b311659e37ea1e4f09153c94669f1b1922fb72161d808621cbc48207aba0ab]]]The perceptron in Chapter 2 can be automatically learned from data if the problem is linearly separable. It is known as the 'perceptron convergence theorem' that a linearly separable problem can be solved in a finite number of training iterations. However, nonlinear separation problems cannot be learned (automatically).

[[[00000000000000000233---7c2e16bc443c6ecefdd802af24fdc4e148d30905d314d38edcc0940bfa4ba697]]]data driven

[[[00000000000000000234---f33987ec8a1b54f44cfbe361cea1747e28a644e1a3a7f2f31b18ec47f061ed48]]]Data is the lifeblood of machine learning. Find answers in data, find patterns in data, tell stories in data—that's what machine learning does, and without data, nothing happens. Therefore, 'data' exists at the center of machine learning. This data-driven approach is a departure from the human-centric approach.

[[[00000000000000000235---6c6cf44846d898cca8273e9bd74fddf722c0374533642f690afcaa588d5dad40]]]Now, usually when you're trying to solve a problem—especially when you need to find some pattern—it's common for people to think one way or another to come up with an answer. People's experiences and intuitions are used as clues to advance the work through repeated trial and error, such as ``This problem seems to have this kind of regularity,'' or ``No, no, the cause may be in another place.'' increase. On the other hand, machine learning methods avoid human intervention as much as possible and try to find answers (patterns) from collected data. In addition, neural networks and deep learning have the important property of being able to keep human intervention farther than the methods used in conventional machine learning.

[[[00000000000000000236---a32aaa75c3693bcd6b6d187edeca566bf64b77eac71a051d3861377e3f8bf957]]]Now let's consider a specific problem. For example, I want to implement a program that recognizes the number '5'. Let's say the number '5' is a handwritten image as shown in Figure 4-1, and the goal is to implement a program that can distinguish between 5 and non-5. Now, this problem seems relatively simple, but what kind of algorithm can we think of?

[[[00000000000000000237---fbb676c97ab403b150e6de5fe90a4d6b2fc2ad7905d4d2c8b20f2dc13a683da6]]]
Figure 4-1 Example of handwritten number '5': Different people have different writing styles (habits)


[[[00000000000000000238---868dd2d82542955dd0a39832ba96589d0d52cb2a29042daeab1851f7782afe05]]]If you try to think and design a program that can classify '5' correctly, you will find that it is an unexpectedly difficult problem. Humans can easily recognize '5', but it would be difficult to clearly state what kind of regularity they recognized as '5'. You can also see from Figure 4-1 that different people have different quirks, and finding the rules for being a '5' can be a daunting and time-consuming task. prize.

[[[00000000000000000239---cffcb1bcd1c8ab62d3c57007dd07819948aa5310d7ed69012753ee6efd4776a6]]]Therefore, instead of 'twisting' an algorithm that recognizes '5' from scratch, we would like to effectively utilize data to solve this problem. One possible method is to extract feature values from images and use machine learning technology to learn the patterns of those feature values. The feature value here refers to a converter designed to accurately extract the essential data (important data) from the input data (input image). Image features are usually described as vectors. SIFT, SURF, and HOG are well-known features in the field of computer vision. Such features can be used to convert image data into vectors, and the converted vectors can be trained by classifiers used in machine learning, such as SVM and KNN.

[[[00000000000000000240---77567880ea66a0ce05b95fb2ab76c1c3f22be3480abcfb05bf837a4a8b46be77]]]In this machine learning approach, 'machines' find regularities in the collected data. Compared to devising an algorithm from scratch, this will solve problems more efficiently and reduce the burden on 'people'. However, it should be noted that the features used to convert the image to vector were designed by 'humans'. This is because unless you use the appropriate feature amount (or design the feature amount) according to the problem, you will not get good results. For example, in order to recognize a dog's face, it may be necessary for a person to consider a feature quantity different from the feature quantity for recognizing '5'. In other words, even with an approach based on features and machine learning, depending on the problem, it may be necessary for 'humans' to come up with appropriate feature values.

[[[00000000000000000241---ffe7efd9c8e5c5b9b1d49fe49e54558a9c2106fc463fa59456b5c4f0b20c603a]]]So far, we have described two approaches to machine learning problems. A graphical representation of these two approaches is shown in the upper part of Figure 4-2 below. In contrast, the neural network (deep learning) approach is represented by a single block without human intervention, as shown in the lower part of Figure 4-2.

[[[00000000000000000242---4d80b35d0781cc92c2d4c560815741b8c4a45bc3233f0ae42d7cc4bc50c04aa3]]]
Figure 4-2 Paradigm shift from rule-making by 'humans' to methods of letting 'machines' learn from data: Blocks without human ideas are shown in gray


[[[00000000000000000243---a1d4df336eb898969911ba70a5f800c4f0318b0b1f88f84c9237a4daaf922692]]]As shown in Figure 4-2, neural networks learn images “as is”. In the example of the second approach—features and machine learning approach—humans designed features, but neural networks allow “machines” to learn even important features contained in images. is.

[[[00000000000000000244---a83f92749a5244577f2eda8ec2470420b9dd581a80d6669d8b905d3870c9eed4]]]Deep learning is sometimes called 'end-to-end machine learning'. The term end-to-end here means 'from end to end', which means going from raw data (input) to the desired result (output).

[[[00000000000000000245---c375ba85dabcce9c5a25d53340f6b5489a45e9d0ea9fa17ae36b1b947fea7d63]]]The advantage of neural networks is that all problems can be solved in the same way. For example, regardless of the specifics of whether the problem to be solved is recognizing a '5', a 'dog', or a 'human face', a neural network can: It simply learns given data and tries to discover patterns in given problems. In other words, neural networks can be trained “end-to-end” on raw data, regardless of the problem at hand.

[[[00000000000000000246---3adfea44a1b36159b458bfb500ba8a0b73411646575582c535aa39df253c4c3b]]]training data and test data

[[[00000000000000000247---5214d401b28be44be3c85571e2d22aec6b1fbe9ff0e0948c3c87e6547eadabd6]]]In this chapter, we will explain neural network learning, but before that, we will explain some notes about data handling in machine learning.

[[[00000000000000000248---c2cd1243873e4ddb27718dc5ccb65c116d363c6475ccc313f3151e533f8e21b2]]]Machine learning problems are generally divided into training data and test data for learning and experiments. In that case, we first learn using only the training data and search for the optimal parameters. Then we use test data to evaluate the performance of the trained model. So why do we need to separate training and test data? Because what we're looking for is general-purpose capabilities of the model. In order to properly evaluate this generalization ability, we need to separate the training and test data. Training data is also called training data.

[[[00000000000000000249---9b6b2636aa43104605e029da110c666884d4f34a0f204322d4ecae9cb051d744]]]Generalization ability is the ability to deal with unseen data (data not included in training data), and acquiring this generalization ability is the ultimate goal of machine learning. For example, in the case of handwritten digit recognition problems, it might be used in a system to automatically read postal codes on postcards. In that case, handwritten digit recognition must be highly capable of recognizing characters written by “someone”. That someone is not 'a specific character of a specific person' but 'any character of any person'. Even if the training data at hand is the only one that can be successfully discriminated, it may be learning only the peculiar characters of the people included in that data.

[[[00000000000000000250---aca73ef39f7d0d31fbe44f3b94d76d0f3de7085de059c1f50de8061666dd5712]]]Therefore, if you learn and evaluate parameters with only one data set, you will not be able to perform correct evaluation. Doing so can result in what works well for one dataset, but not for another. By the way, the state of overfitting only for a certain data set is called overfitting. Avoiding overfitting is also a key issue in machine learning.

[[[00000000000000000251---bbf490bd1b57f9cdb0a6edb373d551b63c4a8296a71014081fa232d1b4889be1]]]loss function

[[[00000000000000000252---3a6ea960789254dcccd396df36fc58af21c2d0c37f2dca6bf19b17b9a872f077]]]How would you answer the question, 'How happy are you now?' A normal person's response might be to give a vague answer such as 'I'm so happy' or 'I'm not so happy'. I would be stunned if someone answered something like, 'My current happiness index is 10.23.' Because you judge your happiness numerically with only one index. If there is such a person, he/she may be guided by his or her 'happiness index' alone.

[[[00000000000000000253---a8c7c5b6d173341cff4fe978dbbfe6dce50d775166af01b72d0571e10d5ef045]]]Well, this story of 'happiness index' is a parable, but in fact, the same thing is done in neural network learning. In neural network learning, the current state is represented by a certain 'single index'. Then, using that index as a reference, we search for the optimal weight parameter. Just as the person with the 'happiness index' uses the happiness index as a clue to search for the 'optimal life', the neural network also searches for the optimal parameters based on the 'one index' as a clue. The index used in neural network learning is called a loss function. Any function can be used for this loss function, but generally the sum of squared error or the cross entropy error is used.

[[[00000000000000000254---20c41398ad325b463c17c95528fe1a26c09a5cab7b9bbe86b37d32d04832599e]]]The loss function is a measure of how 'bad' a neural network's performance is. It shows how poorly the current neural network fits the training data and how much it doesn't match the training data. Here, using 'poor performance' as an index may sound somewhat unnatural, but the value obtained by multiplying the loss function by a negative value is 'how good the performance is', that is, 'how good the performance is'. It can be interpreted as an indicator of whether the Also, since 'minimizing poor performance' and 'maximizing good performance' are the same thing, regardless of whether performance is 'bad' or 'good', It's the same thing.

[[[00000000000000000255---b8f2f87247428df123c6f4f42092ac6e4f6da4846a851d68fa44e442b9a27350]]]sum of squared error

[[[00000000000000000256---75e3a7b19535b3dc2852f4c82bf6f32c076f973460e4aadb920fdcb767282189]]]There are several functions that can be used as loss functions, but the most famous one is probably the sum of squared error. This sum-of-squares error is mathematically expressed as:

[[[00000000000000000257---780b996a3ca35d38f6d42ebb5cb4c317205072036e64d1465e30afa0d04bea92]]]Equation (4.1)

[[[00000000000000000258---cc9a459863bb232230b3d3fa32b6a3cc2208328f2cd8198b7f6e83caaf59d0af]]]where yk is the output of the neural network, tk is the training data, and k is the dimensionality of the data. For example, in the example of '3.6 Handwritten Digit Recognition', yk and tk are data consisting of the following 10 elements.

[[[00000000000000000259---fc4a954adf1c582fc4e23cc949349c7407d581816ab3d206ecc16acff1b35f07]]]The elements of this array correspond to the digits '0', '1', '2'... starting from the first index. where y, the output of the neural network, is the output of the softmax function. The output of the softmax function can be interpreted as probabilities, so the example above represents a probability of 0.1 for a 0, 0.05 for a 1, 0.6 for a 2, and so on. On the other hand, t is the training data. In this training data, the correct label is 1, and the others are 0. Here, the label '2' is 1, so the correct answer is '2'. Note that the one-hot notation is a notation in which the correct label is set to 1 and the others are set to 0.

[[[00000000000000000260---641d855f335ed127f4602bb034fee1d5feff380e93424277929a685fdaba78ea]]]Now, the sum of squared error is calculated by calculating the square of the difference between each element of the output of the neural network and the training data that is the correct answer, as expressed in formula (4.1), and then finding the sum. Now let's implement this sum of squared error in Python. This can be implemented like this:

[[[00000000000000000261---7b6474fda3e6bcb8ffdc037836e0cb39ff642d124a83cb4701110ce521d1d117]]]Here, the arguments y and t are NumPy arrays. The implementation of the contents is just an implementation of formula (4.1) as it is, so no explanation is necessary. Now, let's use this function to actually calculate.

[[[00000000000000000262---22205952fb50b178afd8b567b77fd74fcd0beeb311a1cb0bff0c4fc46b049222]]]>>> # '2' is the correct answer >>> 

[[[00000000000000000263---acf1000645bb516a118c5c57b0bf81d4ca51292961f1f6eb6651e7dd3f757560]]]
>>> >>> # Example 1: '2' is most likely (0.6) >>> 

[[[00000000000000000264---d2cb196a1918f832080fd2cc74c12c1c2040cdf9e69d78bccca92e7108146252]]]
0.097500000000000031 >>> >>> # Example 2: '7' is most likely (0.6) >>> 

[[[00000000000000000265---bb36620e0da6eed95e38368e5cf477dd51cfa9aaa742d093d68af9ba4eab39d4]]]Here are two examples. The first example is when the correct answer is '2' and the output of the neural network is '2', which is the highest. On the other hand, in the second example, the correct answer is '2', but the neural network's output is '7' which is the highest. As shown by the results of this experiment, the loss function of the first example is smaller, and the error with the training data is smaller. In other words, the sum-of-squares error indicates that the output results are better fitted to the training data in the first example.

[[[00000000000000000266---313be33e29a31ffa86262a7f3fb5b35b0674097c44d83298b4c24e4c0970dd2d]]]cross entropy error

[[[00000000000000000267---1826b66044bd6b6525adbb3a5cfa38546ed65df2e5af7bee38d480884b49753c]]]Another commonly used loss function for the sum of squares error is the cross entropy error. The cross-entropy error is given by the formula:

[[[00000000000000000268---5bf3eb35efc965e943e065944977b4f7de7816140ba8cb9eb3ed326548e54789]]]Equation (4.2)

[[[00000000000000000269---c1f26e80ad78ffed989b899b6a603378392213a1b265ac52d9f3613897fe0972]]]where log stands for the natural logarithm (loge) in base e. Let yk be the output of the neural network and tk be the correct label. Also, tk is assumed to be 1 only for the correct label index and 0 for the rest (one-hot representation). (4.2) effectively just computes the natural logarithm of the output corresponding to the correct label of 1. For example, if '2' is the index of the correct label and the corresponding neural network output is 0.6, then the cross entropy error can be calculated as −log0.6 = 0.51. Also, if the output of '2' is 0.1, then -log0.1 = 2.30. In other words, the cross-entropy error is determined by the resulting output, which is the correct label.

[[[00000000000000000270---f1205edcf82c655ff601d0d79a63cf94a5704b4cc24def7492d41601eff92eb9]]]By the way, the natural logarithm can be represented graphically as shown in Figure 4-3.

[[[00000000000000000271---a1cc9ff9db85291b7d3670a433fd2977114725cf9566d8d139d36eabe410f494]]]
Figure 4-3 Graph of natural logarithm y = logx


[[[00000000000000000272---7a934bde5c0b66a98db9913d42f4647836267707c1d023f3dfd202485cda9000]]]As shown in Figure 4-3, when x is 1, y is 0, and as x approaches 0, the value of y becomes smaller and smaller. Therefore, equation (4.2) approaches 0 as the output corresponding to the correct label increases. And when its output is 1, the cross entropy error is 0. We can also see that if the output corresponding to the correct label is small, the value of equation (4.2) will be large.

[[[00000000000000000273---cf91257405d0b7234d81bf0035d35f4b2472762b0fbb2d5ecbe8b320b901cce9]]]Now let's implement the cross entropy error.

[[[00000000000000000274---7a276cd3469e85e0de4472961f2776b8b040e2fc049537182abe76c530678abb]]]Here, the arguments y and t are NumPy arrays. In the implementation of the contents, when calculating np.log, delta, which is a minute value, is added and calculated. This is because when a calculation like np.log(0) occurs, np.log(0) becomes -inf, which represents negative infinity, and when that happens, the calculation cannot proceed any further. increase. As a preventive measure, a minute value is added to prevent negative infinity from occurring. Let's do a simple calculation using this cross_entropy_error(y, t).

[[[00000000000000000275---3eb97cc256bcb9e26e76e0a664ab2f6b76f7f5f0074efba4a3e80b47a4843baf]]]In the first example, if the correct label output is 0.6, then the cross-entropy error is approximately 0.51. Next is an example where the correct label output is as low as 0.1, but the cross-entropy error is about 2.3. These results are consistent with previous discussions.

[[[00000000000000000276---580b80d304dded922a3468856f4e3a02e547ba7d5c4c06c37c7a3da025634b5b]]]Mini-batch learning

[[[00000000000000000277---8e3f92eace8e6329d409ba076eb5b3739a19de2056080fd9b8a1cb33902c56bd]]]Machine learning problems learn using training data. Learning using the training data is more precisely finding the loss function for the training data and finding the parameters that minimize that value. Therefore, the loss function should be obtained for all training data. In other words, if there are 100 training data, the index is the sum of 100 loss functions.

[[[00000000000000000278---588c93ef80332f7b047f09269a67d0a88d02207aac6d9f1ce837f5987c296211]]]By the way, the example of the loss function that I explained earlier was considering the loss function of one data. Therefore, if we want to find the sum of the loss functions of all the training data, for example, in the case of the cross-entropy error, we can write the following equation (4.3).

[[[00000000000000000279---37bde6bbbed64c1242b7786bab1dcb43e19b0a6a47cb68fd759264f416abdf96]]]Equation (4.3)

[[[00000000000000000280---a6e7f413813876ef0c4a05298bcadb35264b749dfc1cc3a4cb33dde1f62e9d58]]]where tnk means the kth value of the nth data, where there are N data (ynk is the output of the neural network, tnk is the training data). The formula looks a little complicated, but it's just a matter of extending the formula (4.2), which expresses the loss function for one data, to N data. However, it is normalized by dividing by N at the end. By dividing by this N, you can find the 'average loss function' per piece. Such averaging always gives a uniform metric, regardless of the amount of training data. For example, even if you have 1,000 or 10,000 training data, you can find the average loss function per one.

[[[00000000000000000281---02cbd4a0d761fd2d5669688bf752f701ae6bb24a90d54293b6523bc752ddfc20]]]By the way, the MNIST dataset had 60,000 training data. Therefore, it takes a little time to calculate the sum of loss functions for all data. Also, when it comes to big data, the number of data is huge, on the order of millions or tens of millions. In that case, it is impractical to compute a loss function for all data. Therefore, we select a part of the data and use that part of the data as an 'approximation' of the whole. In neural network learning as well, only a certain number of pieces are selected from the training data—this is called a mini-batch—and learning is performed for each mini-batch. For example, randomly select 100 out of 60,000 training data and use those 100 for training. Such a learning method is called mini-batch learning.

[[[00000000000000000282---908007f0c3403d0587f46443c72c492fa52b77daf0b9ba880394636f4d9245f9]]]Let's write a code that randomly selects a specified number of data from the training data for mini-batch learning. Before that, here's the code for reading the MNIST dataset.

[[[00000000000000000283---c7187d8375f947b2e9a305c07d8955350ba21b4ed5ac6d9cabe5910d7b7a4694]]]As explained in Chapter 3, the function load_mnist is a function for loading the MNIST dataset. This function can be found in the script dataset/mnist.py provided with this book. This function loads training and test data. By specifying one_hot_label=True in the argument when loading, it can be obtained as a one-hot expression, that is, a data structure in which only the correct label is 1 and the rest are 0.

[[[00000000000000000284---e90b7cb04cf5d1368d0aec96c020aa125db3092cb8bb3c5fad1eda83d055c01c]]]Now, by loading the MNIST data above, we can see that there are 60,000 training data and the input data is 784 columns (originally 28×28) of image data. Also, the teacher data is 10 columns of data. So the shapes of x_train and t_train above are (60000, 784) and (60000, 10) respectively.

[[[00000000000000000285---97b7a7e308b5146a0b57f28a081cc42dc7cb39e85b7cfaefc6cccb586f339031]]]So how can we randomly pick 10 out of this training data? For that, you can use NumPy's np.random.choice() and write:

[[[00000000000000000286---7ce0f06d8a738b7f3ff905b3cf7952f19d39138088e60c37dfeb162eb914f006]]]By using np.random.choice(), you can randomly select any number from the specified numbers. For example, np.random.choice(60000, 10) selects 10 random numbers from 0 to less than 60000. In actual code, you can get the indices to pick out as a mini-batch as an array, as shown in the following example.

[[[00000000000000000287---d7d302207fa9d45d8c7b318fb24264fe153b786a8825422a5964a7ebc2b41cfb]]]Now all that's left to do is retrieve the mini-batch given this randomly chosen index. Use this mini-batch to compute the loss function.

[[[00000000000000000288---fd0061e6ef0f6c95480ea21ad9854906b5eaff95bae514feb1d3c3be199da018]]]To measure TV viewership, we don't look at TVs in all households, but only in selected households. For example, by measuring the audience rating of 1,000 randomly selected households in the Kanto region, it is possible to approximate the audience rating of the entire Kanto region. The 1,000-household ratings don't exactly match the overall ratings, but can be used as a rough approximation. Similar to this audience rating story, the mini-batch loss function is also measured by approximating the whole with some sample data. In other words, we substitute a small randomly-chosen collection (mini-batch) as a rough approximation of the total training data.

[[[00000000000000000289---ca6806390a16292d527e98b0ed1efd5933d1e8564d94cea668bfff8785519b0c]]][Batch version] Implementation of cross-entropy error

[[[00000000000000000290---b4551faa3d7d020a0fc89eaa314be0b10d8cb533ffc65471d0e6bb1d4024d9a8]]]So how can we implement cross-entropy error for batch data like mini-batches? This can be easily implemented by modifying the cross-entropy error we implemented earlier—it was an error for a single set of data. Here, we will implement it so that it can handle both the case where there is a single piece of data and the case where the data is collected and input as a batch.

[[[00000000000000000291---c5e53a0c903f42cb43c9c080f07e3dec83c72b3197d15a87b4bfaae2f2547863]]]where y is the neural network output and t is the training data. If the number of dimensions of y is 1, that is, if you want to obtain the cross-entropy error per data, shape the data. Then normalize by the number of batches and calculate the average cross-entropy error per sheet.

[[[00000000000000000292---c2dffdfdbedecdf84beb52ff4171812bfe8f206be93c2b05781744bfbedd9179]]]Also, when the training data are given as labels (not as one-hot representations, but as labels such as '2' and '7'), the cross-entropy error can be implemented as follows.

[[[00000000000000000293---d479126b7d9d7300aa48f59f967dc14e863a93f44afb08c72cdbaa45da7138e6]]]The implementation point is that elements with t equal to 0 in the one-hot representation also have a cross-entropy error of 0 and can be ignored in the computation. In other words, if we can get the output of the neural network for the correct label, we can calculate the cross-entropy error. Therefore, when t is a one-hot expression, the part calculated by t * np.log(y) is changed to np.log( y[np.arange(batch_size), t] when t is a label expression. ) to implement the same processing (in the explanation here, the description of 'small value 1e-7' is omitted for clarity).

[[[00000000000000000294---b92d8987c7a38804de29ac49daf4f366b3ece300798354bf3fc281a90069d869]]]For reference, here's a quick np.log( y[np.arange(batch_size), t] ). np.arange(batch_size) produces an array from 0 to batch_size-1. For example, if batch_size is 5, np.arange(batch_size) will produce a NumPy array of [0, 1, 2, 3, 4]. t stores labels like [2, 7, 0, 9, 4], so y[np.arange(batch_size), t] is the neural network output corresponding to the correct label for each data (in this example y[np.arange(batch_size), t] is [y[0,2], y[1,7], y[2,0], y[3,9] , yields a NumPy array of y[4,4]]).

[[[00000000000000000295---7387bb47d96f6c0f3dd39060d61241ea6b1fa43ec083637a50d69acf78f0efb5]]]Why set the loss function?

[[[00000000000000000296---0430549784b75bf0d7e3253a579b6f1dab0f4ce7e80eb8a682d69ddc8ff98e3a]]]Now that we've talked about the loss function, you might be wondering why we're introducing a loss function. For example, in the case of digit recognition, we want to acquire parameters that increase the recognition accuracy, so it would be troublesome to introduce a loss function. The question is whether 'recognition accuracy' should be used as an index because it is to acquire a neural network that increases accuracy.

[[[00000000000000000297---206abae58a5d2edfc4e4b9421dc7e0f6b3c425d3e085cf0ca595b4762395ffa8]]]The answer to this question can be found by looking at the role of 'derivatives' in neural network learning. Details will be explained in the next section, but in neural network training, when searching for optimal parameters (weights and biases), we look for parameters that minimize the value of the loss function. Here, in order to find the location of the smallest possible loss function, the derivative of the parameter (more precisely, the gradient) is calculated, and the value of the parameter is gradually updated based on the value of the derivative.

[[[00000000000000000298---3f0863bae71736e0a7569523562983736d48fcd88ce5f901ad68a405bfd5760b]]]For example, let's say we have a hypothetical neural network here, and we want to focus on one weight parameter in that neural network. At this time, the differentiation of that one weight parameter with respect to the loss function expresses 'how the loss function changes when the value of that weight parameter is slightly changed.' If the value of the derivative becomes negative, the loss function can be decreased by changing the weight parameter in the positive direction. Conversely, if the value of the derivative is positive, the loss function can be decreased by changing the weight parameter in the negative direction. However, when the derivative reaches 0, moving the weight parameter either way will not change the value of the loss function, so the weight parameter will stop updating there.

[[[00000000000000000299---2678284eca35f63f43978e3a82e3d621d67bd0d7c153f7734cec9339a90e1666]]]The reason why the recognition accuracy should not be used as an index is that the differentiation becomes 0 in most places, making it impossible to update the parameters. Well, the story is getting a little long, so I'll summarize what I've explained so far.

[[[00000000000000000300---ce08ffd440f3a912bfbf8021ec5e7c1fed583f1ac0c36f64f7826786d3ff9dc7]]]Recognition accuracy should not be used as a 'index' when training a neural network. The reason is that if the recognition accuracy is used as an index, the derivative of the parameter becomes 0 in most places.

[[[00000000000000000301---0b59253c2086712c18e296db9d113ef576cc4b7b4e0aeba9832fdce05d39799f]]]If we use recognition accuracy as an index, why is the derivative of the parameter almost always 0? ——To explain why, let's consider another specific example. Here, it is assumed that a certain neural network can correctly recognize 32 out of 100 training data. At this time, the recognition accuracy is 32%. If we were to use the recognition accuracy as an indicator, even if we changed the value of the weight parameter slightly, the recognition accuracy would remain at 32%, and no change would appear. In other words, just a small adjustment of the parameters does not improve the recognition accuracy and remains constant. Even if the recognition accuracy were improved, the value would not be a continuous change like 32.0123…%, but a discontinuous value like 33% or 34%. On the other hand, if the loss function is the index, the current loss function value is represented by a value like 0.92543…. And if you slightly change the value of the parameter, the loss function will also change continuously like 0.93432 in response to it.

[[[00000000000000000302---0f468dc28fde1d79cd922b1d8f3dcf155084434e8142127fa86db670b422462d]]]Recognition accuracy shows almost no response to minute changes in parameters, and even if there is a response, the value changes suddenly and discontinuously. The same story applies to the 'step function' of the activation function. Because if we use a step function for the activation function, the training of the neural network will not work well for the same reason. For the same reason, the derivative of the step function is 0 almost everywhere (anywhere other than 0), as shown in Figure 4-4. In other words, when a step function is used, even if the loss function is used as an index, minute changes in parameters are eliminated by the step function, and the value of the loss function shows no change.

[[[00000000000000000303---b4563edb71f9283cc3622783c558ab81b85b61253002bc6492a2006bc66651b6]]]
Figure 4-4 Step function and sigmoid function: The slope (tangent) of the sigmoid function never goes to 0, whereas the step function has a slope of 0 almost everywhere.


[[[00000000000000000304---db63681d3ba5499c3bee72159ca6fb60fd2b44c98bf1935fb284a511637221be]]]The step function is a function that changes only at a certain moment like 'shishiodoshi', while the derivative (tangent line) of the sigmoid function has a continuous output (value on the vertical axis) as shown in Figure 4-4. changes exponentially, and the slope of the curve also changes continuously. In other words, the derivative of the sigmoid function is never 0 anywhere. This is an important property in the “learning” of neural networks. This property—the slope never goes to 0—allows neural networks to learn correctly.

[[[00000000000000000305---a47ec98c2be9ac989d67216a4b382bd965c8d6d1429e358eb466728dc2e674b1]]]Numerical differentiation

[[[00000000000000000306---4a1270a776d5feed899c38308432d5c3bd2542775246acab2965a78015f74a86]]]The gradient method uses gradient information to determine the direction of travel. Here, I will explain what a gradient is and what properties it has. Before that, I would like to start with an explanation of 'differentiation'.

[[[00000000000000000307---fb43cf67ed27d52b3ff7301278632406cac903e70cc85e011118c0067d07e6c0]]]differential

[[[00000000000000000308---78dde6e3e6ef51d6690b851e9f457977fbb3395f1bca0a76b65f7db4f2fa6984]]]For example, let's say you are a full marathon runner and you run 2km in 10 minutes from the start. As for how to calculate the running speed at this time, it can be calculated as 2 / 10 = 0.2 [km/min]. In other words, it can be calculated that you ran at a speed (change) of 0.2 km per minute.

[[[00000000000000000309---47b543be7ffad29480b7179c94d7f3cea1d2d1352168d5e31c147e41f3de8b9b]]]In this marathon example, we calculated how much the 'running distance' changed with respect to 'time'. However, the calculation performed here means that you ran 2 km in 10 minutes, so you correctly calculated the 'average speed' for 10 minutes. A derivative is a measure of the amount of change at a given moment. Therefore, make the 10 minutes as short as possible—the distance you ran in the last minute, the distance you ran in the last second, the distance you ran in the last 0.1 second, and so on. , you will be able to get the amount of change at a certain moment (instantaneous speed).

[[[00000000000000000310---2d41f26e6b9875addc7e2fd654245c6f98c84cb62309295a8bb180460972f4b6]]]In this way, the derivative expresses the amount of change at a given moment. This is defined mathematically as:

[[[00000000000000000311---610231699bea92d62e8a9a79402761f9ca2f3efb2c8b8195f2490562dc30ab2d]]]Equation (4.4)

[[[00000000000000000312---98c596da7f998dadc402c10a59abfb8f75e13e2b8349d5f33c043e0d2beec2db]]]Equation (4.4) is an equation that expresses the differentiation of a function. The left-hand side is a symbol representing the derivative of f(x) with respect to x—the degree of change of f(x) with respect to x. The derivative expressed by equation (4.4) means how much the value of the function f(x) changes due to a 'small change' in x. At that time, h, which is a 'small change', is brought as close to 0 as possible, which is expressed by .

[[[00000000000000000313---f3f4428eb21a34030d88b08aaffcd575023378b2bf8a492c3506d2486d0a2b28]]]Now, referring to equation (4.4), let's implement a program to calculate the derivative of a function. If we implement equation (4.4) straightforwardly, we can substitute a small value for h and perform the calculation. For example, what about an implementation like this:

[[[00000000000000000314---8544348843c575354609bb386c1d7f2e30ef69bf899b606235111a47c9757153]]]# bad example

[[[00000000000000000315---3cc3b451baa3f3ce0962f9b0a339900cfe5887d9be21acc6e6b2c083e5487882]]]The name of the function is a function named numerical_diff(f, x) from numerical differentiation. Suppose this function takes two arguments: 'function f' and 'argument x to function f'. At first glance, this implementation looks fine, but there are actually two points that need to be improved.

[[[00000000000000000316---3df4f54c086364dd3ad1e7997313dc4e6c52f8c15cdd89623901f06d81de5a5a]]]In the above implementation, we wanted to use the smallest possible value for h (if possible, we wanted h to be infinitely close to 0), so h is 1e-50 (50 0s in '0.00...1' number) is used. However, in this case rounding error becomes a problem. A rounding error is an error in the final calculation result due to the omission of a number in a small range of decimals (for example, omission of eight decimal places). For example, in Python, rounding errors can be illustrated by the following example.

[[[00000000000000000317---4f6b5a03dcaf3a94a105571ffa238c71a68d8686a8f2ac11446fbe21ac9f63dc]]]As shown above, when 1e-50 is represented by float32 type (32-bit floating point number), it becomes 0.0, which means that it cannot be represented correctly. In other words, using values that are too small causes computational problems. This is the first improvement point. It is to use as this tiny value h. Using a value of degree has been found to give good results.

[[[00000000000000000318---5abfa32f5acaa06d0b5eb6a88cd696e3e54f48cf3209518451d4923c39265dd2]]]The second improvement point of the above implementation is about the difference of the function f. The above implementation calculates the difference of the function f between x+h and x, but it should be noted that there is an error in this calculation in the first place. As shown in Figure 4-5, the 'true differentiation' corresponds to the slope of the function at x (this is called the tangent line), but the differentiation performed in this implementation is (x + h) corresponds to the slope between and x. Therefore, the true derivative (true tangent) and the value of our implementation do not exactly match. This difference arises because h cannot approach 0 indefinitely.

[[[00000000000000000319---85d2ec01f51f93b7ecfca22f4626ab4b2aeb342403babe2a306a26059291d649]]]
Figure 4-5 Values of true derivative (true tangent) and numerical derivative (approximate tangent) are different


[[[00000000000000000320---f272076e690e77e7f5062aaf344678994356c5c662b78fdc95984886c1f6f18f]]]Numerical differentiation includes error, as shown in Figure 4-5. As a device to reduce this error, the error can be reduced by calculating the difference of the function f at (x＋h) and (x−h). This difference is called the central difference because it calculates the difference before and after centering x (on the other hand, the difference between (x + h) and x is called the forward difference). Now, based on the two improvements, we will implement numerical differentiation (numerical gradient).

[[[00000000000000000321---48088abacd21d8e5e989b1d4ed01e9c1faec7a6cb9e0b66d5614867ab4ecbf40]]]Finding differentiation by minute differences, as we do here, is called numerical differentiation. On the other hand, finding the differential by expanding a mathematical formula is called ``analytically solving'' or ``analytically finding the differential,'' using the word analytic. For example, the derivative of y = x2 can be solved analytically as So the derivative of y at x=2 can be calculated as 4. Analytic differentiation can be obtained as 'true differentiation' that does not include error.

[[[00000000000000000322---1c43b7080e1ed52c97b09ffd4cd85e6f2a37bd0e61d2d4427491611168432eaa]]]Examples of numerical differentiation

[[[00000000000000000323---26abf6f29f3a49e26474f47c09197e45b451f9778dcf6e493427daeef6dae580]]]Let's differentiate a simple function using the numerical differentiation above. The first is the quadratic function expressed by the following formula.

[[[00000000000000000324---67119cc151a7a4311d906dc936270e625306c6719fdb8c9e82457398dfd392c8]]]Equation (4.5)

[[[00000000000000000325---359828a0654a6be9765219f90745d8645ba7225b1fde7f79aa759f70dc4d2b50]]]A Python implementation of this expression (4.5) looks like this:

[[[00000000000000000326---a566d1d3fe6cecaeb3cdfb82d753a2584bdb92c2f6f881b3128d7954ec3f42ec]]]Then draw this function. The code for drawing and the generated graph looks like this (Figure 4-6).

[[[00000000000000000327---b9549d771146dfb9d4095ff0dcae2a2f6b98d3e3f7cfd6a847e6c208e2f6d5ec]]]# x array from 0 to 20 in steps of 0.1

[[[00000000000000000328---75238c9ef2d5985494f87366d5e18f25779ee0deed46bbff69134c2372803c4f]]]
The graph in Figure 4-6


[[[00000000000000000329---263a3ee23db551f7a99012354c4bd18835908577fe438ea1d93daab4f7097aa2]]]Now let's calculate the derivative of this function at x=5 and x=10 respectively.

[[[00000000000000000330---31c1a98663d8414f13fe596254ace22db8c9735e9e450b7fe5388acca7d70d93]]]The derivative value calculated here is the amount of change in f(x) with respect to x, which corresponds to the slope of the function. Note that the analytical solution for is Therefore, the 'true differentiation' at x = 5 and 10 is 0.2 and 0.3. Comparing the results with the numerical differentiation above, it does not match exactly, but you can see that the error is very small. . In fact, the error is so small that it can be considered almost the same value.

[[[00000000000000000331---a3771da049ca3d42543ddb7e9409b871439b9addcf37d14e34bb39a883039a90]]]Now, let's use the result of numerical differentiation above and plot a straight line with the numerical differentiation value as the slope. The result looks like Figure 4-7, which confirms that it corresponds to the tangent of the function (the source code is in ch04/gradient_1d.py).

[[[00000000000000000332---07a4cf1648c53e06da5753f05179b5dd36086eff07c726eeb8424c4a9150b226]]]
Figure 4-7 Tangent line at x = 5, x = 10: Use the value obtained from numerical differentiation for the slope of the straight line


[[[00000000000000000333---0b7dadf5dd237a1f0e5ab0e16c4856c8f0093e03bfc9504373dc539167e5f5ff]]]partial differentiation

[[[00000000000000000334---241325bf3cb24afb59919482f8fd583a5cfd110e9a20031f7d654f55558a757f]]]Next, let's look at the function represented by formula (4.6). It's a simple formula that just computes the sum of the squares of the arguments, but unlike the previous example, notice that there are two variables.

[[[00000000000000000335---a81798491ae1d41460182d594b122f38a69d595aa02c384bd32d4172bc817cbb]]]Equation (4.6)

[[[00000000000000000336---7d65b22846f2300588eb9603d6ed09dce7a0e5964447715351255efbb7d84d24]]]This expression can be implemented in Python as follows:

[[[00000000000000000337---803931c8a81c932bd5f6fc52478dbc415ddba488ccec359e41473386ae0b248e]]]# or return np.sum(x**2)

[[[00000000000000000338---f0689be24070ac72a3eeec4419453bb9748b18672b033b3ccd426cd7f3a23a6d]]]Here, we assume that the input is a NumPy array as an argument. The content of the function is a simple implementation that just squares each element of the NumPy array and finds the sum (the same process can be implemented with np.sum(x**2)). Now let's plot this function on a graph. The results are drawn as a three-dimensional graph, as shown in Figure 4-8.

[[[00000000000000000339---92b24ee03e0407bf1f3b652cb05b97344d9527253915f80dc632075826b97fe0]]]
The graph in Figure 4-8


[[[00000000000000000340---eee022216d48c3f927d5423523acda45e265188294c61a23f951714c9780b34c]]]Now, let's find the derivative of equation (4.6). The point to note here is that there are two variables in equation (4.6). Therefore, it is necessary to distinguish which variable of the two variables, x0 and x1, is the differentiation with respect to which variable. The differentiation of a function consisting of multiple variables, which is treated here, is called partial differentiation. If we express this partial derivative as a formula, we write it as follows.

[[[00000000000000000341---6f92a03237798ca22d8b71aed94110c66c6e429aaaf8a3e4723b94757c6d12f3]]]How can we find the partial derivative? Let's try to solve the following two partial differential problems.

[[[00000000000000000342---23a7973c0ffd702b52bfade0ac64e1c5280a2ebe69b3d2f6d0184b90d1e35cef]]]Question 1: Find the partial derivative with respect to x0 when x0 = 3 and x1 = 4.

[[[00000000000000000343---a74bb320f67306dc946a0ef342c666d10025aa9a93ee25b9b164d5ba9df3d7fa]]]Question 2: Find the partial differential with respect to x1 when x0 = 3 and x1 = 4.

[[[00000000000000000344---52804a9ceefa007dc2e97cfd636b282ca276a090da683a2f9a793fc36b419199]]]These problems are implemented by defining a function with only one variable and calculating the derivative with respect to that function. For example, in question 1, we define a new function with x1=4 fixed, and then apply the numerical differentiation function to the function whose only variable is x0. From the above results, the answer to question 1 is 6.00000000000378 and the answer to question 2 is 7.999999999999119. This is nearly identical to the analytic derivative solution.

[[[00000000000000000345---4dede0288688badf1b33d2e8aac94b52de986aaa5663e340adcf74dc9a472987]]]In this way, partial differentiation is the same as one-variable differentiation, and finds the slope at a certain point. However, in the case of partial differentiation, the target variable is narrowed down to one among multiple variables, and the other variables are fixed at a certain value. In the implementation of the example above, we defined a new function to fix the non-target variable to a specific value. Then, to the newly defined function, we applied the function of numerical differentiation used so far to find the partial derivative.

[[[00000000000000000346---e12dfefc1f126b3bb31233b22b9b73701020edf9f0a3deca277717cb00c5b3e8]]]Slope

[[[00000000000000000347---85a5de518e294b8b2761a8c91722cf68459e07b7e08fd1f3ef3dd40e1974d6be]]]In the previous example, we calculated the partial derivatives of x0 and x1 for each variable. Now let's say we want to calculate the partial derivatives of x0 and x1 together. For example, consider calculating both partial derivatives of (x0, x1) together when x0=3 and x1=4. In addition, as shown in the above, the partial differential of all variables is called the gradient. Gradients can be implemented, for example, as follows:

[[[00000000000000000348---47e5dd18391444106793cb83a7fe4769a756f0aba277105a5305fe47324a716f]]]# create an array with the same shape as x

[[[00000000000000000349---20ae3fc89f01d94423cf215e4fa68486c353252811ed0e3057526b3e38d73524]]]# Calculate f(x+h)

[[[00000000000000000350---6265c92d93149e7ef115897b9eaa732d1ae7f8d36b21712d6d3e0c5b83b4b0eb]]]# Calculate f(xh)

[[[00000000000000000351---9194ffcc0f9e5f2a07f6150c4af65e412ec07dd6314f72c44aef2830f1a788f8]]]# restore the value

[[[00000000000000000352---a4d361a6e99ab1cfefbc95de8bfe8862a96662b5a9d86c7b295d34d85dde0e47]]]The implementation of the numerical_gradient(f, x) function looks a bit complicated, but it does little more than numerical differentiation of one variable. As a side note, np.zeros_like(x) creates an array with the same shape as x, but with all zeros.

[[[00000000000000000353---903a1d74ea6d167a86fff3e338f2b49b08d721cf3b6ba7e9a1e42288a0642c6b]]]The numerical_gradient(f, x) function finds the numerical derivative for each element of the NumPy array x, where f is a function and x is a NumPy array. Now let's use this function to actually calculate the gradient. Here we find the gradients at points (3, 4), (0, 2), and (3, 0).

[[[00000000000000000354---4b1ad0a416d06f7e0e86abcdb6c1d4704851f4a92684f71866bf24edd25e813b]]][†1] We actually get the values [6.0000000000037801, 7.9999999999991189], but they are printed as [6., 8.]. This is because when outputting a NumPy array, the numbers are formatted 'for easy viewing'.

[[[00000000000000000355---f72a8aeea824ed951ca2207f1423551e59f580e4a4f31746986b2995288b8dfa]]]Thus, we can compute the gradient at each point in (x0, x1). In the example above, the slope of the point (3, 4) is (6, 8), the slope of the point (0, 2) is (0, 4), the slope of the point (3, 0) is (6, 0), etc. What does this gradient mean? To understand it, let's try to represent the gradient of . However, here I draw a vector with a negative gradient result (source code is in ch04/gradient_2d.py).

[[[00000000000000000356---792251e35fe3a4ca9b37e428437d1057466f5ba46519823cc00d4aabb02f0288]]]The gradient of is illustrated as an oriented vector (arrow) as shown in Figure 4-9. Looking at Figure 4-9, the gradient seems to point to the 'lowest point (minimum)' of the function. Like a compass, the arrow points to a single point. Also, you can see that the farther away from the 'lowest place', the larger the size of the arrow.

[[[00000000000000000357---394480b8124dc11acc217aaeb8f334a5533d327d6980fd775d687adc2982dde4]]]
Gradient in Figure 4-9


[[[00000000000000000358---933e9e1d47ba97193236a2260ac67a28b0cbccd5d0e37a61717ee84e5d812681]]]The example in Figure 4-9 points to the lowest slope, but that is not always the case. However, the slope points in the direction of decreasing at each point. More precisely, the direction in which the gradient points is the direction that reduces the value of the function the most at each location. This is an important point, so remember it!

[[[00000000000000000359---e72103918c48f92fb76562a83160bd0e3a2790023b95c48d2d95f018ec2e1165]]]Gradient method

[[[00000000000000000360---02e67c1c32e57350888bb3e0291d375742108470ecf6c0783d43b25f0c659dfd]]]Many machine learning problems search for optimal parameters during learning. Neural networks also have to find the optimal parameters (weights and biases) during training. Here, the optimal parameter is the value of the parameter when the loss function takes the minimum value. But loss functions in general are complex. The parameter space is vast and we have no idea where to find the minimum value. Therefore, the gradient method is to find the minimum value (or the smallest possible value) of the function by making good use of the gradient.

[[[00000000000000000361---7484e830655f8179c5d7737a3598375a7efd75813a01531755886a7f13ae29aa]]]The caveat here is that the gradient is the direction that reduces the value of the function the most at each point. So we can't guarantee that the destination of the gradient is really the minimum value of the function, or that it's really the direction it should go. In fact, in most complex functions the direction of the gradient is not the minimum value.

[[[00000000000000000362---9ec6808053da09c7582ea1769274771fc9ae6fef5b3f0ca1fe6787780c6cffe0]]]At the local minima or minima of the function, also called saddle points, the gradient is 0. A local minimum is a local minimum, that is, a point that is the minimum only within a limited range. A saddle point is a point that is a maximum when viewed in one direction and a minimum when viewed in another direction. The gradient method looks for the zero gradient, which is not necessarily the minimum (it could be a local minimum or a saddle point). Also, complex and distorted functions can get stuck in (almost) flat terrain and stagnate in learning, known as a 'plateau.'

[[[00000000000000000363---54aae31ff33505f54644636af77f460ce13822e9aee56f1485f0b3c8af37f4fe]]]Even if the direction of the gradient does not always point to the minimum, going in that direction will reduce the value of the function the most. Therefore, in the problem of finding the location of the minimum value—or the problem of finding the location of the function with the smallest possible value—the gradient information should be used as a clue to determine the direction to proceed.

[[[00000000000000000364---be1a2d5498d692f4af47ac4a6797711c5edbaedcb2ac159f9a944be195635aeb]]]That's where the gradient method comes in. The Gradient method walks a fixed distance in the direction of the gradient from your current location. Then, the gradient is obtained in the same way at the destination, and it moves in the gradient direction repeatedly, such as moving in the gradient direction. Gradient method is to gradually reduce the value of the function by repeating the process in the direction of the gradient. Gradient method is a technique often used in machine learning optimization problems. In particular, the gradient method is often used in training neural networks.

[[[00000000000000000365---ba2abe55dee1884f9b6ad22d478208453b1da6c0b2735a40e38be5651db36eb6]]]Gradient methods are called differently depending on whether the goal is to find the minimum or the maximum. To be precise, searching for the minimum value is called the gradient descent method, and searching for the maximum value is called the gradient ascent method. However, if we reverse the sign of the loss function, the problem of finding the minimum value is the same as finding the maximum value, so the difference between 'falling' and 'rising' is essentially irrelevant. Generally, in the field of neural networks (deep learning), the gradient method often appears as 'gradient descent method'.

[[[00000000000000000366---2263af33aab72037b6f88a9397e9027689f29f7afa71c0742666a30cd34331ce]]]Now, let's express the gradient method as a formula. The gradient method can be expressed as formula (4.7) below.

[[[00000000000000000367---a451840743cc8ab1f4ae695b44cf8336c551852d76422957989751be8ff2a48d]]]Equation (4.7)

[[[00000000000000000368---0093805c352a1f1b584546f6fef7c7ae349c54ef50ae0b681abc4fd0e1e6835d]]](4.7) represents the amount of updates. This is called the learning rate in neural network learning. The learning rate determines how much to learn and how much to update the parameters in one learning.

[[[00000000000000000369---39788cb11b3cedb88ba7db61b3ea6771cafd5b35e6b2259315d87a0b372e44cd]]]Equation (4.7) shows a single update equation and repeats this step. In other words, at each step, the value of the variable is updated as shown in formula (4.7), and by repeating that step several times, the value of the function is gradually reduced. Also, here we show the case with two variables, but even if the number of variables increases, it will be updated by the same formula--the value of the partial derivative of each variable.

[[[00000000000000000370---1c9a7ae1038efb765fa13fe4bc62e9b44790a1f208da186c7f32a3acfcd2d5f4]]]Note that the value of the learning rate must be determined in advance to some value, such as 0.01 or 0.001. This value is generally too large or too small to get you to a 'good place'. In neural network learning, it is common to check whether learning is correct while changing the value of the learning rate.

[[[00000000000000000371---db0976557df74e1aa61db834fa346266386ad5b486c4a61aae92c234ffa70dca]]]Now let's implement gradient descent in Python. The implementation is simple and looks like this:

[[[00000000000000000372---0a77ffbf1edf0f910d9c39523d7e569cea50864fc98b68ddf0e86f9c52b877ea]]]The argument f is the function to be optimized, init_x is the initial value, lr is the learning rate, and step_num is the number of iterations by the gradient method. The gradient of the function is obtained by numerical_gradient(f, x), and the process of updating with the value obtained by multiplying the gradient by the learning rate is repeated the number of times specified by step_num.

[[[00000000000000000373---154a28440c498198176c3469409f423f565f62bf8521995176a89340fa22c950]]]With this function you can find the local minimum of the function and hopefully find the minimum. Now let's try to solve the following problem.

[[[00000000000000000374---af3f8258c76494470f5a4d9fbba3c760d68f184f2ce9244f5edb77a78641832a]]]Q: Find the minimum value of using the gradient method.

[[[00000000000000000375---9a87ab020ac9a1cb77596067f0afa414b47fb4f6ff3b942ff2057c596722c7bd]]]Here we use the initial value of (-3.0, 4.0) to start the search for the minimum using the gradient method. The final result is (-6.1e-10, 8.1e-10), which is pretty close to (0, 0). In fact, the true minimum is (0, 0), so the gradient method gave us almost the correct result. Figure 4-10 shows the update process using the gradient method. The origin is the lowest place, but you can see that it is gradually approaching there. Note that the source code for drawing this figure can be found in ch04/gradient_method.py (ch04/gradient_method.py does not show dashed contour lines in the figure).

[[[00000000000000000376---c365c00b54c4f4a758ac1be704e718da3e38018b1ec8e660f326110bba8befae]]]
Gradient method update process in Figure 4-10: dashed lines indicate the contours of the function


[[[00000000000000000377---0ff54f6daf43aab8feecf6b2d7d82cd6508941c2fcc30a15e214dd17782ca7a2]]]By the way, I said that a learning rate that is too large or too small does not produce good results, but here we will experiment with both cases.

[[[00000000000000000378---a36aeb5299dc8e04f5d229f9c7468a09b66c364fc47950d2d2ed3b3ca212d954]]]# Example of too large learning rate: lr=10.0 >>> 

[[[00000000000000000379---f36c9845691a5d513ded0edc05e3bcf1660eb9ad341256518aac8a00c296fb83]]]
array([ -2.58983747e+13, -1.29524862e+12]) # too small learning rate example: lr=1e-10 >>> 

[[[00000000000000000380---71792f569459288d1a0a3c618a52b7c41ba59221b91392cf7ca1f8937523f658]]]As the results of this experiment show, if the learning rate is too large, it will diverge to large values. Conversely, if the learning rate is too small, it will end up with few updates. This means that setting an appropriate learning rate becomes an important issue.

[[[00000000000000000381---17fc7880bd4be57a50280f4592a519a082c32343d9655d1ba6f5f81987189fbb]]]Parameters like learning rate are called hyperparameters. This is a different parameter from neural network parameters—weights and biases. This is because the weight parameters of a neural network are parameters that are “automatically” acquired by the training data and the learning algorithm, whereas hyperparameters like the learning rate are parameters that are manually set. In general, it is necessary to try various values of these hyperparameters to find cases that can be learned well.

[[[00000000000000000382---5863ff2d102afb0aa621ffd3def85cf1d2066b2c7b286f50d9f369ea5c8b3025]]]Gradients for Neural Networks

[[[00000000000000000383---03ca614c74c654d3d6061d42c643ae10ed10161187d9c2bda9f52ed11d489885]]]Gradients also need to be found in neural network training. The gradient here is the gradient of the loss function with respect to the weight parameter. For example, let's say we have a neural network with only weights W of shape 2x3 and we denote the loss function by L. In this case the gradient can be expressed as The actual formula is as follows.

[[[00000000000000000384---b02d1f97cc4b07decae8d2df93712948f3a53ab77bf1c7a44d8696f1683fd757]]]Equation (4.8)

[[[00000000000000000385---e80cc6a269b55cc30dd31a4049bac8cd230c54610b6cef0c23f32de29661c7f9]]]Each element of consists of a partial derivative with respect to the respective element. For example, the element at row 1, column 1 represents how much the loss function L changes when w11 is slightly changed. The important point here is that the shape of is the same as that of W. In fact, in equation (4.8), W is the same 2x3 shape.

[[[00000000000000000386---fbd1e5391e871e5e74a7bf18d1b0d164fba54b3d5cd8998d848635deb84f65c6]]]Now, let's take a simple neural network as an example and implement an actual gradient calculation. For that, I will implement a class called simpleNet (source code is in ch04/gradient_simplenet.py).

[[[00000000000000000387---0879e265a581751d5994e31dc5ba5195ecf7796ef586e3ae9b618ca2c526b07b]]]# Initialize with Gaussian distribution

[[[00000000000000000388---e6f8f04aee50b6e4409d48c4f9f7f4104060d5635c234b611103cdc5f56bc2e9]]]Here we make use of the softmax and cross_entropy_error methods found in common/functions.py. It also makes use of the numerical_gradient method found in common/gradient.py. Now, the class simpleNet has a single instance variable of a weight parameter with a shape of 2x3. It also has two methods, one is the method predict(x) for prediction and the other is the method loss(x, t) for finding the value of the loss function. Here, the input data is input to the argument x, and the correct label is input to t. Let's try using this simpleNet.

[[[00000000000000000389---e5b4cd4855b881cc04117aa31ed04cf48af1f494a5801d409eb72ce95184e478]]] # weight parameters [[ 0.47355232 0.9977393 0.84668094] [ 0.85557411 0.03563661 0.69422093]] >>> >>> 

[[[00000000000000000390---edce887ed192f91aceabe85d56a99b7d1b820ef112b60286dc145cf7b6f5599b]]] # Index of max value 2 >>> >>> 

[[[00000000000000000391---be68a50057881010939de8a92d91359fce8a8b8f9cc6f7a2ae3bdc2ccc7aa5cd]]] # correct label >>> 

[[[00000000000000000392---c1da9cf69d4f70c7b6143b0d19e89d13d7c42722817234fe216800225ccb8d9f]]]Next, let's find the slope. As before, find the gradient using numerical_gradient(f, x) (The argument W of the function f(W) defined here is a dummy. We defined f(W) to be consistent with f(x) internally).

[[[00000000000000000393---1d0ffb8d455cee4536827c7d404569e6f88c3fec0cf801b2987ae68719af3f44]]]The argument f of numerical_gradient(f, x) is the function and x is the argument to the function f. So here we define a new function f that takes net.W and computes the loss function. Then pass that newly defined function to numerical_gradient(f, x).

[[[00000000000000000394---cae9a7bc3b9524d59d18af6dcec814fa37e0e14bde0372e59010533b8571b31a]]]numerical_gradient(f, net.W) results in dW, a two-dimensional array of shape 2x3. If you look inside the dW, you'll see that, for example, is about 0.2. This means that increasing w11 by h increases the value of the loss function by 0.2h. Also, is approximately −0.5, which means that increasing w23 by h reduces the value of the loss function by 0.5h. Therefore, from the point of view of reducing the loss function, it is better to update w23 in the positive direction and update w11 in the negative direction. Also, regarding the degree of update, we can see that w23 contributes more than w11.

[[[00000000000000000395---c27afecdfc0cd146230394442f960396a0dcb78772e6cbd11c8225b91323d628]]]In the above implementation, I wrote like 'def f(x):...' to define a new function, but in Python, if it's a simple function, you can write it using the lambda notation. can. For example, you could implement it using lambdas like this:

[[[00000000000000000396---7fdc91cbb26fcbea779567909eb4754a5caf99878ae4bee281304c823585f01c]]]After finding the gradients of the neural network, all that remains is to update the weight parameters according to the gradient method. In the next section, we will implement the entire learning process for a two-layer neural network.

[[[00000000000000000397---2c54683d2cbaff3cf43117153f91796ae3c0811f02615fd57175cc8c797435b9]]]The numerical_gradient() used here is slightly modified from the previous implementation to accommodate multidimensional arrays like the weight parameter W. However, the changes are simple only to accommodate multidimensional arrays. I won't explain the implementation here, but if you want to know more, please refer to the source code (common/gradient.py).

[[[00000000000000000398---198a289ffb1fd4870b489d4fde2dd0ffeb3e23fba6a56ba4d6840d989e63f200]]]Implementing learning algorithms

[[[00000000000000000399---4b2d653769ba426301e84d39d5cae359cc0420fed60a5fc77d73038b773f4661]]]Now you have all the basic knowledge about training neural networks. So far, important keywords such as 'loss function', 'mini-batch', 'gradient', and 'gradient descent' have appeared one after another, so I decided to check the neural network learning procedure as a review. increase. Next, we summarize the neural network learning procedure.

[[[00000000000000000400---bb9f5f19c7f14c1c83bc2f60c8b6b533ef8da215dc1b1ce8125546531c5951db]]]premise

[[[00000000000000000401---7fcbd656131441754c8de3ad30317ee2560bebdbf3b7be3c5117ef2e2c2c972a]]]Neural networks have adaptive weights and biases, and adjusting these weights and biases adaptively to training data is called 'learning.' Neural network training is performed in the following four steps.

[[[00000000000000000402---ff35bb1782b003c5652590e6dc4c3b22802e4740e6c25077880e42cd495a28eb]]]Step 1 (mini-batch)

[[[00000000000000000403---bc98ca5126c5be5eaa1a36be69f90790b1b8f3ed14dd679950fbf2f5f6c8c01f]]]Randomly select some data from the training data. The selected data is called a mini-batch, and the purpose here is to reduce the value of the loss function of the mini-batch.

[[[00000000000000000404---cbf6fb02e308f7ba7bf5604e82f4615e67e9ee373f3388e721e0646d6b0681ce]]]Step 2 (Slope Calculation)

[[[00000000000000000405---174c78711ee8903a2796ec5e2afa45f17828e926376b17758e641f17dcfe6027]]]Find the gradient of each weight parameter to reduce the mini-batch loss function. The slope indicates the direction that reduces the value of the loss function the most.

[[[00000000000000000406---6c38142ce74803c319b99967ef878fbbfd1b1af802867e8daca160be4310757c]]]Step 3 (Update parameters)

[[[00000000000000000407---489fc9d1cf1b1e3dc70c4bbb7d34279fd849c9c8407e9478f128c5834ac90707]]]The weight parameter is updated by a small amount in the direction of the gradient.

[[[00000000000000000408---d8d2067db934a21e3070adbc16e44d16a7edaf5a9f07a504704ad019a490fab9]]]Step 4 (repeat)

[[[00000000000000000409---4afeefc5fcb1318c31f20095924ca1e0ea4c3b0a3d41430ac016deb2ad0cb595]]]Repeat step 1, step 2, and step 3.

[[[00000000000000000410---ccff8bc7da1d9ca4fbfc436e832e9b1ca5b4fc9c050259d617fd36556fa2385d]]]Training a neural network is done using the above four-step method. This method uses gradient descent to update the parameters, but since the data used here is randomly selected as a mini-batch, it is called stochastic gradient descent. called by name. Probabilistic means 'chosen at random'. Therefore, stochastic gradient descent means ``gradient descent for randomly selected data''. In addition, in many deep learning frameworks, stochastic gradient descent is generally implemented with a function named SGD, which is an acronym for English.

[[[00000000000000000411---8efb92005dd0b7df3f31ce2017b69af7ab1adc61af45042c2039ce397cacbfb7]]]Now let's implement a neural network that actually learns handwritten digits. Here, we target a two-layer neural network (a network with one hidden layer) and train it using the MNIST dataset.

[[[00000000000000000412---e43f67cfbcea87369787d84d00fe699172a343fd3447fbbee6d9958bc806a9dd]]]A class of two-layer neural networks

[[[00000000000000000413---394fb27ebcd86a691deedb250528e2768c6a1cec9ec7f193055ca5e7c666384a]]]We'll start by implementing a two-layer neural network as a class. Implement this class as a class named TwoLayerNet as follows†2. The source code is in ch04/two_layer_net.py.

[[[00000000000000000414---f184a3d1e21daaa6f5516f939b2865c25e0130cffcebc518f0e257f53d7f675a]]][†2] The implementation of TwoLayerNet was based on the implementation of the Python source code provided in the course CS231n[5] at Stanford University.

[[[00000000000000000415---d7f2704dda40d0528bed1e8e16c66e17b842f50172d7ba8554f23c7229aedc67]]]# Initialize weights

[[[00000000000000000416---3be1559c2728443f7c759c3afe3584849fc8c1ea668b1700faae69229fb3339d]]]# x: input data, t: training data

[[[00000000000000000417---3be1559c2728443f7c759c3afe3584849fc8c1ea668b1700faae69229fb3339d]]]# x: input data, t: training data

[[[00000000000000000418---f18ff78d6ca40062f522df624805e08ba8879f7eb84c42ea707ee85b38c3d0d9]]]The implementation of this class is a bit lengthy, but it has a lot in common with the implementation of neural network forward processing in the previous chapter, so there's not much new to see. First, let's organize the variables and methods used in this class. Regarding variables, only important variables are picked up and shown in Table 4-1. All of the methods are listed in Table 4-2.

[[[00000000000000000419---9a144c4ecfd221035ce8f4b8b4505f17ba17ebe04dfa396fca4c8df9b00c5368]]]Table 4-1 Variables Used in the TwoLayerNet Class

[[[00000000000000000420---1d1ef987633443e3cf3941a1eef5d4cbb1dee991f3677b7c6f5c3a4839cd715c]]]variable

[[[00000000000000000421---9683551a843c71d8b84ba930126021ef40831ee11bd5e69b06a3ea589148bba6]]]explanation

[[[00000000000000000422---4ceffaae78861ac65039f2551f08b3794f6b68fc40b2b5a4f8499e04b0b2a0d0]]]A dictionary variable (instance variable) that holds the parameters of the neural network.

[[[00000000000000000423---eec89f1b0d665d974f6ec7ab3e5c31aa304c22088d23ae1a0316916bbc8c4551]]]is the weight of the first layer,

[[[00000000000000000424---ccb568959194b51a7f7430fb918d6e0a8fbeb8cf4e37545dd63824a0512dccc5]]]is the first layer bias.

[[[00000000000000000425---a797534e61782100bce2f34f0b2b9ec7b8ddb4d55dfab3d6af379adaadd2cc1f]]]is the weight of the second layer,

[[[00000000000000000426---600ed542d29447f137a50ca188d61f7662e2bdd3a27579dff96547eca50c87d4]]]is the second layer bias.

[[[00000000000000000427---16d3f42e44785bec9997851bebdf2a0db3157cd6b9719578254246ae8085b8f5]]]A dictionary variable holding the gradient (

[[[00000000000000000428---ea2f6a8ce1dede0a6bf3860850c32659151eaf9cef1d279a8e4f88de881bc997]]]method return value).

[[[00000000000000000429---3f4377ba04dfca94ae3b3b486ace3419d4938135ff4e99ef8cef79279d376f1c]]]is the gradient of the weights in the first layer,

[[[00000000000000000430---2c7e00fd8f1cab9c746f22440ab70dbdcf3c9c6b9a76aa86cf689a32554cc86d]]]is the slope of the first layer bias.

[[[00000000000000000431---d9085c7d7f4d62da01b33788c14cb31aca38b3c4f511f5f5382ac43e99628d12]]]is the gradient of the weights in the second layer,

[[[00000000000000000432---a6b93a652f0a7cf5f0ec2ee45ae5d6c2bbc4f6b9ab6e47104bf56d9526e546b9]]]is the slope of the second layer bias.

[[[00000000000000000433---0ab7f1bf8753ad25a5ca82b4349235ff27007577da0f7864d767bca5e7a72cac]]]Table 4-2 Methods of the TwoLayerNet Class

[[[00000000000000000434---99942ce88f0b978ae878a57b8584fb85b2d2fbbad57b31929100a7363d500b02]]]method

[[[00000000000000000435---9683551a843c71d8b84ba930126021ef40831ee11bd5e69b06a3ea589148bba6]]]explanation

[[[00000000000000000436---9c85880f483ef1a30b1b6d1b9eee38a6ea2a5e5bd09ad3213ce365568782d731]]]Initialize.

[[[00000000000000000437---48dbfa25bf99ea7916a77410b14a9b4cc46a6989beffd78ff3c615ca8f238747]]]Arguments are the number of neurons in the input layer, the number of neurons in the hidden layer, and the number of neurons in the output layer, starting from the top.

[[[00000000000000000438---ef670f48347db3637ea83e1f587d5fe2111512c5c76a762d22da41d497fd730c]]]Recognize (infer).

[[[00000000000000000439---8f0e863bf02b3043e1f2142321fb02ff777e7bd7ed7fa4f4261a7dff5c42ca82]]]of the argument

[[[00000000000000000440---c281dc55ae1a991d806e506395e4acbfd4677554405fb0feb719d79910a19571]]]is image data.

[[[00000000000000000441---2b576a23c2464d5f867a8eb2e211aaa0a48dc212ff5ab4284103919ccfb3412d]]]Find the value of the loss function.

[[[00000000000000000442---8f0e863bf02b3043e1f2142321fb02ff777e7bd7ed7fa4f4261a7dff5c42ca82]]]of the argument

[[[00000000000000000443---22a5f2a63996157de316b0d10a97211371ebf2db7a5f2bb1548d35ede1fa08bf]]]is image data,

[[[00000000000000000444---eea03d518dc210a1ea0e13f80d7ec9fc9fb864edea4ae2d456e03c798680e07f]]]is the correct answer label (same for the arguments of the three methods below).

[[[00000000000000000445---ec575dbf741773e1ca718afa2fa0ed3edb05b360e9714eb072f5052ac85014e5]]]Find recognition accuracy.

[[[00000000000000000446---455006a66f14d0ca74ca28e4062a99aa7a6f90eabe17252a7c9b602b99f5b18b]]]Find the gradient for the weight parameter.

[[[00000000000000000447---455006a66f14d0ca74ca28e4062a99aa7a6f90eabe17252a7c9b602b99f5b18b]]]Find the gradient for the weight parameter.

[[[00000000000000000448---de76425b6ecc384ac2aac274d16009f584885f43e3158a7d04d538813e78ae47]]]A faster version of!

[[[00000000000000000449---e2e5b86b720eac9c5378ac900229e1632a01e63e367d4ce0571c5a076d6d0638]]]Implementation will be done in the next chapter.

[[[00000000000000000450---9b29151c7bcdce66e137cef1190e74faa56fb9a6228c3fd0391bea9fc61c4884]]]The TwoLayerNet class has dictionary variables params and grads as instance variables. The params variable stores the weight parameters, for example the weight parameters for the first layer are stored as a NumPy array in params['W1']. Also, the first layer bias is accessed like params['b1']. Let's look at an example.

[[[00000000000000000451---2996111e9ba0a034d05513c91a83b2ecf1d1ee59aa2e39f34b5a9de907d14bde]]]As above, the params variable contains all the necessary parameters for this network. And the weight parameters stored in the params variable are used in the inference process (forward process). By the way, the inference process can be done like this:

[[[00000000000000000452---11727a2e8cd9892e3400569b80c5dd048839ebfe5d3379598bb29188912f42a6]]]# Dummy input data (for 100 sheets)

[[[00000000000000000453---055c1368da71659c82dc9091c1809863148fd64ddaa4c46bf65adc2f3fa5d5fd]]]Also, the grads variable stores the gradient of each parameter, corresponding to the params variable. For example, using the numerical_gradient() method to compute the gradient stores the gradient information in the grads variable, as shown below.

[[[00000000000000000454---11727a2e8cd9892e3400569b80c5dd048839ebfe5d3379598bb29188912f42a6]]]# Dummy input data (for 100 sheets)

[[[00000000000000000455---18c77255fec645c0dc48684366d36147e5a2d2a8ef578771f224f7eafec43fd3]]]# Dummy correct label (100 sheets)

[[[00000000000000000456---fdcbc5420d1103eb2f23645210152c90a2cdce1a761d138b38138fa5d80fc725]]]# calculate gradient

[[[00000000000000000457---56d862ffefc1cbc276d28059b38b37afd2dc05f020b7772796ce44b20909815c]]]Next, let's take a look at the implementation of TwoLayerNet's methods. The first is the __init__(self, input_size, hidden_size, output_size) method, which is the initialization method of the class (initialization method is the method called when TwoLayerNet is generated). Arguments mean the number of neurons in the input layer, the number of neurons in the hidden layer, and the number of neurons in the output layer, starting from the top. When performing handwritten digit recognition, the input image size is 28 x 28, totaling 784, and the output is 10 classes. Therefore, specify the arguments input_size=784 and output_size=10, and set an appropriate value for hidden_size, which is the number of hidden layers.

[[[00000000000000000458---4a2f73e4af5c9ebf348bc03c42f1d0f02b969b19e9804b33c076eb2b17d94371]]]This initialization method also initializes the weight parameters. The problem of how to set the initial values of the weight parameters is important for successful neural network training. We'll take a closer look at initializing the weight parameters later, but for now let's just say that the weights are initialized with Gaussian random numbers and the biases are initialized with 0. Predict(self, x) and accuracy(self, x, t) are almost the same as the implementation of neural network inference processing in the previous chapter. If you have any questions, please check the previous chapter. Also, loss(self, x, t) is a method to calculate the value of the loss function. The implementation of this method simply calculates the cross-entropy error based on the result of predict() and the correct label.

[[[00000000000000000459---1d1f05b8841d4c9a35d98fdfd1ff58947a0cb22e5dc0f9c50dafa1d2cf9edb08]]]The remaining numerical_gradient(self, x, t) method computes the gradient for each parameter. It computes the gradient to the loss function for each parameter by numerical differentiation. Note that gradient(self, x, t) is a method that will be implemented in the next chapter. It uses backpropagation to compute gradients efficiently and quickly.

[[[00000000000000000460---cbaf4ee5d8c0c9e8e4aa826f36d5d337e9a95a8c4b98c81d39a4911fa8aabe54]]]numerical_gradient(self, x, t) computes the gradient of a parameter by numerical differentiation. In the next chapter, we will explain a method for obtaining this gradient calculation at high speed. This method is called error backpropagation. Gradient results obtained using backpropagation are similar to those obtained from numerical differentiation, but are much faster. The method to find the gradient by error backpropagation is called gradient(self, x, t) and will be implemented in the next chapter, but it takes time to learn the neural network, so I want to save time. People should be proactive and use gradient(self, x, t) instead of numerical_gradient(self, x, t)!

[[[00000000000000000461---181589c3065a01b6608f7966591b8db66db8ae7f79b7d9311c70dd64eb2b75c1]]]Implementation of mini-batch learning

[[[00000000000000000462---654d8c3b5d782e856ba3e2754d72a9d743e1676f47b9dbb6fb71f969a86a97a5]]]The implementation of neural network training is done with mini-batch training, which was discussed earlier. In mini-batch learning, some data is randomly extracted from the training data—this is called a mini-batch—and parameters are updated using the gradient method for that mini-batch. Now, we will train the TwoLayerNet class using the MNIST dataset (the source code is in ch04/train_neuralnet.py).

[[[00000000000000000463---057f5701974280a65f5d6858e0b1bc6d80a54b46a196bab67f5868a3d591df22]]]# hyperparameters

[[[00000000000000000464---505105bbc23de1355c43437126b32ad2a1ff722ead0c99d4784f0691efcd9a2b]]]# get minibatch

[[[00000000000000000465---e68fc8c5c2f0902a04eae8f52cdc44ccec6dcf6996a8d2c59d1b00761b3114ad]]]# compute the gradient

[[[00000000000000000466---fb88a8ee208ae90ae69d838b628261efffa4d13306fcc8c653e805edcca18b83]]]# grad = network.gradient(x_batch, t_batch) # Fast version!

[[[00000000000000000467---38f43c19da8bdd7e5866eb1f7c6ecbd90942f9b37066fd1c3a57f64ff215bc8c]]]# update parameters

[[[00000000000000000468---7887cffe244b297cbdad280c38c2e07c19b2072d6c81dd60ba936c44a1ea8a8a]]]# Record your learning progress

[[[00000000000000000469---4eea3fdd3e24748f3973b6c5f12d91ee9c48b8ce7925dce6654e3f6e8eb1dc6a]]]Here, the mini-batch size is set to 100, and 100 data (image data and correct label data) are randomly extracted from 60,000 training data each time. Gradients are then obtained for those 100 mini-batches, and the parameters are updated using stochastic gradient descent (SGD). Here, the number of gradient method updates—the number of iterations—is set to 10,000. After each update, the loss function is calculated for the training data and added to the array. Figure 4-11 shows the changes in the value of this loss function in a graph.

[[[00000000000000000470---f6920ef3ce542f2c83303a3bbf19ecc97acafb2e167440a99217ec3f080bda9a]]]
Figure 4-11 Transition of loss function: Transition up to 10,000 iterations on the left, transition up to 1,000 iterations on the right


[[[00000000000000000471---109ceda07159cff705b4ef8c532572e1141b7d405623c7926f4f55fe4e045c24]]]Looking at Figure 4-11, we can see that the value of the loss function decreases as the number of learning times progresses. This is a sign that learning is going well and that the weight parameters of the neural network are gradually adapting to the data. It's just that the neural network is learning -- it's getting closer and closer to the optimal weight parameters by repeatedly bombarding it with data!

[[[00000000000000000472---d79c76fef17597d2d2abefba6010a2a562aa63e4dea9e370a203d69d8e8e4b44]]]Evaluate with test data

[[[00000000000000000473---1ac308e020ff8dc593686a355ed9821ebdbca183ae69c42230a6aaa0f2c29379]]]From the results in Figure 4-11, we were able to confirm that the value of the loss function gradually decreased as learning was repeated. However, the value of this loss function is precisely the value of the 'loss function for a mini-batch of training data'. A decrease in the value of the loss function in the training data is a sign that the neural network is learning well, but this result alone does not tell us whether it will perform as well on other datasets. not.

[[[00000000000000000474---0f2dc28c5d2f89279ad3a6075cfc75055cc6198f22b75c7ce19185a07edc6c7d]]]In learning a neural network, it is necessary to check whether it can correctly recognize data other than the training data—this is to check whether 'overfitting' has occurred. Overfitting means that, for example, only digit images included in the training data can be correctly discriminated, but digit images not included in the training data cannot be discriminated.

[[[00000000000000000475---e3b9a3887af52c64bf695d6884f5f632cdc395f2aab5f5d7dc9344f1df4833d2]]]In the first place, the goal of learning a neural network is to acquire the ability to generalize. Therefore, in order to evaluate the generalization ability of a neural network, we must evaluate it using data not included in the training data. Therefore, in the next implementation, we will periodically record the recognition accuracy for training data and test data during the learning process. Here, we record the recognition accuracy of training data and test data every 1 epoch.

[[[00000000000000000476---0cce1d137026d3905ab491e9c67962bd8cbe7757b983b8ba329b2ff9b3ac3a38]]]Epoch is a unit. One epoch corresponds to the number of times when all the training data is exhausted in learning. For example, if you train with 100 mini-batches on 10,000 training data, after 100 iterations of stochastic gradient descent, you have 'seen' all the training data. In this case, 100 times = 1 epoch.

[[[00000000000000000477---77fc75a827603209c73d26048708834795e323c5c07d83502a36b8ef628baf1a]]]So let's modify the previous implementation just a little bit so that we can get the evaluation right. The differences from the previous implementation are shown here in bold.

[[[00000000000000000478---057f5701974280a65f5d6858e0b1bc6d80a54b46a196bab67f5868a3d591df22]]]# hyperparameters

[[[00000000000000000479---20afb3f20ed7dafe5b604266d41ce18076ab246fc2face3c92592b7b0da7acd3]]]# number of iterations per epoch

[[[00000000000000000480---505105bbc23de1355c43437126b32ad2a1ff722ead0c99d4784f0691efcd9a2b]]]# get minibatch

[[[00000000000000000481---e68fc8c5c2f0902a04eae8f52cdc44ccec6dcf6996a8d2c59d1b00761b3114ad]]]# compute the gradient

[[[00000000000000000482---fb88a8ee208ae90ae69d838b628261efffa4d13306fcc8c653e805edcca18b83]]]# grad = network.gradient(x_batch, t_batch) # Fast version!

[[[00000000000000000483---38f43c19da8bdd7e5866eb1f7c6ecbd90942f9b37066fd1c3a57f64ff215bc8c]]]# update parameters

[[[00000000000000000484---b5bae2902d46652a15fa395650a04316553b12aa8db4dd1daff1933f5006b62c]]]# Calculate recognition accuracy every 1 epoch

[[[00000000000000000485---7eea255a576382c35aede7a45e644d44d72ab986d5885b8a6a36baa417655e22]]]In the above example, we calculate the recognition accuracy for all training and test data every epoch and record the results. The reason why the recognition accuracy is calculated for each epoch is that it takes time to constantly calculate the recognition accuracy in the repetition of the for statement. Also, there is no need to record the recognition accuracy at such a detailed frequency (it is sufficient to roughly understand the transition of the recognition accuracy from a broader perspective). Therefore, we record the progress of the recognition accuracy for each epoch of the training data.

[[[00000000000000000486---22344d0ddc58e522987632ae86657194502642bddf776afdd4fe3b62bf9e387c]]]Now let's plot the results obtained by the code above. The result should look like Figure 4-12 below.

[[[00000000000000000487---99d133fe6813c08fad5c04c981655cd4d6361a6103bde5b5d28b6322e66ecde6]]]
Figure 4-12 Changes in recognition accuracy for training data and test data. Horizontal axis is epoch


[[[00000000000000000488---239f0434879fada78d97e0a002581812cec7ae74d16cc3f9b5e8ab37bb953640]]]In Figure 4-12, the solid line indicates the recognition accuracy of the training data, and the dashed line indicates the recognition accuracy of the test data. As you can see, as the epoch progresses (as learning progresses), both the recognition accuracy evaluated using the training and test data improves. Also, you can see that there is no difference between the two recognition accuracies (the two lines almost overlap). Therefore, it can be seen that overfitting does not occur in this learning.

[[[00000000000000000489---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000000490---a8ec78509fd3db15cb2858bb2b748b41050e007c3456bf3bf12543b0de34345b]]]In this chapter, we explained the training of neural networks. First, we introduced a “metric” called a loss function to allow the neural network to learn. Using this loss function as a reference, the goal of neural network learning is to find the weight parameter that minimizes its value. Also, as a method for finding the value of the loss function that is as small as possible, I explained a method that uses the slope of the function, called the gradient method.

[[[00000000000000000491---19850c73ec605a12530fa271fcc972171b998181be314b2c4c58825fcf2e154b]]]What we learned in this chapter

[[[00000000000000000492---155001c53b9b9c3319a5d4b1b7c9e416c08830d0439020c5883585857f951234]]]Data sets used in machine learning are divided into training data and test data.

[[[00000000000000000493---3e5df3fb958a0d4bfbdf49a18c0aace6e908dac71f1c4bc252ab887b962f2467]]]It trains on training data and evaluates the generalization ability of the trained model on test data.

[[[00000000000000000494---b7908fcc80088ef8a2444e74fbf53798184c6c5be8627c77fdb9f0f24f7eed82]]]Learning of the neural network uses the loss function as an index and updates weighting parameters so that the value of the loss function becomes smaller.

[[[00000000000000000495---dedb97975ce3cea0dcc73b465427dd0694e352017d47fea04596800b69d6c72a]]]When updating the weight parameter, the gradient of the weight parameter is used to repeat the work of updating the weight value in the direction of the gradient.

[[[00000000000000000496---2138c6618a9b6f2e38dbd7b846c7ddd6695db1431016c084d4bbbbc516f0fbb7]]]Numerical differentiation is the process of obtaining differentiation from the difference when a very small value is given.

[[[00000000000000000497---e1291b21432b2f433f66662e33fd7a05351d2035a968ee13dc91e22f49ce0d21]]]A gradient of the weight parameter can be determined by numerical differentiation.

[[[00000000000000000498---d785031c771d7a6c79fbf28180d3e8849bd51cba83095dbe4bdd87e643b53e2c]]]Calculations by numerical differentiation are time consuming, but easy to implement. On the other hand, the somewhat complicated error backpropagation method implemented in the next chapter can find gradients at high speed.

[[[00000000000000000499---066c6a41a8ed489b43ec07285dc093bd8202eacf454506394df85a55c7652bd4]]]Appendix A

[[[00000000000000000500---e46de69c2bbb71993693e3a10bffa111238a4f88e932e00245eeb8607a446b69]]]Computation graph of softmax-with-loss layer

[[[00000000000000000501---3269f530b9622af6ca168944c6d717e666d8d6ee0f2e70208b3d91b0f86cc453]]]Here we present the computational graphs of the softmax function and the cross-entropy error, and find their backpropagation. The softmax function is called the Softmax layer, the cross entropy error is called the Cross Entropy Error layer, and the layer that combines the two is called the Softmax-with-Loss layer. Showing the results first, the Softmax-with-Loss layer can be written in a computational graph as shown in Figure A-1.

[[[00000000000000000502---338e9816d2485a9a07d19a92f5b8ced29047fe3913e80118bd31203b2659ed60]]]
Figure A-1 Computation graph of Softmax-with-Loss layer


[[[00000000000000000503---97bb0edef836d44791c74b937df5e18fb4bc132293ecfeaca234d85145114521]]]The computational graph in Figure A-1 assumes a neural network that performs 3-class classification. The input from the previous layer is (a1, a2, a3) and the softmax layer outputs (y1, y2, y3). Also, the teacher label is (t1, t2, t3) and the Cross Entropy Error layer outputs the loss L.

[[[00000000000000000504---66a3006b5cdb4db394787cc7ac1d342b470d82792cf58244e3204e459702f9f7]]]In this appendix, we show that the backpropagation result for the Softmax-with-Loss layer is (y1−t1, y2−t2, y3−t3), as shown in Figure A-1.

[[[00000000000000000505---a5183a3438de63a0b3ea55ba0745d1a9f88462a380d08b968e8add8975d6b7a5]]]forward propagation

[[[00000000000000000506---05a31e35269b5cb418f6025262549fda7fead7ffc880fa1d3ff19885220d2c14]]]The calculation graph in Figure A-1 omits the contents of the Softmax layer and the Cross Entropy Error layer. Here, I would like to start by drawing the contents of those two layers without omitting them.

[[[00000000000000000507---76c29f056470a7aa0b6951be8e62989a36f4ab1423c51c4f491bb3997c0f47db]]]First of all, the softmax layer, the softmax function is expressed by the following formula.

[[[00000000000000000508---36557b999310c1817c093734d966b4ce8182d7de3d89c8ffa6f20e849f750835]]]Formula (A.1)

[[[00000000000000000509---b9db1d337972f567956845c8068da798e823dc18da8cceeec276a2170e678c05]]]Therefore, the softmax layer can be expressed as a computational graph as shown in Figure A-2.

[[[00000000000000000510---eae306e167955f5c2dc89e5736b8afb255ad215fd4e058d75d9f06f1a9599cf2]]]
Figure A-2 Computation graph of Softmax layer (Forward propagation only)


[[[00000000000000000511---01554b71ce7dda876b47163da87d0637746a9258b9636f2aee4fa33c347ed812]]]In the computational graph of Figure A-2, the sum of the exponents—the denominator term in equation (A.1)—is abbreviated as S. Also, the final output is (y1, y2, y3).

[[[00000000000000000512---9c0f152fab2d97c9ef075cd2e2107e706952e95dd9bedf819f2951513cbba044]]]Next, let's talk about the Cross Entropy Error layer. The cross-entropy error is expressed mathematically as:

[[[00000000000000000513---ff456bf4a637f0f27d5208d389f99054c945553b8a9d1293d6ca0bf65414bb58]]]Formula (A.2)

[[[00000000000000000514---f7f01dc0917188b360018091729d7898ccfe5611d447066991198e467655c773]]]From equation (A.2), the computational graph of the Cross Entropy Error layer can be drawn as shown in Figure A-3.

[[[00000000000000000515---50e87365334a17098e6106feb54a55e1ad7926acf19d5c89fd5ebcb444dd4ee1]]]
Figure A-3 Computation graph of Cross Entropy Error layer (forward propagation only)


[[[00000000000000000516---6e529c080e31243f4ef1d5a053a8bc9f1bba7cc04f26b204879cba7e596e6760]]]The computational graph in Figure A-3 is a straightforward representation of Equation (A.2) as a computational graph. Therefore, I don't think there are any particular difficulties.

[[[00000000000000000517---cea91ee0f9b994beb80608d43708f8ef538386c20da45b94826dbb0e6e3b989c]]]Next, let's look at backpropagation.

[[[00000000000000000518---bed50c73a0b61f35d2ed856af57ab1c46fc7d057cc4148e82cc28a7246da2a9c]]]back propagation

[[[00000000000000000519---f40758b0c1ca0dde8641db0b9f50af784ea1a5e1dea9af244ef4b7929fb7eed9]]]Let's start with the backpropagation of the Cross Entropy Error layer. Backpropagation of the Cross Entropy Error layer can be depicted as in Figure A-4 below.

[[[00000000000000000520---00602ec58b964f372c23b6481b76f66b7b1bf10481aea89d1989bb1ea19571f2]]]
Figure A-4 Backpropagation of Cross-Entropy Error


[[[00000000000000000521---3faca5a8d340f053acf4645b38ef21314859f5a3863634791485e6f57bba4c06]]]When finding the backpropagation of this computational graph, be careful of the following points.

[[[00000000000000000522---be4c2a6e2fd99bf23f56a8ae1a1d716a4f748f39492bfa2acdb41b2197dc9bea]]]The first backpropagation value—the rightmost backpropagation value in Figure A-4—is (because) 1

[[[00000000000000000523---869f530a4ffa817e63f877c50b6adf65b7064cbf5e70e01467a930206bec2788]]]In the back propagation of the 'x' node, the value obtained by flipping the input value at the time of forward propagation is multiplied by the differential from the upstream and sent downstream

[[[00000000000000000524---3cd2952f3393ac9745c469787f01b0b5a31e599d6906ec70d97ce4feb7e1a1bd]]]At the '+' node, the derivative transmitted from the upstream flows as it is

[[[00000000000000000525---a2ebd7abeb726916369089cc8b464dd072043fd7f035d59320bdfa765cd574e7]]]Backpropagation of the 'log' node follows the formula

[[[00000000000000000526---43833f3594db76848b291cdc2d831f2b89987bb2ea53ba1c97183b1d5167a8bf]]]By following the above points, the backpropagation of the Cross Entropy Error layer can be obtained easily. The result is the input for backpropagation to the softmax layer.

[[[00000000000000000527---64974449e6ea8a94f9350be98e9cc72763a1e057171bfcf106064ad37237a3b9]]]Next, let's talk about backpropagation of the Softmax layer. Softmax layers are a little complicated, so I would like to proceed with backpropagation while checking them one by one.

[[[00000000000000000528---e93fe08e7ccbc4c3536f1e40a309957727c2390e68e17ab4e1e7af83654bbc1a]]]step 1

[[[00000000000000000529---5e9698f992e999c23e0d922e24d449f3eaf92f83401b4d43629b570a8a01899b]]]Backpropagation values flow from the previous layer (Cross Entropy Error layer).

[[[00000000000000000530---8e20d1d4524eac18dd0049c998d71cb63f6799bea0da7f697df3e314c6eb3e8f]]]step 2

[[[00000000000000000531---8a9fd44393a8b11f03ee066d5efc664ee4e021b5e69ba5a4631c1ebe86e91b0a]]]The 'x' node 'flips' the forward propagation values and multiplies them. Here the following calculations are made:

[[[00000000000000000532---b17c61eb958a8581aace84cae4666aca83058051060ce4fa69c3ffad734feedc]]]Formula (A.3)

[[[00000000000000000533---3201c4535a225da6767f4168a0dcc1e1993bb69c0dacf3cdf1cbbe8218953237]]]step 3

[[[00000000000000000534---2fdd24bf227e6d52a01f9e5a30dc67e97e8e42fdbba0de100e668291c2c11863]]]If multiple branches flow during forward propagation, their backpropagation values are added during backpropagation. So here the three branched backpropagation values (−t1S, −t2S, −t3S) are added. And since we backpropagate '/' to this added value, the result will be Also, here (t1, t2, t3) are the teacher labels, which is a 'one-hot vector'. A one-hot vector is one of (t1, t2, t3) is 1 and all others are 0. So the sum of (t1, t2, t3) is 1.

[[[00000000000000000535---6d409a808698085894c3bd2b364fab9e7b350f741174f1958f891db93247ab7e]]]step 4

[[[00000000000000000536---8629fdf95bc25de0370f35c338ad9fbeb06b1f316bbac523586e1fe17b529a58]]]The '+' node just flows as is.

[[[00000000000000000537---bb21644c2e1bfc0a2a05b13ac42c085dc01953ac15ef29b3953f2914d9da8f23]]]step 5

[[[00000000000000000538---b234e88a9ba37be6e0c18b4d7299001259b87eb217eca69e033c09a0bd239e82]]]The 'x' node is a 'flipped' multiplication. Here, when transforming the expression, is used.

[[[00000000000000000539---f44b31844f5238ae7d4c3db25aaf61db985a33a1927e11214e3dbf13855a6946]]]step 6

[[[00000000000000000540---f0e1fa37d43d12aa818730bda515fbd3d0939f246934b9f1c4c0371717dcc590]]]The 'exp' node has the following relational expression:

[[[00000000000000000541---dbbbc9a9413ab5c9b62adb53cde822a281f4ad3f68c48e01d4f3183cc69c656f]]]Formula (A.4)

[[[00000000000000000542---8618b8324bcf8411b5cbd90eb69d761e895bb854d83e06319517d650f5c27d56]]]From this, the sum of the two branched inputs multiplied by exp(a1) is the desired backpropagation. When written as a formula, it becomes y1−t1 when formatted. From the above, it is derived that the forward propagation is y1−t1 at the node with a1 as the input of the forward propagation. The remaining a2 and a3 can be obtained in the same way (results are y2−t2 and y3−t3, respectively). It is also easy to show that similar results can be obtained outside of the 3-class classification we are dealing with—for example, for n-class classification.

[[[00000000000000000543---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000000544---36d1aa4d821953adeca25ea8a16f0cc1ed4e968c0ed183d6aaee6acce488dbba]]]Here, the computational graph of the Softmax-with-Loss layer is shown without omission, and its backpropagation is obtained. If we draw the calculation graph of the Softmax-with-Loss layer without omitting it, it looks like Figure A-5.

[[[00000000000000000545---d2774bb257064473a8677bd6d028a665f48aae8a5c640572d7b303429127dc9b]]]
Figure A-5 Computation Graph of Softmax-with-Loss Layer


[[[00000000000000000546---72b89fc5593e0a030066dc258e0cd7c3d1ef2f7bb89bd0aa14b50a05600e3e9b]]]The computational graph in Figure A-5 looks complicated. However, finding the derivative (backpropagation procedure) would not have been such a difficult task if we proceeded while checking one by one using the computational graph. Besides the Softmax-with-Loss layer described here, if you come across layers that look complicated (such as the Batch Normalization layer), I encourage you to think in the same way as I did here. It's probably easier to understand than just chasing the formula.

[[[00000000000000000547---25776fc8b2e92d3d94c0cea93957def950b0a750b090f7c92cc11575b1ce6318]]]Chapter 2

[[[00000000000000000548---062778e6cd1eee78f464f7a925071f30e942f778a493dd222c3abbd8fb8d10a0]]]perceptron

[[[00000000000000000549---24f74f49a3adc3bd75893a49dc202df2cf0b227074d7094e8bd8c0e24dfb2889]]]This chapter describes an algorithm called the perceptron. Perceptron is an algorithm devised in 1957 by an American researcher named Rosenblatt. The reason why we are still learning about this old algorithm is that perceptron is also the origin of neural networks (deep learning). Therefore, learning how perceptrons work will also help you learn important ideas for advancing to neural networks and deep learning.

[[[00000000000000000550---79cda02944e0b6473675b5dc36cc8e469b29483e44d00e0e35f378f5a730ea7c]]]This chapter describes perceptrons and uses them to solve simple problems. We will familiarize you with Perceptron through the process.

[[[00000000000000000551---233aed36184207428891bbdbe38a646a1db75aafc1b4bab3b45cddfec176ac5b]]]What is Perceptron

[[[00000000000000000552---e689c470bafeabc1ca3d9cc65eb91d09474c8ec8d02cb538dcca335872ed7526]]]A perceptron†1 takes multiple signals as inputs and outputs a single signal. The 'signal' mentioned here should be imagined as something that has a 'flow' such as an electric current or a river. Just as an electric current flows through a wire, sending electrons forward, a perceptron signal creates a flow and carries information forward. However, unlike the actual current, the perceptron signal is a binary value of 'pass/do not pass (1 or 0)'. In this document, 0 corresponds to 'no signal' and 1 corresponds to 'signal'.

[[[00000000000000000553---81bf02ad6ad3756dacd038716300972fd994be4da17d4ea1ba9b723a7a254712]]][†1] The perceptrons described in this chapter are properly called 'artificial neurons' or 'simple perceptrons'. However, since the basic processing content is often common, we will simply refer to it as a 'perceptron' here.

[[[00000000000000000554---91e343f652b6d44ff19b03c9b3e776e7521f8119d02c8153124b8c83c7542eb2]]]
Figure 2-1 Two-input perceptron


[[[00000000000000000555---568333091f274f0515bbe62db921837a0821c10b50e5c86603ee5c0d0e7e732e]]]Now, Figure 2-1 shows an example perceptron that takes two signals as inputs. x1, x2 are input signals, y is output signals, w1, w2 are weights (w is an initial of weight). The circles in the figure are called 'neurons' or 'nodes.' Each input signal is multiplied by its own weight (w1x1, w2x2) as it is sent to the neuron. A neuron sums the signals it receives and outputs a 1 only when the sum exceeds some limit—sometimes called 'the neuron fires.' Here, the limit value is called the threshold and is represented by the symbol θ.

[[[00000000000000000556---21eb2454db9f8c11bb167e54d8dda528c158c245969f4881e227f0060c29903e]]]The working principle of the Perceptron is just that! The above can be expressed as formula (2.1) below.

[[[00000000000000000557---8ad93e0b71a543cf0e1067adbce4c6466ca29dc95f06f33be85478845dc0ef21]]]Equation (2.1)

[[[00000000000000000558---815bb25bc82d7232e3f7c8617101465c7fa33f2cf3e9e537d368a9df6397f3bb]]]A perceptron has unique weights for each of its multiple input signals. The weight then acts as a factor controlling the importance of each signal. That is, the higher the weight, the more important the signal corresponding to that weight.

[[[00000000000000000559---6f861b62e4ecf3dee2a8245472c0b2a9483dbf9f5446cd1ac7febc99d7482cb0]]]The weight corresponds to 'resistance' in terms of current. Resistance is a parameter that determines how difficult it is for current to flow. The lower the resistance, the larger the current that flows. Perceptron weights, on the other hand, mean that the greater the value, the greater the signal flow. Both resistance and weight work the same in that they control the difficulty of signal flow (ease of flow).

[[[00000000000000000560---b94ea8701705066871c3eacce9584a19c59f469ad8d328670ead785aacf9b20b]]]simple logic circuit

[[[00000000000000000561---5de0d8e0e15a31fad3845adcfd2720aedc88991ff22f1411314b5be306aacfb5]]]AND gate

[[[00000000000000000562---b948d731ff40fcd2f4101e9d8fec47fac9cdde9b9678b8fb730ac9d342143b4d]]]Now let's consider a simple problem using perceptrons. Here, I would like to take logic circuits as a subject and first consider AND gates. An AND gate is a gate with two inputs and one output. The correspondence table between the input signal and the output signal as shown in Figure 2-2 is called the 'truth table', and as shown in Figure 2-2, the AND gate outputs 1 only when the two inputs are 1. and output 0 otherwise.

[[[00000000000000000563---86943d1816466535ad4f5ffeced902d12cd8343ffa6b43a25fd5b9367327c949]]]
Figure 2-2 AND Gate Truth Table


[[[00000000000000000564---7dec7d7d6df9685282f9da374cc07c6f92ceaa2ff2624da173632a4a6394c107]]]Now, I would like to express this AND gate with a perceptron. The task here is to determine the values of w1, w2, and θ so as to satisfy the truth table in Figure 2-2. Then, what values should be set to create a perceptron that satisfies the conditions in Figure 2-2?

[[[00000000000000000565---bb522ef7deea2f63549e4ba6e114fb47b81a3bfb28515780fcd765eaa1f3b809]]]In fact, there are an infinite number of ways to select parameters that satisfy Figure 2-2. For example, when , it behaves as shown in Figure 2-2. In addition, (0.5, 0.5, 0.8) and (1.0, 1.0, 1.0) also satisfy the AND gate conditions. With such parameters, the sum of the weighted signals exceeds the given threshold θ only when both x1 and x2 are 1.

[[[00000000000000000566---9d2077a483711fed87f6a7fae3e6089c3d7cf6fbdb863f6aef143cb2b76283c1]]]NAND gate and OR gate

[[[00000000000000000567---07f768ef5a84733133bdc1cebdc9572052b354801e461ab6bf441288cd88c046]]]Next, let's consider a NAND gate. NAND stands for Not AND, and its behavior is the inverse of the output of an AND gate. Expressed as a truth table, it outputs 0 only when both x1 and x2 are 1, and outputs 1 otherwise, as shown in Figure 2-3 below. Then, what combinations of NAND gate parameters are possible?

[[[00000000000000000568---28c487e40c647fdbbd6b8badff081418f5031eb54beb8d39eac5b41fbf30cf7c]]]
Figure 2-3 NAND Gate Truth Table


[[[00000000000000000569---25a993911c8a3d74f9bdd51744fab77e59045b23c5b92f79cc3569aa8ae652a1]]]To represent a NAND gate, there are, for example, combinations of (there are an infinite number of other combinations). In fact, you can also implement a NAND gate by simply inverting all the signs of the parameter values that implement the AND gate.

[[[00000000000000000570---cf9e922da91e114a6e6cb53199e9260901451f9e65739def1a91fb2697e8fa19]]]
Figure 2-4 OR Gate Truth Table


[[[00000000000000000571---30ef20461b6ef74bb67e7bcdc130ecb3aad158e050aee5231a74449b05640c4b]]]Along the same lines, consider the OR gate in Figure 2-4. An OR gate is a logic circuit whose output is 1 if at least one of the input signals is 1. What parameters should be set for this OR gate? please think about it.

[[[00000000000000000572---4ac42117b7735be5c2cf65b0b5af76dad12d474b0e152da287a09d109deffeec]]]Here, we humans, not computers, determine the parameters of the perceptron. While looking at the 'learning data' called the truth table, I thought about the parameter values by hand (I came up with it). For machine learning problems, let the computer automatically do the work of determining the value of this parameter. Learning is the task of determining appropriate parameters, and the work performed by humans is to consider the structure (model) of the perceptron and provide learning data to the computer.

[[[00000000000000000573---305c7e969d04fac4fe959339fb5839dcb695af9a23220074c693650d4a2a4ee3]]]As described above, we have learned that we can express logic circuits such as AND, NAND, and OR by using perceptrons. The important point here is that the perceptron structure is the same for all AND, NAND, and OR gates. In fact, the only difference between the three gates was the parameter (weight and threshold) values. In other words, the same structural perceptron can be transformed into AND, NAND, and OR, just like a chameleon actor playing different characters, simply by adjusting the values of the parameters appropriately.

[[[00000000000000000574---f728bc3b7047c7e1986e8919c23e8fc443f8940436ababc96a95aa3a3309f924]]]Perceptron implementation

[[[00000000000000000575---107144230324c8e764ea5335a4b913b00d78c85d1bd2f00f51babc95d35d255c]]]easy implementation

[[[00000000000000000576---2de8d2dea8f6802dac86266abd4cef16fa999e8e0fc940ffa14285880c188d20]]]Now, let's implement the previous logic circuit in Python. Here we define a function called AND that takes x1 and x2 as arguments.

[[[00000000000000000577---ae177df9f51a72c3d921764242103f8805564f587f2d94caba7889a7a34fe293]]]The parameters w1, w2, and theta are initialized within the function, returning 1 if the sum of the weighted inputs exceeds the threshold, and 0 otherwise. Let's check if the output is as shown in Figure 2-2.

[[[00000000000000000578---9bff8cf22cfddf7ecd1eb646ee2c04349681639a2326b64af32194259bf5e7a6]]]AND(0, 0) # outputs 0 AND(1, 0) # outputs 0 AND(0, 1) # outputs 0 AND(1, 1) # outputs 1


[[[00000000000000000579---31678bb4f11d070892be028a4c9e70e044e356e8feb61902ed03aa64b5b0ee13]]]The output is as expected! Now we can implement the AND gate. NAND gates and OR gates can also be implemented in a similar way, but here I would like to tweak this implementation a little.

[[[00000000000000000580---2cc0f6c5b652d58e274a1dcb66dd0ac003e9fc804c9516df4ace3e051606ec03]]]Introducing weights and biases

[[[00000000000000000581---588b4f37d45a6cb72a61fb9ed13c0cb3d8e2cd768702918d88694db3b48fe5e1]]]The implementation of the previous AND gate is straightforward and easy to understand, but considering the future, I would like to modify it to a different implementation method. Prior to that, the operation of the perceptron is expressed by the following equation (2.2), with θ in equation (2.1) set to −b.

[[[00000000000000000582---d5c0e3d20bb61fce8f75d0e7854f50c77c344b1b6266e972537d0e7d4ff67221]]]Equation (2.2)

[[[00000000000000000583---184d18e4331d46c7a6155cd2002a4c9bb54822670c36146d039fbc2463515bad]]]Equations (2.1) and (2.2) express exactly the same thing, just by changing the notation of symbols. Here b is called bias and w1 and w2 are called weights. As shown in equation (2.2), the perceptron calculates the sum of the input signal multiplied by the weight and the bias, and outputs 1 if the value is greater than 0, and 0 otherwise. To do. Now, let's use NumPy to implement the method of formula (2.2). Here, we will proceed while checking the results one by one with the Python interpreter.

[[[00000000000000000584---113e4520494c46cb1c9f20eee37a534ddeb2beb1f91e60c22916aa6cc04ceed7]]]     # enter >>> 

[[[00000000000000000585---8853c3290e949215bba03b2b78f80ac8acffb5ad0576326bf07e6e710ae3e98e]]] # weight >>> 

[[[00000000000000000586---8e74c89dceb87a05046dca0aba62ba6b9a886fd9fa5f6b5334be98f31edf2246]]]                 # Bias >>> 

[[[00000000000000000587---827e00ffde0464cd609b3293f6d772a053b4a5d552c7daaa778c26d3266ded39]]]
-0.19999999999999996 # about -0.2 (calculation error due to floating point numbers)


[[[00000000000000000588---8f445e628b3d9ed5e41ff6aee4993ac8d45718d2fae4d13239b230fd0eb5e718]]]As shown in this example, NumPy array multiplication multiplies the elements of two arrays if they have the same number of elements. So computing w*x would result in computing the multiplication of each element ( [0, 1] * [0.5, 0.5] => [0, 0.5] ). Also, np.sum(w*x) calculates the sum of each element. Adding the bias to this weighted sum completes the calculation of equation (2.2).

[[[00000000000000000589---f7db7617524470c1672f050e0147758757c0373dd8ba6947dfd39a9e9b502bb9]]]Implementation with weights and biases

[[[00000000000000000590---e0302aa455e7e7739b0acc9868488f0cf74c1596f53b85d8ba8d1248744c245e]]]Using the weight-and-bias scheme, an AND gate can be implemented as follows:

[[[00000000000000000591---ab57f9787514eb4a6df993a59e65997c1deb9e5ef6e6c1888949f238bdaa8e9a]]]We've named −θ the bias b here, but note that the bias works differently than the weights w1 and w2. Specifically, w1 and w2 function as parameters that control the importance of the input signal, while bias is a parameter that adjusts the ease of firing—the degree to which the output signal outputs 1. Works. For example, if b is −0.1, the neuron fires only when the weighted sum of the input signals exceeds 0.1. But if b is −20.0, the neuron will not fire unless the weighted sum of the input signals exceeds 20.0. Thus, the bias value determines how easily a neuron fires. Note that w1 and w2 are called 'weights' and b is distinguished from 'bias', but depending on the context, all parameters b, w1, and w2 are sometimes called 'weights'.

[[[00000000000000000592---d5f2ac62d45ca5f60e464558a2c0590ba1fecff98c8b7af723f5c6f01a07cf30]]]The term bias has the meaning of 'getting out'. This means how much to put on the output when there is no input (when the input is 0). In fact, the calculation of (2.2) outputs only the bias values when the inputs x1 and x2 are 0.

[[[00000000000000000593---ed9491e0d8dcf2d7e3645cff2b6913d9d3fbcc47e89ea47f7e18f178ea2af4a0]]]Now let's continue to implement the NAND and OR gates.

[[[00000000000000000594---2d5b0debc182429e35b752cb9d96994c51d5307045b05d1e76815ab94ce748b1]]]# Only weights and biases are different from AND!

[[[00000000000000000595---2d5b0debc182429e35b752cb9d96994c51d5307045b05d1e76815ab94ce748b1]]]# Only weights and biases are different from AND!

[[[00000000000000000596---b3c3b19c77f7b504095f8eed5168160eb758cce0c98c5bc4f5b02f4c0fe55132]]]As explained in the previous section, AND, NAND, and OR are perceptrons with the same structure, differing only in the weight parameter values. Even in the implementation of NAND and OR gates, the only difference from AND is where the weight and bias values are set.

[[[00000000000000000597---ec9daa39581e935e8842184611927ace4be5a88f7c760321e842be6bc05b712e]]]limit of perceptron

[[[00000000000000000598---ee2f3beae3b95364d35b9543e81ab36e974505f1bca6974b0d4ae0d4e11a3c50]]]As we have seen, perceptrons could be used to implement three logic circuits: AND, NAND, and OR. Next, I would like to think about the XOR gate.

[[[00000000000000000599---0bc59cf9ab46ab51c2560fbc5a9a69579b07e304faefcf3ad22fc1a93c864b72]]]XOR gate

[[[00000000000000000600---b0c7af295a0f763323c3a615469aacd66ca8977b08abc3e62886dbdf9f0c570b]]]An XOR gate is a logic circuit, also called an exclusive OR. As shown in Figure 2-5, the output is 1 only when either x1 or x2 is 1 ('exclusive' means denying anyone but yourself). Now, what weight parameters should we set to implement this XOR gate with a perceptron?

[[[00000000000000000601---df34a01a342487ce0d7f91b7d3a63f9ad0ca4a9e7f44248f8906c9bc19c134cf]]]
Figure 2-5 Truth Table for XOR Gate


[[[00000000000000000602---25be65c7af9535d6427f3ff40e64089e2bee61b52464caf900eb6a56aa3d0354]]]In fact, the perceptrons we have seen so far cannot implement this XOR gate. Why can AND and OR be realized, but not XOR? In order to explain it, I would like to draw a diagram and think visually.

[[[00000000000000000603---9e3470202a79a166d1d03952b3cf905b28c195f69ef01a1df5124820ac8a389e]]]First, let's visually consider the behavior of an OR gate. An OR gate, for example, satisfies the truth table in Figure 2-4 when the weight parameters are (b, w1, w2) = (−0.5, 1.0, 1.0). At this time, the perceptron is expressed by the following equation (2.3).

[[[00000000000000000604---15467d4c33924090159b5990bef9d465f8fdca2dd0a882148dab7feabc9b915a]]]Equation (2.3)

[[[00000000000000000605---b37ff1b57dec1d1e63a916cb90a056e483c44d3213e17b29e102ddd271f4191d]]]The perceptron represented by equation (2.3) creates two regions separated by a straight line. One region separated by a straight line outputs 1, the other outputs 0. A graphical representation of this is shown in Figure 2-6.

[[[00000000000000000606---792f5e618f49e395bf93ec8a2401f9fc344afa1dfa78311f7a04af294c670e04]]]
Figure 2-6 Perceptron Visualization: The gray area is the area where the perceptron outputs 0, and this area satisfies the properties of the OR gate


[[[00000000000000000607---f0c65a33d88d4c6aef2282b20845d95aba52e0dd57661af6bf5ff1e42cc8b611]]]The OR gate outputs 0 when (x1, x2) = (0, 0) and outputs 1 when (0, 1), (1, 0), (1, 1). In the figure, 0 is indicated by ○ and 1 is indicated by △. If you want to make an OR gate, you need to separate ○ and △ in Figure 2-6 by a straight line. In fact, the straight line above correctly divides the four points.

[[[00000000000000000608---6895182c14eee3db071234703bbe3f0733d7c483561cb1fca20cf02f3e0cf652]]]So what about XOR gates? Is it possible to create an area that separates ○ and △ by a single straight line, as in the OR gate?

[[[00000000000000000609---d515adfd5d1200ecdf5ab3247648a2c63742409a51fa2d1d23b0ebab814f81af]]]
Figure 2-7 ○ and △ represent the output of the XOR gate. Is it possible to create an area that separates ○ and △ by a straight line?


[[[00000000000000000610---97b29f0f1343e4362653b62cbb3023b437ba95f21411e7746eda71f1bfe8ec97]]]No matter how much you think about it, it is impossible to divide the circles and triangles in Figure 2-7 by a straight line. In fact, one straight line cannot separate ○ and △.

[[[00000000000000000611---64b11f3e0af6d68ceab99c8df5d25dcc92a68543c2fd8a6190d42c2aa4c60979]]]linear and nonlinear

[[[00000000000000000612---66ad1c4557c36842dfc7a5640eb955cf004332df59f7af61367bb578f5c47ddb]]]○ and △ in Figure 2-7 cannot be separated by a single straight line. However, if we can remove the constraint of 'straight line', we can separate ○ and △. For example, you can create an area that separates ○ and △ as shown in Figure 2-8.

[[[00000000000000000613---9702aaa85ac8827d212d5cb53d9f4ac1dfc1960e5a69c215b4ba1a4dd12558f0]]]
Figure 2-8 If it is a curve, ○ and △ can be separated


[[[00000000000000000614---10d115343e5f30e0b5199ddf0ba7052022bb2f8a86db1c95ad63b00ef1c38069]]]The limitation of the perceptron is that it can only represent the area divided by one straight line like this. A perceptron cannot express a tight curve like Figure 2-8. By the way, a curved area like the one in Figure 2-8 is called a non-linear area, and a straight line area is called a linear area. The terms linear and non-linear are often heard in the field of machine learning, but you can imagine things like Figures 2-6 and 2-8.

[[[00000000000000000615---c3eb1e97d8c2c4a0d508fd2630cd003f73c274db035219314cdb7f398e391d1b]]]multilayer perceptron

[[[00000000000000000616---066002fd44dc2640b51823039de28dad5e49b350853aa9710035d516ff5a6360]]]Unfortunately, perceptrons could not represent XOR gates. But that's not sad news. In fact, the beauty of perceptrons is that they can be “layered” (the story of this section is that XOR can be expressed by stacking layers). I would like to put aside the explanation of what is meant by 'layering' here, and consider the problem of XOR gates from a different perspective.

[[[00000000000000000617---35f4e28e748a7df54d19c01dfec1e33f79b5e8191ee89c1ee6d572be2722772c]]]Combination of existing gates

[[[00000000000000000618---4253b9d35c3bc45e229c5bf91b4ae5972d89ec5bbb1e76885bed44d70dcd1255]]]Well, there are several ways to make an XOR gate. One way is to wire up a combination of the AND, NAND, and OR gates we've built so far. Here, AND, NAND, and OR gates are represented by the symbols in Figure 2-9. By the way, the circle at the tip of the NAND gate in Figure 2-9 means that the output is inverted.

[[[00000000000000000619---cf2f9bc72c05c8dad18911d77445eb8a60233abadaeb29b30faab62963b42049]]]
Figure 2-9 Symbols for AND, NAND, and OR Gates


[[[00000000000000000620---ffe5bf93a2731776f4718f0a378aaea607143ab08601d7ca7f35012206b2a075]]]So how do we wire AND, NAND and OR to make an XOR gate? Let's think for a moment. Hint: You can substitute AND, NAND, or OR for each '?' in Figure 2-10 to complete the XOR.

[[[00000000000000000621---6a6d3a2a0c6aa202e99f7aa36c433a948d457023840e106cc1a2b794e05a182e]]]
Figure 2-10 Insert an AND, NAND, or OR gate into the '?' to complete the XOR!


[[[00000000000000000622---a53d02e546a639d4ae9186ea302f2e9f2e901f3ee8b579e725e4b1b6071d30e7]]]The limitations of perceptrons mentioned in the previous section are, to be precise, 'single-layer perceptrons cannot represent XOR gates' or 'single-layer perceptrons cannot separate nonlinear regions'. We will now see how perceptrons can be combined (by stacking layers) to realize an XOR gate.

[[[00000000000000000623---ab2649b7c87250eeab0cea531bde50bc8a88cc1937b35fba118cf7e6ba268ce1]]]An XOR gate can be realized with the wiring shown in Figure 2-11. Here x1 and x2 represent the input signals and y represents the output signal. x1 and x2 are the inputs to the NAND and OR gates, and the outputs of the NAND and OR are the inputs to the AND gate.

[[[00000000000000000624---1c1423a7b0dd4f483060f1e32350bdf4c4afded7b1d09856d4b01dbf0bcfb557]]]
Figure 2-11 Implementing an XOR gate by combining AND, NAND, and OR gates


[[[00000000000000000625---a368346ad769fabcbcd974b1badcf8c69ec7fc83fcb8562275dc092001e8e1a5]]]Now, let's check if the wiring in Figure 2-11 really achieves XOR. Let's fill in the truth table with NAND output as s1 and OR output as s2. The result should look like Figure 2-12. Focusing on x1, x2, and y, it is certainly the output of XOR.

[[[00000000000000000626---dc4a73e3bb2ac1c03821c6c92b8f0a5a742e8cf910ab7dd309e9d26597aa11cb]]]
Figure 2-12 Truth Table for XOR Gate


[[[00000000000000000627---170e4b50dd62e4587f1230113960935ab3f01e0d5f14477bfa969f2b825928e3]]]XOR gate implementation

[[[00000000000000000628---84ababbc372653354cb27ffbcb598673f97f5c3f7dda8d854b77f45466a6931f]]]Next, let's implement the XOR gate represented by the wiring in Figure 2-11 in Python. With the functions AND, NAND, and OR defined so far, we can (easily!) implement them like this:

[[[00000000000000000629---ce434e4de4146d962989f7da5fbf3e39374ac57cf4da0b984ad094d2a231f594]]]This XOR function outputs the expected result.

[[[00000000000000000630---906c66b1ea1f69fd135c729143ce9350021531d82495e66ea4a82d42c5853c65]]]XOR(0, 0) # outputs 0 XOR(1, 0) # outputs 1 XOR(0, 1) # outputs 1 XOR(1, 1) # outputs 0


[[[00000000000000000631---8d22016883e08940fc331cc0f847643e4147ac00098bedab4f0e9f684ef5bc98]]]We have now completed the XOR gate. Now let's express the XOR we just implemented in terms of perceptrons (with the neurons explicitly shown). Then it will look like Figure 2-13.

[[[00000000000000000632---cb3d3ebae23224e748a8ab75d0b2677340eac3ad1dbdb01d420d561e4036f055]]]
Figure 2-13 Perceptron Notation for XOR


[[[00000000000000000633---2d559d086521b81a06075bd35c08d72d6fe4e08ec02f281bdefc64918b7f9f6f]]]XOR is a multi-layered network as shown in Figure 2-13. Here, let's call the leftmost layer the 0th layer, the rightmost layer the 1st layer, and the rightmost layer the 2nd layer.

[[[00000000000000000634---54b5772e326de16a8ab9375e4843d140929ff5dad9477e4b2f5c9e3b91dc28fe]]]Now, the perceptron in Figure 2-13 has a different shape than the AND and OR perceptrons (Figure 2-1) we've seen so far. In fact, XOR is a two-layer perceptron, whereas AND and OR are single-layer perceptrons. By the way, a perceptron with multiple layers is sometimes called a multi-layered perceptron.

[[[00000000000000000635---8a008549aaa020edb74e46f7007fb33dc172d32ba647b28bd24e24d915b48f02]]]The perceptron in Figure 2-13 consists of three layers in total, but there are actually two layers with weights (between the 0th and 1st layers, and between the 1st and 2nd layers), so ' Let's call it a two-layer perceptron. In some literature, the perceptron in Figure 2-13 is called a 'three-layer perceptron' because it consists of three layers.

[[[00000000000000000636---7a20c5d52aa2841ac79caf3373f77e94edd284979ca009d33a75793ea14fc165]]]In a two-layer perceptron, as shown in Figure 2-13, signals are sent and received between neurons in layers 0 and 1, followed by signals in layers 1 and 2. will be split. A more detailed description of this behavior is as follows.

[[[00000000000000000637---d54bde88850712e7a092772d693f02dedffc7de355dbc3802900ff1e2d2d0199]]]Two neurons in layer 0 receive input signals and send signals to neurons in layer 1

[[[00000000000000000638---095c0642c31d0395957c7f5f74102d6771fe76362db31de22be1afc5c555376c]]]1st layer neuron sends signal to 2nd layer neuron, 2nd layer neuron outputs y

[[[00000000000000000639---0c464bc50a9627308d421185a4c0d1e9ae4e17271db9dd2930416a6fb17afe58]]]By the way, the operation of this two-layered perceptron can be compared to the assembly work of a pipeline. Workers in the first stage (first layer) modify the 'parts' that flow in, and when their work is completed, they hand over the parts to workers in the second stage (second layer). The 2nd layer worker modifies the 'parts' handed over from the 1st layer worker, completes the parts, and ships (outputs) them.

[[[00000000000000000640---bd41cbd42ff43f846ca48d35b2ab4fd91b99a9d98a858b08e08321ef3c514369]]]In this way, in the XOR gate perceptron, 'parts are handed over' between workers. By making such a structure (two-layer structure), the perceptron can realize an XOR gate. This can be interpreted as 'what could not be expressed with a single-layer perceptron can now be realized by adding one layer.' In other words, it can be said that the perceptron has become possible to express more flexibly by stacking layers (deepening the layers).

[[[00000000000000000641---7568ba3c141a097642dcbf373fb1b8ccaedbd9bb17e2d6d867c115ce94781a14]]]NAND to computer

[[[00000000000000000642---0303a446e9f5d32aa01b351e340b30d0374c349dfb55d20203052492ffa9dd20]]]Multilayer perceptrons can create more complex circuits than we have seen so far. For example, perceptrons can be used to create adders for addition. Encoders that convert binary numbers to decimal numbers and circuits that output 1 when certain conditions are met (circuits for parity checks) can also be represented by perceptrons. And, as a matter of fact, a “computer” can be expressed using a perceptron!

[[[00000000000000000643---72baa456d11b4883bbd0a873a75529aefe90142396c2eed738576fef038347ab]]]By the way, a computer is a machine that processes information. If you give a computer some input, it will process it in a certain way and output the result. Processing according to a fixed method means that computers have inputs and outputs in the same way as perceptrons, and perform calculations according to fixed rules.

[[[00000000000000000644---4f25d7d1f813e9a27af7e918a5db3db257ebd4362ee284d343cc80a738e8501c]]]It may seem that a computer performs very complicated processing inside, but in fact (you may be surprised) you can reproduce the processing performed by a computer simply by combining NAND gates. What does the amazing fact that you can build a computer out of NAND gates mean? Because, as we have seen, NAND gates could be made with perceptrons. In other words, if a computer can be created by combining NAND gates, it is possible to express a computer by combining perceptrons alone (a combination of perceptrons consists of multiple layers of single can be expressed as a perceptron of ).

[[[00000000000000000645---2ee17c3f3bd6241003c2d90dd16b9403362668723533a63f56e53024747911b0]]]When I say that a computer can be made from only a combination of NAND gates, you may not believe it. If you are interested in this point, I recommend the book 'Theory and Implementation of Computer Systems: How to Make a Modern Computer' (O'Reilly Japan). The theme of this book is to gain a deep understanding of computers, and under the slogan 'From NAND to Tetris,' we will create a computer that actually runs Tetris from NAND. If you read this book, you will be able to realize that a complex system such as a computer can be created from only a simple element called NAND.

[[[00000000000000000646---624014c169549fe55346a3375f91c8327cf5736bd243d9cbe2d6ad25d871593b]]]In this way, multi-layered perceptrons are capable of complex expressions that even computers can create. Then, what kind of perceptron structure can represent a computer? How many layers must be added to build a computer?

[[[00000000000000000647---d4afe12b3e31adf6d9a44135f1817b778c955b475d491951211506e8daab795b]]]The answer to this question is that, in theory, you can build a computer with two layers of perceptrons. This is because it has been proven that arbitrary functions can be represented by using a two-layer perceptron (more precisely, one that uses a nonlinear sigmoid function as the activation function; see the next chapter for details). . However, building a computer with a two-layer perceptron structure and appropriate weights would be a very difficult task. When actually building a computer starting from low-level elements such as NAND, the natural way to do it is to build up the necessary parts (modules) step by step--first AND and OR gates, then Half adders and full adders, then arithmetic logic units (ALUs), then CPUs, and so on. For this reason, it is natural for perceptron-based computers to be created as a structure with many layers.

[[[00000000000000000648---8b3fd963ecbbdba0979461f3540ddc128877f1883f03ddb4dfe28aed03fd9ddc]]]In this book, we won't actually build a computer, but keep in mind that perceptrons can be layered to create non-linear expressions, and in principle (theoretically) they can also express the processing that computers do. prize.

[[[00000000000000000649---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000000650---dc7ed7cb7e67313fc120d38e291464226064a6440faa80d93ae3944dd5b6eb37]]]In this chapter you learned about perceptrons. The perceptron is a very simple algorithm, so you should have quickly understood how it works. This perceptron will be the basis for the neural networks we will learn in the next chapter. That is why what we have learned in this chapter is so important.

[[[00000000000000000651---19850c73ec605a12530fa271fcc972171b998181be314b2c4c58825fcf2e154b]]]What we learned in this chapter

[[[00000000000000000652---96003743d624717fce478f39b0103ef2178a8d82a7c66e797b65cc6c12f38886]]]A perceptron is an algorithm with inputs and outputs. Given an input, it will output a certain value.

[[[00000000000000000653---396b036e9c789499e1931792b945d70036b49540e6047d1cc3dd60d42b721475]]]In the perceptron, 'weight' and 'bias' are set as parameters.

[[[00000000000000000654---a992e831ea7d9daf9e22d912333306781d00ee4e9d31664f755457b50c7299f6]]]A perceptron can be used to express logic circuits such as AND and OR gates.

[[[00000000000000000655---364f5b2ff1098c7dbbd8864ce2e776a3af0fca2337c5108ed8f6b8ccb2a46630]]]An XOR gate cannot be represented by a single-layer perceptron.

[[[00000000000000000656---d541c4deea6a830a21c220a5b06e90637176fc5c17364c2e0f07e3226ac46303]]]Using two layers of perceptrons, we can express an XOR gate.

[[[00000000000000000657---b7654d39b802d8be87e042cc09b531547014cdbe16702a19081a306a3a658d70]]]Single-layer perceptrons can only represent linear regions, while multi-layer perceptrons can represent nonlinear regions.

[[[00000000000000000658---8f435da2bf7237f49d130de53cbab46b560b5707ed2e8f9e8295e19c34b5b9c6]]]A multilayer perceptron can (in theory) represent a computer.

[[[00000000000000000659---e1b3e6d1018f3a48202006d7c1ead9d579ea3a5c56d5bfae576ac16e118d237b]]]Chapter 5

[[[00000000000000000660---7a252faced62c16768ec1f444ae935b393a9d70a5b5bb876ebf54093f4eb429b]]]Backpropagation method

[[[00000000000000000661---026d3cb5a63624bc38995f911fae60c7cc006bb37af130f91615a14621a86837]]]In the previous chapter, we explained the training of neural networks. At that time, the gradient of the weight parameter of the neural network—more precisely, the gradient of the loss function with respect to the weight parameter—was obtained by numerical differentiation. Numerical differentiation is simple and easy to implement, but has the disadvantage of being computationally time-consuming. In this chapter, we will learn about the 'backpropagation method', which is a method for efficiently calculating gradients of weight parameters.

[[[00000000000000000662---93f898d9411c46b250e357b8b11c6d64aac114f9e74aca66b4ad406c98897275]]]I (personally) think there are two ways to get backpropagation right. One is to understand by 'formula' and the other is to understand by 'computational graph'. The former is the more common method, especially when many books on machine learning revolve around math. It is true that explanations using mathematical formulas are rigorous and concise, so it is a reasonable method. there is. Therefore, in this chapter, I would like you to understand the error backpropagation method 'visually' by using computational graphs. By actually writing the code, I think you will be able to understand it even more and be convinced that 'I see!'

[[[00000000000000000663---4ff3aac719f2753cc4b74f6abb9e2dafd06d5577b0b97c1f49adf64ab5b29cd3]]]The idea of explaining the error backpropagation method using a computational graph can be found in Andrej Karpathy's blog [4], and in the deep learning class 'CS231n' at Stanford University conducted by him and Professor Fei-Fei Li [5]. is used as a reference.

[[[00000000000000000664---f71c94f8c8345630d65d48dad020ef878815b61f35855ce7699e3412e00bc47b]]]calculation graph

[[[00000000000000000665---860f4d4886537ad819666a48c02f3e7b9bc6ea4469be0231db32ca02d35b9e60]]]A computational graph is a graphical representation of the process of computation. The graph here is a graph as a data structure, represented by multiple nodes and edges (straight lines connecting nodes are called 'edges'). In this section, we will solve some simple problems to familiarize ourselves with computational graphs. We will start with a simple problem and proceed step by step until we arrive at backpropagation.

[[[00000000000000000666---e23967b0aabedf30e2d69c80473a9861dfe94d47034b02460f382321a1697955]]]Solve with Computational Graph

[[[00000000000000000667---453b8403cb0f66da0e970d2d222f247b02c838642462b9e052c6a0d0fe69e84f]]]Now, let's solve a simple problem using 'Computational Graph'. The problems we are going to see are so easy that you can solve them with mental arithmetic, but the goal here is to familiarize yourself with computational graphs. If you learn how to use computational graphs, they will show their power in the complicated calculations that you will see later, so please learn how to use computational graphs here.

[[[00000000000000000668---7ba4684da1b66d85cb8417cd75b3d36b2904260f9f3ef8dafeaaca7f476a7f37]]]Question 1: Taro bought two apples at the supermarket for 100 yen each. Ask for the amount to be paid. However, 10% consumption tax shall be applied.

[[[00000000000000000669---9b64e404f0dc0226ebba6f1f5d68e385f706b32de8aabd941fa465c71c8c6b0d]]]A computation graph represents the process of computation with nodes and arrows. Nodes are indicated by ○, and the contents of operations are written in ○. In addition, by writing the intermediate result of the calculation above the arrow, the calculation result for each node is expressed from left to right. Solving Question 1 using a computational graph results in Figure 5-1.

[[[00000000000000000670---7eac3dd911c8a6cafc43d15a01ce30b3db0fbadf1988875c42e17992a18d9f20]]]
Figure 5-1 Answer to Question 1 with Computational Graph


[[[00000000000000000671---5b1308d5ca4b08f59a5900a90e621eec2af349f68ff968e66c0f34e310211965]]]As shown in Figure 5-1, the apple's 100 yen first flows to the 'x2' node, and then 200 yen is propagated to the next node. Subsequently, the 200 yen flows to the 'x1.1' node and becomes 220 yen. Therefore, from the result of this calculation graph, the answer is 220 yen.

[[[00000000000000000672---87dcab02dfd7f197c257be3c6ab7c139a3d96827540921470e807f2499b2680f]]]In Figure 5-1, 'x2' and 'x1.1' are represented as one operation and circled, but it is also possible to represent only the multiplication 'x' as an operation. In that case, as shown in Figure 5-2, '2' and '1.1' can be written outside the circle as variables 'number of apples' and 'consumption tax' respectively.

[[[00000000000000000673---0c3078da20b449f222d03b2d5545427001e5fdb7b9acb82eec9685d54f1ff73e]]]
Figure 5-2 Answer to Question 1 using a calculation graph: Put 'number of apples' and 'consumption tax' as variables outside the circle


[[[00000000000000000674---cb452ab511714dd2b2d35571c6e3b5f64f30c422be512136fedbb12b4d4a7052]]]Now for the next question.

[[[00000000000000000675---de2c8d5b2b198535ca6bfc5fff653b2448830efc2aced938b222e8c124eba614]]]Q2: Taro bought two apples and three oranges at the supermarket. An apple is 100 yen and a mandarin orange is 150 yen. Find the amount to be paid, assuming a 10% consumption tax.

[[[00000000000000000676---826f2ceb2840d0e099df09b2faea7ea46877fc3f7857e3bb5a7f914f3d1e9c67]]]As with Question 1, solve Question 2 using a computational graph. The calculation graph looks like Figure 5-3.

[[[00000000000000000677---fec701117dd2f41b74f8a8f0c871c157504945b442bdf60db8e7d24def694dae]]]
Figure 5-3 Answer to Question 2 with Computational Graph


[[[00000000000000000678---6916e538479a89a37ee2529b8a8f118cafa69ed9c8c2d4b6463b01c60c71d5f9]]]In this problem, a new addition node '+' is added to add up the amounts of apples and oranges. Once the computation graph is constructed, the computation proceeds from left to right. Notice that the result of the calculation propagates from left to right, like a current flowing through a circuit. When the calculation result reaches the rightmost position, the calculation ends there. From Figure 5-3, the answer is 715 yen.

[[[00000000000000000679---f3c83a2e0ea0a8b1d0df31e6179ed8f46f6b3de6b7c27fc0a4d3cd0f7fa0ed28]]]As we have seen, to solve a problem using a computational graph,

[[[00000000000000000680---641d4b4f6afbb93b4c9d008d868669454ddc217244c546f600395e374e295ab1]]]Build a computational graph

[[[00000000000000000681---23af50b65aebb35e636b16dab8b0bf109260e390431251556bca050f960179e9]]]Advance the calculation from left to right on the calculation graph

[[[00000000000000000682---e9d6d34e6a77b04b2c94ffcc7764b00fbb72b0121755cbf38030bbb6186d39b6]]]I will do it in the flow. The second step here, 'going from left to right,' is called forward propagation, or forward propagation for short. Forward propagation is propagation from the starting point of the computational graph to the ending point. Given the name of forward propagation, we can also think of backward propagation -- from right to left in the diagram. In fact, it's called backward propagation. Backpropagation plays an important role in computing derivatives going forward.

[[[00000000000000000683---31009b752a8b759a22c51cec0033dd82a8cd02577c918f4a5f3d24052c17764a]]]local computation

[[[00000000000000000684---c44eb7375a6bb015d3e31aab82c353e359e3f5a0f4f5d341a68703a0e63f637d]]]Computational graphs are characterized by the fact that the final result can be obtained by propagating 'local computations'. The word local means 'a small area that concerns you'. Local computation boils down to being able to output the next result (and the future result) from only the information relevant to you, regardless of what is going on in the whole.

[[[00000000000000000685---b766f9a0092b58eb5f03bc91204ee6913001fad98c53c3f82d34daa55cee7478]]]Let's explain local computation with a concrete example. For example, if you buy two apples and a lot more from the supermarket. In that case, you can draw a computation graph like Figure 5-4.

[[[00000000000000000686---75a3a7fb00246eb683ad441450995358d75f060853841547652fb6fc38b89580]]]
Figure 5-4 Example of Shopping for Two Apples and Many Others


[[[00000000000000000687---549a2c8e8dc764a2f71751176b5d2571350ed11ce13c088ceeda9653857d27ca]]]Suppose you make a lot of purchases and the total amount (by complex calculations) is 4,000 yen, as shown in the calculation graph in Figure 5-4. The important point here is that the computation at each node is a local computation. This means, for example, that the calculation of adding up apples and other purchases——4,000 + 200 → 4,200——is just adding two numbers without thinking about how the number 4,000 has been calculated. It means that you should have enough. In other words, each node's computation has to do its own computation—in this example, adding two numbers entered—and not think about the big picture. is.

[[[00000000000000000688---fca7939dd878a8d2507772bc46bfcb02c8249d4c6d51872ea9359810e7b53f57]]]In this way, the computational graph allows us to concentrate on local computations. No matter how complex the overall computation is, what you do at each step is a 'local computation' of the target node. The local computations are simple, but the propagation of their results yields the results of the complex computations that make up the whole.

[[[00000000000000000689---509fbad20494e27a2a7db51e353d4b091e0df8e01b6c3ce4841634fe547f7f60]]]For example, assembling a car is a complex task, but it is usually done by division of labor in an 'assembly line'. What each person (the machine in charge) does is a simplified job, and the result of that work flows to the next person, and finally the car is completed. Computational graphs also divide complex computations into 'simple and local computations' and transmit the results of computations to the next node in a flow-like manner. There is something similar to assembling a car that complex calculations can be decomposed and built from simple calculations.

[[[00000000000000000690---5471dccea547e405cb78fc534976ed5006047913943ea824c2c8d55befe91948]]]Why solve with computational graphs?

[[[00000000000000000691---4bb673da37fc55769d64abc5c62064353edb682d5c9bde3d66c159fde324dbf2]]]So far, we have solved two problems using computational graphs. What are the advantages of computational graphs? One advantage lies in the 'local computation' I mentioned earlier. No matter how complex the overall computation is, local computation can simplify the problem by concentrating on simple computations at each node. Another advantage is that the calculation graph can hold all the results of intermediate calculations (for example, when the calculation reaches two apples, the amount is 200 yen, and the amount before consumption tax is added). is 650 yen). However, for that reason alone, the use of computational graphs may not be persuasive. In fact, the main reason for using computational graphs is to efficiently compute 'derivatives' by backpropagation.

[[[00000000000000000692---20c3ff048e421bce984fc70c93be7fed17daf4db81cd6b342fd031b8e807069c]]]To explain backpropagation of computational graphs, let us consider the problem of Question 1 again. In question 1, I bought two apples and asked for the final payment amount including consumption tax. Now, for example, let's say you want to know how an increase in the price of apples affects your final payment amount. This is equivalent to finding the 'derivative of the amount paid with respect to the price of the apple'. In symbolic terms, this is equivalent to finding where x is the price of the apple and L is the payment amount. The value of this derivative represents how much the payment amount would increase if the price of the apple rose 'slightly'.

[[[00000000000000000693---0121c4b6d1d300b91755e75e0e876a46bd48613c5a736073e20511556edf5ccb]]]As I said earlier, values like 'the derivative of the amount paid with respect to the price of an apple' can be found by backward propagation on the computational graph. If we show only the result first, we can obtain the derivative by backpropagation on the computational graph as shown in Figure 5-5 (I will explain how to perform backpropagation in a moment. ).

[[[00000000000000000694---a8311ff18cc62954f70b369bbdd6821c6626f4a62acc4b2a11a73a4bc7475032]]]
Figure 5-5 Propagation of Differential Values by Backpropagation


[[[00000000000000000695---ac09d72ccb7122306bce455729844d23977bc21e5ccddda6974e089b845e354a]]]As shown in Figure 5-5, backpropagation is illustrated by an arrow (thick line) pointing in the direction opposite to the forward direction. Backpropagation conveys 'local derivatives', whose values are written below the arrows. In this example, backpropagation propagates the differential value from right to left, '1 → 1.1 → 2.2'. From this result, we can say that the value of the 'derivative of the amount paid with respect to the price of the apple' is 2.2. This means that if the price of an apple rises by 1 yen, the final payment amount will increase by 2.2 yen (more precisely, if the price of an apple increases by a small (meaning an increase of only 2.2 times).

[[[00000000000000000696---c391c804448913cbb2cfa37c570ef2dfb7d4c8da218ddc34b1da102bb78ddbf0]]]Here, we have only obtained the differentiation with respect to the price of apples. At that time, it is possible to share the results of differentiation obtained halfway (differentiation that has flowed halfway), and it is possible to efficiently calculate multiple derivatives. In this way, the advantage of the computational graph is that the differential value of each variable can be obtained efficiently by forward propagation and back propagation.

[[[00000000000000000697---5309e3bdd59394c928d629b977a6afc354beb97c64cf496231ae6a3ab9fdba79]]]chain rule

[[[00000000000000000698---07c8d9716ddd55914d5b958e0b4f338e85698d95da92fe678b0d4c85f9a09bfb]]]The forward propagation of the computational graph we've done so far propagated the results of computations forward—from left to right. The calculations you performed at that time must have seemed natural to you, as they are routine calculations. Backward propagation, on the other hand, propagates 'local derivatives' in the opposite direction to forward -- from right to left -- which can be confusing at first. The principle of transmitting this 'local differential' is based on the chain rule. Here we describe the chain rule and show that it corresponds to backpropagation on the computational graph.

[[[00000000000000000699---20578ef4049785b924198e68a11955213b6c790ddc47219b7d36ec6e1f5c5f2a]]]Backpropagation of computational graphs

[[[00000000000000000700---8e7463beb9247a54fd1c507ee3f42ed178b1869aa0a6fcaecf456820938e2504]]]Let's quickly show an example of backpropagation using a computational graph. Assuming that there is a calculation y = f(x), the backpropagation of this calculation is shown in Figure 5-6.

[[[00000000000000000701---8159c167268f6e365e1409fa080336d5cba9707168cbbfdfe4c4e2f568f0ce02]]]
Figure 5-6 Backpropagation of the computational graph: Multiplying local derivatives in the opposite direction to the forward direction


[[[00000000000000000702---7a1cc3e46335685114f47d6d84991430942c47e71ee06b0c4846d768b6372bf9]]]As shown in Figure 5-6, the backpropagation computation procedure multiplies the signal E by the local derivative ( ) of the node and propagates it to the next node. Local differentiation here means finding the differentiation of the computation y = f(x) in forward propagation, which means finding the differentiation of y with respect to x (). For example, if y = f(x) = x2, then It then multiplies that local derivative by the value transmitted from upstream (E in this example) and passes it on to the previous node.

[[[00000000000000000703---ab041cb2e1a735b546e48efb2e584680a5b1bbb3aff56474a17b7f1360c4972f]]]This is the calculation procedure performed by backpropagation, but the point of backpropagation is that the desired differential value can be obtained efficiently by performing this calculation. The reason why such a thing is possible can be explained from the principle of the chain rule. Now let's talk about the chain rule.

[[[00000000000000000704---8bb4d4284a42a1d446822d37f99f28a106e4ebe02518e8d2728ad59799ca0bdc]]]What is the chain rule

[[[00000000000000000705---87058e6c729f23ce53610f988fa8119b0b5ee6b97f9c78f355d4aad3b40d0157]]]To explain the chain rule, we first need to start with composite functions. A composite function is a function composed of multiple functions. For example, the expression consists of two expressions, as shown in the following expression (5.1).

[[[00000000000000000706---3179879a81cf1935a126940a5fe1e0eb10aa35596cf45f5e15e187bacfa07cc1]]]Equation (5.1)

[[[00000000000000000707---8a08a12360d3bde89fb2722465edc002577b9aa0c5b0fc78489c4a0aa662775b]]]The chain rule is a property of differentiation of composite functions and is defined as follows.

[[[00000000000000000708---a40fca6d2d1add86e365c3f941a43601ac1370459d06a0664e458365d732e5e7]]]When a certain function is represented by a composite function, the derivative of the composite function can be expressed by the product of the differentials of the functions that make up the composite function.

[[[00000000000000000709---5c0f4ff23e4b900c4b23f08b024e6369dd785f4d5c0e92bf77cd7b98fb6b4be3]]]This is called the chain rule principle. It is a very simple property (although it may look difficult at first glance). In the example of equation (5.1), the (derivative of z with respect to x) can be expressed by the product of (derivative of z with respect to t) and (derivative of t with respect to x). Expressed as a formula, it can be written as in formula (5.2).

[[[00000000000000000710---6afb7e95f3e8bb282403e852c8cbb1911dac90590cd993a1864aba5ef51656c7]]]Equation (5.2)

[[[00000000000000000711---41dcf498ea4e370b4cf7dd459f532b2e3006bc07ede46ce2e2b1f4a36fca7b21]]]Equation (5.2) is easy to remember because ∂t 'cancel' each other just like this:

[[[00000000000000000712---3171a3324f440a2c88487f6dad4c69a9617758d694975d7132a34e955438e9a9]]]Now let's find the derivative of equation (5.2) using the chain rule. To do so, first find the local derivative (partial derivative) of equation (5.1).

[[[00000000000000000713---817c6d77dfbca08b0b06be966b66fe88b37c95dc2074c0f9dc3240f370cd3319]]]Equation (5.3)

[[[00000000000000000714---92e6cd92ae373c34a43057f0632b4c22e420d67ff8becc89c62f36f32d37d3d0]]]is 2t and is 1, as shown in equation (5.3). This is the result obtained analytically from the differentiation formula. And finally, we can calculate by multiplying the differential obtained by formula (5.3).

[[[00000000000000000715---66d4d102012278f249eb3bb35cb429ab7ac9d88ab0a339f7e0ee4e03344fb6a4]]]Equation (5.4)

[[[00000000000000000716---f49fbf700c1f96108883943fd7abb17fd23de54263f7e55d481c99f4c8ec1bf8]]]Chain rules and computational graphs

[[[00000000000000000717---f2730b5c5aa187117e6d2fa7f2190b2c7fb11d59bcf96a66be06d3822fa20326]]]Now, let's express the calculation of the chain rule performed in equation (5.4) in a computational graph. If we represent the squaring calculation with the node '**2', we can write it as shown in Figure 5-7.

[[[00000000000000000718---fe76dd4757fa02442a2f8fa7cb1a338c547cb19b4bfc7567fc869d41c52bed7d]]]
Figure 5-7 Calculation graph of formula (5.4): Multiplying local differentials in the direction opposite to the forward direction


[[[00000000000000000719---bf7f71e2daf6d60585c9de360cff932dd3da9b1dd5519d22744b75356ce68206]]]Backpropagation of the computational graph propagates signals from right to left, as shown in Figure 5-7. In the backpropagation calculation procedure, the input signal to the node is multiplied by the local differential (partial differential) of the node and propagated to the next node. For example, the input when backpropagating to ``**2'' is , and the local derivative to this——during forwardpropagation, the input is t and the output is z, so the (local) derivative at this node is multiplied by —— and passed to the next node. Note that the first signal of backpropagation in Figure 5-7, , did not appear in the previous equations, but was omitted from the previous equations because it is .

[[[00000000000000000720---a9d94e21cd13ba9ed09760886f1e6ed4f9ddcc084daea5b0f39c98dfcc621329]]]Now, what is of interest in Figure 5-7 is the leftmost backpropagation result. From the chain rule, this corresponds to 'the derivative of z with respect to x'. In other words, what backpropagation does is constructed from the principle of the chain rule.

[[[00000000000000000721---a9cffcab596590b6978bab4a32899e9d87a587e2bc3bb95aac52198cf42b2496]]]Substituting the result of formula (5.3) into Figure 5-7 yields the result shown in Figure 5-8, which can be obtained as 2(x + y).

[[[00000000000000000722---a917364ec1bde44071b0bd61792bf7364efce697324095e55a8d2b09c14a4143]]]
Figure 5-8 From the result of backpropagation of the computational graph, is 2(x＋y)


[[[00000000000000000723---bed50c73a0b61f35d2ed856af57ab1c46fc7d057cc4148e82cc28a7246da2a9c]]]back propagation

[[[00000000000000000724---7e5e56077952b5a24a9166e85d201b90098fbcb6cde775baa72315bad248ec7a]]]In the previous section, we explained that backpropagation of computational graphs is based on the chain rule. Here, we will explain how backpropagation works, using operations such as '+' and '×' as examples.

[[[00000000000000000725---a1e28a64cf0505ce8213e23e4e53953fda4b8a35c32c4afbe0e5ea18e3c427d4]]]Backpropagation of sum nodes

[[[00000000000000000726---e8b8517182ebbe0d3f91f1247f06001993445ec798aacc675aac9c0bbc0b1927]]]Let us first consider the backpropagation of a sum node. Here, we will look at the backpropagation for the formula z = x + y. Let's start with the differentiation of z = x + y, which can be calculated (analytically) as follows.

[[[00000000000000000727---b29d2f993526b74c835fa28eea244db21ab5795fe129d6e7608dd5827728f891]]]Equation (5.5)

[[[00000000000000000728---ff1053c15da83192cc4030db0f3f572e9ed384f5c0095da659b1abde737a9b36]]]and are both 1, as shown in equation (5.5). Therefore, it can be expressed as a computational graph as shown in Figure 5-9.

[[[00000000000000000729---361b304489b154a054ca1d849f8760adf019e0fac3195c3e8ec8f676576283a5]]]
Figure 5-9 Backpropagation of addition nodes: forward propagation on the left and backpropagation on the right. As the backpropagation in the right figure shows, the backpropagation of the sum node passes the upstream value to the downstream as it is.


[[[00000000000000000730---6024c0b93d80256cf935f364b5527fe7bfcfaf6babf06fb654d64028efb21157]]]As shown in Figure 5-9, during backpropagation, the derivatives passed from upstream—in this example—are multiplied by 1 and flowed downstream. In other words, the backpropagation of the addition node only multiplies 1, so the input value is simply passed to the next node.

[[[00000000000000000731---b9e25feefa0dfceb62232fce5c8baae25c1da431bad43963853bed93a95790d6]]]In this example, the value of the derivative transmitted from the upstream is assumed, as shown in Fig. 5-10, because it assumes a large computational graph that eventually outputs the value L. The calculation z = x + y exists somewhere in that large computational graph, and the value from upstream is transmitted. Then, each value is transmitted downstream.

[[[00000000000000000732---151643d7fc5cb538e9f1ea4f85598bf19590a5058577b073f94668d433a314b7]]]
Figure 5-10 This addition node exists in part of the final output calculation. During backpropagation, local derivatives are propagated back from node to node, starting from the rightmost output.


[[[00000000000000000733---106b8550075b4569bdbe1d1cc27b9ea666fa60523de799dd136455195f5a7e98]]]Let's take a look at a specific example of backpropagation of addition. For example, suppose there is a calculation of '10 + 5 = 15', and a value of 1.3 flows from upstream during backpropagation. If this is written as a computational graph, it will look like Figure 5-11.

[[[00000000000000000734---52feef6380036a305691ae318d9264a67267809fd18e1dbafed47aa841b1b7d6]]]
Figure 5-11 Concrete example of backpropagation of a sum node


[[[00000000000000000735---06c2377c34b957ae79fa3b492243ac8a03ee95f9f6c31d07be448f0c14413b7e]]]Backpropagation of a sum node only outputs the input signal to the next node, so 1.3 flows to the next node, as shown in Figure 5-11.

[[[00000000000000000736---b0812c45f61b7ac3d0e9b961607ce8fea17a0933955bfc37120ffd654129438f]]]Multiply node backpropagation

[[[00000000000000000737---76f3548ab6be9af1f6530a7d4354d49247b53bd8745c66b14ad2db350f7995d3]]]Next, let's talk about backpropagation of multiplication nodes. Here, consider the expression z = xy. The derivative of this expression is given by the following equation (5.6).

[[[00000000000000000738---fdc8c21ae8802ff4e58a307deb7d5819c58cdeaa15b6468fa0d0906d7e22292d]]]Equation (5.6)

[[[00000000000000000739---503168023dadbd498c5f31bdc9646cf339374b05bf6cdb6b2bc7d4c814659ac8]]]From equation (5.6), the computational graph can be written as

[[[00000000000000000740---8f206b4cee840b679e1f956c3d3850d83d9f861ddf1bfd82620a174b71b0a9d5]]]
Figure 5-12 Backpropagation of multiplication: forward propagation on the left, backpropagation on the right


[[[00000000000000000741---16891ffb7087b788d9f46b7543c542f9e4cddd052d2e627ddaf593558194bb07]]]In the case of backpropagation of multiplication, the upstream value is multiplied by the 'flipped value' of the input signal in the forward propagation and sent downstream. As shown in Figure 5-12, the flipped value is y in backpropagation if the signal is x in forward propagation, and x in backpropagation if it is y signal in forward propagation. It means that you are in a relationship.

[[[00000000000000000742---74c41516422b274b020b9e68ba1f91b5c6aa78c5e4d13578e5bfd788ee7b98b1]]]Let's look at a concrete example. For example, suppose there is a calculation of '10 × 5 = 50', and a value of 1.3 flows from upstream during backpropagation. If this is written as a computational graph, it will look like Figure 5-13.

[[[00000000000000000743---fac23383ba99314b60bc6a9ec484bb9dec92dffcc463c88f277c9dce8b7f9e5d]]]
Figure 5-13 Specific example of backpropagation for a multiplication node


[[[00000000000000000744---affe5cc8422cdcd9dabe00821616b67b4584264ad666a0641f9b055349c3f8df]]]Backpropagation of multiplication multiplies the value that flipped the input signal, so it can be calculated as 1.3 x 5 = 6.5 and 1.3 x 10 = 13 respectively. Note that we didn't need the values of the input signal for the forward propagation, since the backpropagation just passed the upstream values downstream. Backpropagation of a multiplication, on the other hand, requires the value of the input signal as it was propagated forward. Therefore, when implementing the multiplication node, keep the forward propagating input signal.

[[[00000000000000000745---865175ee993fb1c6f7d2d5da1feba9100a6cf4985df8b635f62ca5af72cf282b]]]apple example

[[[00000000000000000746---2e3166ade7b2de70a5b7abf6a7252bb95fa150173a3b4fbb2b69aae54c6f1353]]]Consider again the apple shopping example we saw at the beginning of this chapter—two apples and sales tax. The problem we want to solve is how each of the three variables (price of apples, number of apples, and sales tax) affect the final payment. This is equivalent to obtaining 'differentiation of payment amount with respect to the price of apples', 'differentiation of payment amount with respect to the number of apples', and 'differentiation of payment amount with respect to consumption tax'. Solving this using backpropagation of the computational graph results in Figure 5-14.

[[[00000000000000000747---f008f2fb12c4b974260ece93e99f3cdd1f3f3448411ba898b2db74949b9d7aca]]]
Figure 5-14 Backpropagation Example of Shopping for Apples


[[[00000000000000000748---76bf0f2d5f0799b889fe0734659e225ec24e165478fe4df4f0a05dd43d6dddcd]]]As we have seen, backpropagation in a multiplication node flips the input signal around and flows downstream. From the results in Figure 5-14, the derivative of the price of apples is 2.2, the derivative of the number of apples is 110, and the derivative of the consumption tax is 200. This translates to, for example, if sales tax and the price of apples increase by the same amount, the sales tax will affect the final payment amount by a magnitude of 200, and the price of apples by a magnitude of 2.2. can. However, in this example, the consumption tax and the apple price are on different scales, so the result is as follows (1 for consumption tax is 100%, and 1 for apple price is 1 yen).

[[[00000000000000000749---8eee5bdb7f9f45dd9f03c0611d92144f3cb09f0a275f5dd048a5fb832703e733]]]Now, as a final exercise, let's ask the backpropagation of 'shopping for apples and oranges'. Fill in the squares in Figure 5-15 and find the derivative of each variable (the answer is a few pages down).

[[[00000000000000000750---5dd28e0935ceb3179e43abc50bf6eefa1eebbfbcedc9c56f4b4fc6c2b8c07042]]]
Figure 5-15 Backpropagation example of shopping for apples and oranges: Fill the squares with numbers to complete the backpropagation


[[[00000000000000000751---4cb4d2df18a25f5b741f0f6de5299b8766c3b5e663d0e0ed46218089dabca1e8]]]Simple layer implementation

[[[00000000000000000752---3bb53261a2763d8247c5ab51483b4aac0e5793bd61314edd355d7b7227203909]]]In this section, we will implement the “apple shopping” example we have seen so far in Python. Here, we will implement the multiplication node of the computation graph with the name 'multiplication layer (MulLayer)' and the addition node with the name 'addition layer (AddLayer)'.

[[[00000000000000000753---f6fc0a8db8bd582e525d43f4275c6f3beca4ebd3a624aabcda81539a0c83a623]]]In the next section, we will implement the 'layers' that make up the neural network with a single class. 'Layer' here is a functional unit in a neural network. For example, Sigmoid for sigmoid function and Affine for matrix multiplication are implemented on a per-layer basis. Therefore, we will implement the multiplication node and the addition node in units called 'layers' here as well.

[[[00000000000000000754---3d7d58be6447c6784286ca5481ec132047d299619ea9d581fdc2a2cd00e7d065]]]Multiply layer implementation

[[[00000000000000000755---1a6e82b0efaff0bf2770d469926ddc8ae1f31613e46e035138874411f17bc059]]]Layers are implemented to have common methods (interfaces) called forward() and backward(). forward() corresponds to forward propagation and backward() corresponds to backward propagation.

[[[00000000000000000756---f5037e260d155c2257b112f49e8b3cc6b802955d844da40033a9c8ef4fef53ea]]]Now let's implement the multiplication layer. A multiplication layer can be implemented as a class named MulLayer as follows (source code is in ch05/layer_naive.py):

[[[00000000000000000757---2fb0041372c8c1d35c601bb59fe837140ce7f84aeef9f6bb733c0a8b8844e70c]]]# Flip x and y

[[[00000000000000000758---82ca2a0f8910bdde2356e04c82e86b73cffa369d4094720188fbe30ba8ecc0ba]]]__init__() initializes the instance variables x and y, which are used to hold the input values during forward propagation. forward() takes two arguments x and y, multiplies them and outputs. On the other hand, backward() multiplies the derivative (dout) transmitted from the upstream by the 'flipped value' of the forward propagation and flows downstream.

[[[00000000000000000759---2fc1135b10a0ee0cb99c22d9fa116e0c824ff392b75032b70cddc5dd70e8b659]]]The above is the implementation of MulLayer. Now, let's use this MulLayer to implement the 'apple shopping' we've seen so far -- two apples and sales tax. In the previous section, we were able to perform calculations as shown in Figure 5-16 using forward and backward propagation of the computational graph.

[[[00000000000000000760---4854489ab15f1eb9d8609696c9bd7fc14ed0b0bbed6d59ea681620f0255ecc0a]]]
Figure 5-16 Shopping for two apples


[[[00000000000000000761---4ab549a1accbb93b273482c273295bfdeffb4bda078fc7bb579ecb3ce6a2c7a0]]]With this multiplication layer, the forward propagation in Figure 5-16 can be implemented as follows (the source code is in ch05/buy_apple.py).

[[[00000000000000000762---e719118b6f2940d62d4370589a2ccb33a12921044ceeae0689126b3d550a3ed9]]]Also, the derivative with respect to each variable can be obtained with backward().

[[[00000000000000000763---3c479c9bad4713c9b4183cc51ab308c3c19241f03027f7ffb468179449991e3c]]]Here, backward() is called in the reverse order of forward(). Also, note that the argument of backward() inputs 'differentiation with respect to the output variable during forward propagation'. For example, a multiplication layer called mul_apple_layer outputs apple_price during forward propagation, but sets dapple_price, the derivative of apple_price, as an argument during backward propagation. The execution result of this program matches the result in Figure 5-16.

[[[00000000000000000764---dd48bc60c3489404b5623d13ba0517d2ee84b56a131373876ae70658e4101e2b]]]Additive layer implementation

[[[00000000000000000765---43a1a98f4a03a4b0037782d2bd28bbad286fb62d15808e3eb837daf70bcf864f]]]Next, we will implement an addition layer, which is an addition node. An additive layer can be implemented as follows:

[[[00000000000000000766---c905e9060295d617bca71e2d99248ed1f3cffd752268ed7f6a2aac34cfa0a2ff]]]Addition layers do not require any particular initialization, so __init__() does nothing (pass is an instruction to 'do nothing'). Forward() in the additive layer takes two arguments x and y, adds them and outputs them. In backward(), the differentiation (dout) transmitted from upstream is simply passed downstream.

[[[00000000000000000767---1ddb6b2edd05715563feb2a76d34c5c1a9f635311fde304507a47a6323610035]]]Now, let's implement the shopping for 2 apples and 3 oranges shown in Figure 5-17 using additive and multiplication layers.

[[[00000000000000000768---c8b8231e135c8a1d26abebda47e40a0eff276d37062c488b9bd7e6eb69223cf3]]]
Figure 5-17 Shopping for 2 apples and 3 oranges


[[[00000000000000000769---9accd17550f431d5d4bf7890c75f442ad0845e8159e89c9def031997553ce7ad]]]The computation graph in Figure 5-17 looks like this when implemented in Python (the source code is in ch05/buy_apple_orange.py):

[[[00000000000000000770---72539c429b013811a9fd33cd69cdaa2b8880da981b4ba83fd162adb54540b2f1]]]This implementation is a little longer, but each instruction is simple. Create the required layers and call the forward propagation method forward() in the appropriate order. Then, by calling the backpropagation method backward() in the order of forward propagation and reverse propagation, we can obtain the derivative we want.

[[[00000000000000000771---99adde59e8e8dfc79fa744b5c14675c8dc9c5513e4c4b8d5f948237fe150c7cc]]]Thus, the implementation of layers in the computational graph—here multiplications and additions—can be easily done and used to compute complex derivatives. Next, we will implement the layers used in the neural network.

[[[00000000000000000772---3c86c6ed75e6eeba6ca61b5332e2c556c152ae1619b18ffe390038bfc4730cd4]]]Activation function layer implementation

[[[00000000000000000773---7fe37ee89b380c50a9e3364eece27742462e7792d97e2db3c05d3cd00a5f300c]]]Now I would like to apply the idea of computational graphs to neural networks. Here, we will implement the 'layers' that make up the neural network as a single class. First, we will implement the activation function ReLU and the Sigmoid layer.

[[[00000000000000000774---fb0bbcf0421ec9d117fa9d00ade2d9bdd5ab98672dc334a99934c5a9dc396910]]]ReLU layer

[[[00000000000000000775---865a4fc25c6b1249533f4ae011249831e256e04059cc8a7ac4c8d9704795a6e7]]]The ReLU (Rectified Linear Unit) used as the activation function was expressed by the following equation (5.7).

[[[00000000000000000776---ea20a4fa8193deedba691b15e87f8980a611f76aef3ba0268f00270aefe0e1a2]]]Equation (5.7)

[[[00000000000000000777---f7a7163b481848e1cabcf3fe586463fc185f7d86b7a8377e6d0fa112a868c001]]]From equation (5.7), the derivative of y with respect to x is given by equation (5.8).

[[[00000000000000000778---efa69eb0c88846c692523e5c8d8a8eeb081be2a38aa9529609d151205945b17f]]]Equation (5.8)

[[[00000000000000000779---13c5b1593a021601ced9db530602a5f80699f97af8c4ce5d7bb244f9ae6a894b]]]As shown in equation (5.8), if x, the input during forward propagation, is greater than 0, backpropagation will pass upstream values downstream. Conversely, if x is less than or equal to 0 during forward propagation, the signal downstream stops there during backward propagation. Expressed as a computational graph, it can be written as shown in Figure 5-18.

[[[00000000000000000780---5b828800034aa466c7e043181a3376b074976056082b5039de98cd1d34f8f1e9]]]
Figure 5-18 Computation graph of ReLU layer


[[[00000000000000000781---911b2532c1b5944eb6c46ece5d42a04999f278aa439e0a486e33d89fd1891994]]]Now let's do the implementation of this ReLU layer. Neural network layer implementation expects NumPy arrays as input for forward() and backward() arguments. Note that the ReLU layer implementation is in common/layers.py.

[[[00000000000000000782---d453346df1638ddc815dc67f1fecf23f52b9ce0f872110ec61b231cec5acacd8]]]The Relu class has a variable called mask as an instance variable. This mask variable is a NumPy array consisting of True/False, and stores the elements of x, the input of forward propagation, that are less than or equal to 0 as True, and the others (elements greater than 0) as False. For example, the mask variable holds a NumPy array of True/False, as shown in the following example.

[[[00000000000000000783---2e9099d9c7297eab79d32283572a76dbc8c707e183143a62239a94a764bdfede]]]As shown in Figure 5-18, if the value of the input during forward propagation is less than or equal to 0, then the value of backpropagation is 0. Therefore, in backpropagation, the mask retained during forward propagation is used to set to 0 the locations where the elements of the mask are true for the dout propagated from upstream.

[[[00000000000000000784---dcb8480f56085909d416da90db428127aa630d01cc0fa0596abf629b7efd1073]]]The ReLU layer acts like a 'switch' in the circuit. If the current is flowing during forward propagation, the switch is turned ON, and if the current is not flowing, the switch is turned OFF. During reverse propagation, if the switch is ON, the current will continue to flow, and if it is OFF, no more current will flow.

[[[00000000000000000785---e938077af97a906d3f98cf0f3a95e0e4815629b3f638dab3cc55b22f77a84497]]]Sigmoid layer

[[[00000000000000000786---df0eb1a474a23fd75eafa2f8e7687cf3f270edd0c5c7cb8631b7b5936d5f6cbc]]]Next, let's implement the sigmoid function. The sigmoid function was the function expressed by equation (5.9).

[[[00000000000000000787---77c59142c98ee7a589b3783871f77d9e9cd91bb0dc4bcec7f80abde59675cbec]]]Equation (5.9)

[[[00000000000000000788---7ba39080e7d817d628cdc4e9dfe432713227602e443328fb2563869d7531295c]]]Representing equation (5.9) in a computational graph is shown in Figure 5-19 below.

[[[00000000000000000789---e451ac2a484cb41c6a6638dac6a6db1064269b463ab099cdb1363dc817a195ea]]]
Figure 5-19 Computation graph of Sigmoid layer (forward propagation only)


[[[00000000000000000790---60cb3d572adc1e111f3568e7cf218b39d4f9844dcebb90b03dcf20ae0ff2477f]]]Figure 5-19 shows the new 'exp' and '/' nodes in addition to the 'x' and '+' nodes. The 'exp' node does the calculation y = exp(x) and the '/' node does the calculation.

[[[00000000000000000791---24b1f296db3cf6d551bcf854151613da02914500f0aa7503311bf8d316d34bd1]]]The computation of Equation (5.9) consists of local computation propagation, as shown in Figure 5-19. Let's backpropagate the computational graph in Figure 5-19. Here, I would like to look at the flow of backpropagation in order (also as a summary so far).

[[[00000000000000000792---e93fe08e7ccbc4c3536f1e40a309957727c2390e68e17ab4e1e7af83654bbc1a]]]step 1

[[[00000000000000000793---8fc82ba0fb348a6346e7f0752048f59f5b1d1ac9e251fbe98e34c5aaa5a6c6e7]]]The '/' node represents , but this derivative is analytically represented by the formula:

[[[00000000000000000794---05730f69449ead915eaacd1d44667124d7a17193e578983f589654a7d4ee4250]]]Equation (5.10)

[[[00000000000000000795---899a22194dd18295f42a074631d09d6ed0fe7bbb52b4178b44d99f39c2e95906]]]From equation (5.10), in the case of backpropagation, the upstream value is multiplied by −y2 (the square of the output of forward propagation with a minus value) and propagated downstream. In the computational graph it looks like this:

[[[00000000000000000796---8e20d1d4524eac18dd0049c998d71cb63f6799bea0da7f697df3e314c6eb3e8f]]]step 2

[[[00000000000000000797---ef4e22dbf0fc5d8f2576f78341a096454b0fa3626bdc1dc0334367d2e8286f79]]]The '+' node simply passes upstream values downstream. In the computational graph it looks like this:

[[[00000000000000000798---3201c4535a225da6767f4168a0dcc1e1993bb69c0dacf3cdf1cbbe8218953237]]]step 3

[[[00000000000000000799---c82371d5b1b0657c065b6a269a901d5a079717f8057b2bd58f78a4f33ede8512]]]The 'exp' node represents y = exp(x) and its derivative is given by

[[[00000000000000000800---f28c867e9c7d87fa1e9401b09998e3796cc19280c9d0df2b1fc48cc34049621f]]]Equation (5.11)

[[[00000000000000000801---94fed6bc98603e098d3d3949376be0a85df3f4065788a9804096d14ed7f6d37a]]]In the computational graph, the upstream value is multiplied by the forward propagation output—exp(−x) in this example—and propagates downstream.

[[[00000000000000000802---6d409a808698085894c3bd2b364fab9e7b350f741174f1958f891db93247ab7e]]]step 4

[[[00000000000000000803---a8b1af78535d108d5248f061572264b226f350bee153a63aa4c4f271d1c3ff48]]]The 'x' node 'flips' the forward propagation values and multiplies them. So here we multiply by -1.

[[[00000000000000000804---e713f6121ae136b307df5e47ba3a0b15ae1a52dc614c922d214bbf35c2a1fee5]]]
Figure 5-20 Computation graph of Sigmoid layer


[[[00000000000000000805---40e3022078244c246199e888b215dcb367cd1a15945179d83e8fbffa08d7840d]]]From the above, we were able to perform backpropagation of the Sigmoid layer as the computation graph in Figure 5-20. From the results in Figure 5-20, the output of backpropagation is , and this value is propagated to downstream nodes. Note that the value here can be computed only from the input x and output y of the forward propagation. So the computation graph in Figure 5-20 can be written as a grouping of 'sigmoid' nodes as shown in Figure 5-21 below.

[[[00000000000000000806---2aeee95c878b0ef6c52e1da9690d00e1d3cf6dbc9ca04ce9ca1d7d5fd52aa655]]]
Figure 5-21 Computation graph of Sigmoid layer (simplified version)


[[[00000000000000000807---bd6a40426dc829db713d75aab0cd8013bd150b85aab50d20c80deca560a5673c]]]The computation graph in Figure 5-20 and the simplified computation graph in Figure 5-21 have the same calculation results. However, the simplified version of the computation graph can be said to be more efficient because it can omit intermediate computations during backpropagation. It's also important to note that grouping the nodes allows us to focus on the inputs and outputs of the Sigmoid layer without worrying about the details.

[[[00000000000000000808---bbd1ceb92b0b154970812d539b239454c8351ecb3ffbf8c86930a4107a571379]]]can be further organized and written as follows:

[[[00000000000000000809---4928a8651102a739fb085ed322d0f5329a63d88eca54d407bd3ef3073ab3997d]]]Equation (5.12)

[[[00000000000000000810---4c728b71386549a2191b7dd9c4c08242585a7e26c41c9265150d5733bd24d569]]]Therefore, the backpropagation of the sigmoid layer represented in Figure 5-21 can be computed only from the output of the forwardpropagation.

[[[00000000000000000811---806aa0069f2eb59a6ed8d099d5e379c443a3411b71ef062674865850a32ae2bc]]]
Figure 5-22 Sigmoid Layer Computational Graph: Forward Propagation Output y Allows Back Propagation Computation


[[[00000000000000000812---989fa5e7885c166c7d1f323d6a10e92e1ac4813745f54cd77042eda23c3faa90]]]Now let's implement the Sigmoid layer in Python. Referring to Figure 5-22, we can implement it as follows (this implementation is in common/layers.py):

[[[00000000000000000813---2e4966094672b9483a75015e100b3e48d288b6da2b7e82ecd0890c67e5fb4861]]]In this implementation, the output is held in the instance variable out during forward propagation. Then, during backpropagation, we use that out variable to perform computations.

[[[00000000000000000814---5c37a19ce3666a9cafa686eb2dc5008a7eb8a12a068aadfdb11c578b599de7ab]]]Implementing Affine/Softmax layers

[[[00000000000000000815---a32f14225e1a8dfca2475aada43820a8515f0b0721aa8cbc7159e34057bd495d]]]Affine layer

[[[00000000000000000816---dd491dbfbd00c20f4d8d5d80df49a319fb2ec661a832343a61a83b768f784c57]]]In the forward propagation of the neural network, we used matrix multiplication (np.dot() in NumPy) to compute the sum of the weighted signals (see 3.3 Computing Multidimensional Arrays for details). For example, do you remember implementing the following in Python?

[[[00000000000000000817---7d6a6b429305d73ecb5e46959c87c887129b72c23705d62bb97191514c68e7fb]]]   # enter >>> 

[[[00000000000000000818---8853c3290e949215bba03b2b78f80ac8acffb5ad0576326bf07e6e710ae3e98e]]] # weight >>> 

[[[00000000000000000819---1698864423b53105a69f3e686d799af7b2e804a8534f250777160e8ec6d0aa83]]]   # bias >>> >>> 

[[[00000000000000000820---0295bd20e2e9017f1305dc0194cab3a68f6fdf7f9b6879a8f8a5679785e5f5fb]]]Here, let X, W, and B be multidimensional arrays of shape (2,), (2, 3), and (3,), respectively. Then the weighted sum of neurons can be computed as Y = np.dot(X, W) + B. Then, this Y is transformed by the activation function and propagated to the next layer, which is the flow of forward propagation in neural networks. Also, as a review, the point of calculating the product of matrices is to match the number of elements in the corresponding dimensions. For example, the product of X and W must match the number of elements in corresponding dimensions, as shown in Figure 5-23 below. Note that the shape of the matrix is expressed here in parentheses, such as (2, 3) (this is to correspond to NumPy's shape output).

[[[00000000000000000821---18a3f15a12a1d2fa81d4ef7c5262eca0d2cae1376e84de4a9941e60b1595f026]]]
Figure 5-23 Matching the Number of Elements in Corresponding Dimensions in Matrix Multiplication


[[[00000000000000000822---b27ee9e14e882c14c12979be75e9ca6929b8cbf4c69be9ccb69e29a9c82604f8]]]Matrix multiplication in forward propagation of a neural network is called an 'affine transformation' in geometry. Therefore, here, we will implement the process of performing affine transformation under the name of 'Affine layer'.

[[[00000000000000000823---c3ec9bfd225f317b33c618bea6886617f4968d5aeb4060dfd01d22df33ea92d8]]]Now, let's represent the computation we've just done—the sum of matrix products and biases—on a computational graph. Denoting the node that computes matrix multiplication as 'dot', the computation of np.dot(X, W) + B can be represented by the computation graph in Figure 5-24. In addition, the shape of the variable is also indicated above each variable (for example, the shape of X is (2,), and the shape of X and W is (3,) on the calculation graph).

[[[00000000000000000824---464323abe7a3516fbd7fc09f23a5e9d413f8332f2bd2b4bcba0c13377f78ace5]]]
Figure 5-24 Computation graph of the Affine layer: Note that the variables are matrices. At the top of each variable, indicate the shape of that variable


[[[00000000000000000825---4ccd362a0691d458ef6bb8ea68f4875e06a995e1ece9bbd59da836aa61c8e41a]]]Figure 5-24 is a relatively simple computational graph. Note that X, W, and B are matrices (multidimensional arrays). In the computation graphs we have seen so far, 'scalar values' flow between nodes, but in this example, 'matrices' propagate between nodes.

[[[00000000000000000826---95aec2198063a31978be49060f0879d2318c3c6472f0951986fdcbca49e32911]]]Now consider the backpropagation of the computational graph shown in Figure 5-24. When obtaining backpropagation for a matrix, by writing it down for each element of the matrix, you can think of it in the same procedure as the calculation graph for scalar values so far. If we actually write it down, we get the following formula (the process of deriving formula (5.13) is omitted here).

[[[00000000000000000827---538c6a0cd820a85f5ee17abcd90e7aac902575e23df4e970a0d9f0c83aca8fac]]]Equation (5.13)

[[[00000000000000000828---ad676ee24ef09be1f6c4568a95748ee112464513e4bd7d4e91151e373e675b1a]]]The T in WT in equation (5.13) represents the transpose. Transposing means changing the (i, j) element of W to the (j, i) element. Expressed as a formula, it can be written as:

[[[00000000000000000829---326e2e9b1214858f3c1f94af19348bea1757bdb1fb130c996b6d64f306998051]]]Equation (5.14)

[[[00000000000000000830---9755e30db966247d9ff126264357907f2fb0223cca6c63648fbc59cd2edceb19]]]Given that W has shape (2, 3), WT has shape (3, 2), as shown in equation (5.14).

[[[00000000000000000831---b4ee8d4b1a819f963bc2fc6b89a375c420bf704757ab63c131b31eb14876418b]]]Now, let's write the backpropagation of the computational graph based on equation (5.13). The result should look like Figure 5-25.

[[[00000000000000000832---af4de614f8b2cd99d341c74d2eb61420aff6231fd6e952d7612dd0533b2dfb73]]]
Figure 5-25 Backpropagation of the Affine layer: Note that the variables are multidimensional arrays. Underneath each variable during backpropagation, show the shape of that variable


[[[00000000000000000833---3f9a69f7cbc6f77d0c9b6e9cac0f2c9b7d453701b57bad156a31028da014b056]]]Let's take a closer look at the shape of each variable in the computational graph in Figure 5-25. In particular, note that X has the same shape and W has the same shape. In addition, it is clear from the following formula that X has the same shape.

[[[00000000000000000834---7477b7e029cea362973b5b098f45549796daeb1dfbd59a05328b92c9ac4535e9]]]Equation (5.15)

[[[00000000000000000835---d78c866c5ed81b4d5a46a5b37e69e577e657bccc350ee0ca95a6674cf61fe216]]]The reason why we pay attention to the shape of the matrix is that the number of elements in the corresponding dimensions must match in matrix multiplication, and we can derive equation (5.13) by confirming the match. For example, if the shape of is (3,) and the shape of W is (2,3), consider the product of and W so that the shape of is (2,) (Figure 5-26). Then, formula (5.13) is automatically derived.

[[[00000000000000000836---627d71d49f56cf20027ed108f34e3049e1328791bd674b56db5c4874f055acae]]]
Figure 5-26 Backpropagation of matrix products ('dot' nodes) can be derived by assembling the products to match the number of elements in corresponding dimensions of the matrices


[[[00000000000000000837---70c43fe0654bd286cb488b22a01c39679f0ccc90dc38225ccf870b3e8e5083cd]]]Batch Affine layer

[[[00000000000000000838---4534482d23989fa3d3083860e018ce4368070e1ead2d7e394a2eeb774c1e1c26]]]In the Affine layer explained so far, the input X is for one data. Here, we consider the case of forward propagation of N pieces of data collectively, that is, the batch version of the Affine layer (a group of data is called a 'batch').

[[[00000000000000000839---f23a41d62b16fcbc67a1d1e6372383fa7ab5e2d8587c446673ad1a23b0bd2ce3]]]Now let's show the computation graph of the batch version of the Affine layer. A batch version of the Affine layer looks like Figure 5-27.

[[[00000000000000000840---0359a306a229ad0dd6d7671b53e95d294ba2c3a8d7336c15ef4b64b46161586b]]]
Figure 5-27 Computation graph of batch version Affine layer


[[[00000000000000000841---8c5c7f854f9237e53d81961a0635def9abcef141c12f021fb328f52b1c246a71]]]The only difference from the previous explanation is that the shape of the input X is now (N, 2). After that, just do the matrix calculation on the calculation graph as before. Also, when backpropagating, it can be derived in the same way as before, if you pay attention to the shape of the matrix.

[[[00000000000000000842---33ba4cd7b402751f211cf98b1ffb149b5ab74c53eaed0db4cde1ffb5fd870448]]]Care must be taken when adding the bias. For forward propagation, the bias is added to each data for X and W. For example, if N = 2 (2 data), the bias will be added to each of the two data (each calculation result). A concrete example is as follows.

[[[00000000000000000843---b30f94bbabb89100fa65742c883b3563f7efb796da49763d06f7a2d366c678fc]]]Addition of biases in forward propagation is performed for each data (1st data, 2nd data, ...). Therefore, during backpropagation, the backpropagation value of each data should be aggregated into the bias factor. Expressed in code, this looks like this:

[[[00000000000000000844---c8d2f614bd6703d23a013c8500bc1e4996649b2e5c93f1fbd232780cb621d2dd]]]In this example, we assume that there are 2 data (N=2). Backpropagation of the bias is obtained by summing the derivatives with respect to the two data. Therefore, np.sum() calculates the sum of (axis=0) for the 0th axis (the axis with data units).

[[[00000000000000000845---19821d2aed9ff3e4a789af7c38d7863ca9b22fe75c2654d69122e9ff1acbf590]]]From the above, the implementation of Affine looks like this: Note that the implementation of Affine in common/layers.py is an implementation that considers the case where the input data is a tensor (4-dimensional data), and there are some differences from the implementation described here.

[[[00000000000000000846---3c0bb6dccc7bca639bf3d232e311b1bad0d4dc9e274a7da95c2b7c81eb04530a]]]Softmax-with-Loss layer

[[[00000000000000000847---ddaaa01898e26650ea455886df8e1dd1f4cdcbc683117c1b5fe299ffb3f26cd6]]]Finally, we will discuss the output layer, the softmax function. The softmax function (as a refresher) normalizes the input values and outputs them. For example, for handwritten digit recognition, the output of the Softmax layer looks like Figure 5-28.

[[[00000000000000000848---4dbfe6d63deca8ce9f7a15d46504d2f06276f6ffcf90fd1cbf4f0386c8a73e99]]]
Figure 5-28 Input image is transformed by Affine and ReLU layers, and 10 inputs are normalized by Softmax layer. In this example, a score of '0' is 5.3, which is converted by the Softmax layer to 0.008 (0.8%). Also, a score of '2' is 10.1, which translates to 0.991 (99.1%)


[[[00000000000000000849---81a0564d7d078256c66c9c91f407a9b576700207eb23113d6b0bde759e1281a6]]]As shown in Figure 5-28, the softmax layer normalizes the input values—transforms them so that the output sums to 1—and outputs them. Note that handwritten digit recognition classifies 10 classes, so there are 10 inputs to the Softmax layer.

[[[00000000000000000850---f9c1d7177871ad1c575e2ea6a1c076c5e80d107ff4d0f7d963a167ee4ebf7ca2]]]There are two phases in neural network processing: inference and learning. Neural network inference typically does not use softmax layers. For example, when performing inference with the network in Figure 5-28, the output of the last Affine layer is used as the recognition result. In addition, the non-normalized output result of the neural network (the output of the Affine layer before Softmax in Figure 5-28) is sometimes called the 'score'. This means that if your neural network infers only one answer, you are only interested in the maximum score, so you don't need a softmax layer. On the other hand, when training neural networks, softmax layers are required.

[[[00000000000000000851---d14011404e61458bcbc00472db4252cf6ca526d64f73f0c48b1567b9c95669c4]]]We are going to implement a softmax layer, but here we will implement it in a layer named 'Softmax-with-Loss layer', including the loss function, the cross entropy error. Figure 5-29 shows the calculation graph of Softmax-with-Loss layer (softmax function and cross-entropy error).

[[[00000000000000000852---89a36877e8b32982cfe97c22928dcb14e12697c75d0c331061c55ed105405648]]]
Figure 5-29 Computation graph of Softmax-with-Loss layer


[[[00000000000000000853---3957853938aafb3178f0861686faa3efab40729c7e1ea81a57a7b7268512422c]]]As you can see, the Softmax-with-Loss layer is a little more complicated. Only the results are shown here, but those who are interested in the derivation process of the softmax-with-loss layer can refer to 'Appendix A Computation graph of the softmax-with-loss layer'.

[[[00000000000000000854---25569d67c372974ba3937fe293415cb5a1622a52de28ceb2b9433ceff19ce575]]]The computation graph in Figure 5-29 can be simplified and written as shown in Figure 5-30.

[[[00000000000000000855---b1df0995416e3d02109d2197381d87e96b6446034713081344b07bc7321ce007]]]
Figure 5-30 Computational Graph of 'Simplified' Softmax-with-Loss Layer


[[[00000000000000000856---1b21d9ea049a0e380b79bb4d5af408f7ac91d298ff171be6e3fa7f9a09eaf4d3]]]In the computational graph of Figure 5-30, we represent the softmax function as the Softmax layer and the cross entropy error as the Cross Entropy Error layer. Here, we assume that we are doing a 3-class classification and that we receive 3 inputs (scores) from the previous layer. The softmax layer normalizes the input (a1, a2, a3) and outputs (y1, y2, y3), as shown in Figure 5-30. The Cross Entropy Error layer takes the output of Softmax (y1, y2, y3) and the teacher labels (t1, t2, t3) and outputs the loss L from those data.

[[[00000000000000000857---3ae9cd85fc9b6280745a127ad9b3bbebcad12d8304382fc9d6b7ca82885ba2d5]]]Of note in Figure 5-30 is the result of backpropagation. Backpropagation from the softmax layer gives a 'clean' result of (y1−t1, y2−t2, y3−t3). (y1, y2, y3) are the outputs of the Softmax layer, and (t1, t2, t3) are the training data, so (y1−t1, y2−t2, y3−t3) are the differences between the output of the Softmax layer and the training labels. Become. In backpropagation of the neural network, this error, which is the difference, is propagated to the previous layer. This is an important property in neural network learning.

[[[00000000000000000858---85a90a6a9ba56d732bcf9f82b6f2631bf50c01270ecaeae13ef7741c54bd0ab5]]]By the way, the purpose of training the neural network was to adjust the weight parameters so that the output of the neural network (output of Softmax) is closer to the teacher label. Therefore, it is necessary to efficiently convey the error between the neural network output and the teacher label to the previous layer. The previous result (y1−t1, y2−t2, y3−t3) is exactly the difference between the output of the Softmax layer and the teacher label, and it honestly represents the error between the current neural network output and the teacher label. is.

[[[00000000000000000859---1bc947a0406dca8a58f9d849dffe6e072854bd64638945c74bb8d98b9e23f357]]]Using the 'cross-entropy error' as the loss function of the 'softmax function', the backpropagation gave a 'beautiful' result of (y1−t1, y2−t2, y3−t3). In fact, such a “clean” result is not a coincidence, a function called the cross-entropy error was designed to do so. In regression problems, the 'identity function' is used for the output layer, and the 'sum of squared error' is used for the loss function (see '3.5 Designing the output layer') for the same reason. In other words, if you use the 'sum of squared error' as the loss function of the 'identity function', the backpropagation will give a 'beautiful' result of (y1−t1, y2−t2, y3−t3).

[[[00000000000000000860---c15e82a5f54118fa5a934f22996e40488b1aa0910cbd388317d3c38fb23d3a38]]]Let's consider a concrete example here. For example, for data with teacher labels of (0, 1, 0), the output of the softmax layer was (0.3, 0.2, 0.5). The probability for the correct label is 0.2 (20%), so the neural network at this point cannot recognize it correctly. In this case backpropagation from the softmax layer will propagate a large error of (0.3, −0.8, 0.5). This large error propagates to the previous layers, so the layers before the softmax layer will learn a lot from the large error.

[[[00000000000000000861---fd832c3c18f6f916969854018b0f0bb4954e83488851f7b19233c6ceca984c4f]]]Also, as another example, consider the case where the output of the Softmax layer is (0.01, 0.99, 0) for data with teacher labels of (0, 1, 0) (this neural network is fairly accurate are recognized). In this case, backpropagation from the softmax layer will result in a small error of (0.01, −0.01, 0). This small error propagates to the previous layers, but since the error is small, the layers before the softmax layer learn less.

[[[00000000000000000862---cfb9f34d8eb246ca597b4ecb344c1eb1f03f2d953ef1e8b4979090077df4f77e]]]Now let's implement the Softmax-with-Loss layer. A Softmax-with-Loss layer can be implemented as follows:

[[[00000000000000000863---a99f21325e952f8a3c99a7058c1713bba77bad8f94f170ed48f4dbc90aca429b]]]# loss

[[[00000000000000000864---dc767fcfe45e33d132a9565d3603663a15e6d16cd4d97370091f27a8b6ec640b]]]# softmax output

[[[00000000000000000865---7f55f4c13ce6da6c48881d794ab17e5901d9d34cc4a652a3e855d5c4047b8ac5]]]# Teacher data (one-hot vector)

[[[00000000000000000866---6d871c791424e6f69788dfb841fe21f5315212b02e7a5cfa6af5a7466d59eab9]]]In this implementation, we use the functions—softmax() and cross_entropy_error()—implemented in “3.5.2 Notes on implementing the softmax function” and “4.2.4 [Batch-compatible version] Cross-entropy error implementation”. doing. So the implementation here is very simple. Also note that when backpropagating, the error per data is propagated to the previous layer by dividing the propagated value by the number of batches (batch_size).

[[[00000000000000000867---7d34b71bc4ef272af1818492803780b537ed5fd8362a8a111fe262ed76804fcf]]]Implementation of backpropagation

[[[00000000000000000868---56585624a3e87a0be92aef9ece0e7de3212ed1d71bcc1073fd8350690d294d80]]]By combining the layers implemented in the previous section, you can build a neural network as if you were combining Lego blocks. Here, we will build a neural network by combining the layers we have implemented so far.

[[[00000000000000000869---21492d63f09c9f8facf9610c344db2e12e7dcd58bdfef5ef2d9cbc4e0d5d90e1]]]Overall diagram of neural network learning

[[[00000000000000000870---10a656f78ab8a8e9679196eebb1adb69ee8483e568c06d403342622b89bc012b]]]This is getting a little long, so let's review the big picture of neural network training before we dive into the specific implementation. Next, the neural network learning procedure is shown.

[[[00000000000000000871---bb9f5f19c7f14c1c83bc2f60c8b6b533ef8da215dc1b1ce8125546531c5951db]]]premise

[[[00000000000000000872---7fcbd656131441754c8de3ad30317ee2560bebdbf3b7be3c5117ef2e2c2c972a]]]Neural networks have adaptive weights and biases, and adjusting these weights and biases adaptively to training data is called 'learning.' Neural network training is performed in the following four steps.

[[[00000000000000000873---ff35bb1782b003c5652590e6dc4c3b22802e4740e6c25077880e42cd495a28eb]]]Step 1 (mini-batch)

[[[00000000000000000874---34de03174951333a45b7f0e5e2dc935f041ab8e23504c1a0bc2c461d235da669]]]Randomly select some data from the training data.

[[[00000000000000000875---cbf6fb02e308f7ba7bf5604e82f4615e67e9ee373f3388e721e0646d6b0681ce]]]Step 2 (Slope Calculation)

[[[00000000000000000876---3f56ccf78562cda27cc6b363ae591e05163d7f1bd8978d06bc672be472e93b60]]]Find the slope of the loss function for each weight parameter.

[[[00000000000000000877---6c38142ce74803c319b99967ef878fbbfd1b1af802867e8daca160be4310757c]]]Step 3 (Update parameters)

[[[00000000000000000878---489fc9d1cf1b1e3dc70c4bbb7d34279fd849c9c8407e9478f128c5834ac90707]]]The weight parameter is updated by a small amount in the direction of the gradient.

[[[00000000000000000879---d8d2067db934a21e3070adbc16e44d16a7edaf5a9f07a504704ad019a490fab9]]]Step 4 (repeat)

[[[00000000000000000880---4afeefc5fcb1318c31f20095924ca1e0ea4c3b0a3d41430ac016deb2ad0cb595]]]Repeat step 1, step 2, and step 3.

[[[00000000000000000881---09466c954484d899ffb66960c4fd36fc7a8705211dfb30f6b104b6ae64e6451e]]]The error backpropagation method described so far comes into play in Step 2, 'Computing the Gradients.' In the previous chapter, we used numerical differentiation to find this gradient. By using the error backpropagation method, the gradient can be obtained quickly and efficiently, unlike the time-consuming numerical differentiation.

[[[00000000000000000882---071d1f6a7d38a3abb3354bc19b4e860ae57bc4ccadf6d5afea70a5dca53f99b8]]]Implementation of Neural Network for Backpropagation

[[[00000000000000000883---416f16e7a0655b1a8c8bffb77b46d84eeb9bc393473008d852a128e15370251c]]]Now let's do the implementation. Here, we will implement a two-layer neural network as TwoLayerNet. First, the instance variables and methods of this class are organized and shown in Table 5-1 and Table 5-2.

[[[00000000000000000884---8ab9e3f4d0bb1845917a3ab76a8ef0f10fdbf689f4c3e46ef2e182c30727d7ff]]]Table 5-1 Instance Variables of the TwoLayerNet Class

[[[00000000000000000885---4376f0ba8b9327e8f33afe1c55f19c6442fbbae4fe8669a2c6a5649842eb806c]]]instance variable

[[[00000000000000000886---9683551a843c71d8b84ba930126021ef40831ee11bd5e69b06a3ea589148bba6]]]explanation

[[[00000000000000000887---eac86dfe74837cdce7f00bb6a80febcda18434e784dc46cd83cb5f1fe53edaa8]]]A dictionary variable that holds parameters for the neural network.

[[[00000000000000000888---eec89f1b0d665d974f6ec7ab3e5c31aa304c22088d23ae1a0316916bbc8c4551]]]is the weight of the first layer,

[[[00000000000000000889---ccb568959194b51a7f7430fb918d6e0a8fbeb8cf4e37545dd63824a0512dccc5]]]is the first layer bias.

[[[00000000000000000890---a797534e61782100bce2f34f0b2b9ec7b8ddb4d55dfab3d6af379adaadd2cc1f]]]is the weight of the second layer,

[[[00000000000000000891---600ed542d29447f137a50ca188d61f7662e2bdd3a27579dff96547eca50c87d4]]]is the second layer bias.

[[[00000000000000000892---be5fa246b506095d61d649e955511f80c51517864bc904ec3850a773a80b076b]]]holds the layers of the neural network

[[[00000000000000000893---0e7c5ba3246e432fe21b7e3407871870e966a07925cbb0840acda71ec320f5b0]]]ordered dictionary

[[[00000000000000000894---deaefb5029187716edadda70cffd97ac0344f9eee952086cbea94c25e521c35a]]]variable.

[[[00000000000000000895---e8eb8a095e2354383d3f3e6ece8481fa3a0427afd7b06328cded6bfbe5562a66]]]and so on

[[[00000000000000000896---0e7c5ba3246e432fe21b7e3407871870e966a07925cbb0840acda71ec320f5b0]]]ordered dictionary

[[[00000000000000000897---0baa23ea4d8d6611a62407233f7d3612ce6388c8e5aeb00b09470da11b7e66d5]]]to keep each layer in .

[[[00000000000000000898---76112d0bd37287a1786531ac3bfc7e4fb737762e91d0749de8ec73ef0c1de6bc]]]Last layer of the neural network.

[[[00000000000000000899---91a8c1cfefd5e11c03c9aa88205d998bebaa9a0e69ce398a9efbb20634f1e659]]]In this example,

[[[00000000000000000900---48d89bc5e9988302b8e9898232c1307c84a3ccb0bd44d700ac250bb4d87af8fb]]]layer.

[[[00000000000000000901---13f5529fd155505bc35c9b8850c50fbf7fe0fe3696a2a74b241689aae23afd40]]]Table 5-2 Methods of the TwoLayerNet Class

[[[00000000000000000902---99942ce88f0b978ae878a57b8584fb85b2d2fbbad57b31929100a7363d500b02]]]method

[[[00000000000000000903---9683551a843c71d8b84ba930126021ef40831ee11bd5e69b06a3ea589148bba6]]]explanation

[[[00000000000000000904---9c85880f483ef1a30b1b6d1b9eee38a6ea2a5e5bd09ad3213ce365568782d731]]]Initialize.

[[[00000000000000000905---6cc664745b02cd1e7690bd6aa997d2164f0ee0c47214669ad2f12f90210ac5a1]]]The arguments are, from the top, the number of neurons in the input layer, the number of neurons in the hidden layer, the number of neurons in the output layer, and the scale of the Gaussian distribution at the time of weight initialization.

[[[00000000000000000906---ef670f48347db3637ea83e1f587d5fe2111512c5c76a762d22da41d497fd730c]]]Recognize (infer).

[[[00000000000000000907---8f0e863bf02b3043e1f2142321fb02ff777e7bd7ed7fa4f4261a7dff5c42ca82]]]of the argument

[[[00000000000000000908---c281dc55ae1a991d806e506395e4acbfd4677554405fb0feb719d79910a19571]]]is image data.

[[[00000000000000000909---2b576a23c2464d5f867a8eb2e211aaa0a48dc212ff5ab4284103919ccfb3412d]]]Find the value of the loss function.

[[[00000000000000000910---8f0e863bf02b3043e1f2142321fb02ff777e7bd7ed7fa4f4261a7dff5c42ca82]]]of the argument

[[[00000000000000000911---22a5f2a63996157de316b0d10a97211371ebf2db7a5f2bb1548d35ede1fa08bf]]]is image data,

[[[00000000000000000912---0ac20473b3726350cff40d8764f68d6aa832b6010fdce554d6d63067f6988d47]]]is the correct answer label.

[[[00000000000000000913---ec575dbf741773e1ca718afa2fa0ed3edb05b360e9714eb072f5052ac85014e5]]]Find recognition accuracy.

[[[00000000000000000914---bc4f4f7796caa1757fb5af8773c3b6259db67f6b54e8a7f51c301603c8f72616]]]Obtain the gradient for the weight parameter by numerical differentiation (same as in the previous chapter).

[[[00000000000000000915---3e24c762e1e8a2c5f8cbdd7f388175a5fe7fc4198858b2ccf67726cc9c606e29]]]Gradients for weight parameters are obtained by error backpropagation.

[[[00000000000000000916---74237416f4c587b976d7198dbb4475eaf7737daf9594528d2bf6c192b9c5e5b4]]]The implementation of this class is a little long, but the content of the implementation has many parts in common with '4.5 Learning Algorithm Implementation' in the previous chapter. The main change from the previous chapter is the use of layers. By using layers, the process of obtaining recognition results (predict()) and the process of obtaining gradients (gradient()) can be achieved simply by layer propagation. Now for the implementation of TwoLayerNet.

[[[00000000000000000917---d7f2704dda40d0528bed1e8e16c66e17b842f50172d7ba8554f23c7229aedc67]]]# Initialize weights

[[[00000000000000000918---7021dcf7079c3447ef0d2e8d46d15dccd4766f8901ea1ef36ddeb4d848ec3fff]]]# create layers

[[[00000000000000000919---3be1559c2728443f7c759c3afe3584849fc8c1ea668b1700faae69229fb3339d]]]# x: input data, t: training data

[[[00000000000000000920---3be1559c2728443f7c759c3afe3584849fc8c1ea668b1700faae69229fb3339d]]]# x: input data, t: training data

[[[00000000000000000921---218e9c76d5eb7001307fd43bd158c9d45ec20893a3e2da4fbc00de3a7142e876]]]# setting

[[[00000000000000000922---9f8958524738b9a63d6e2ce6a1c6cb96555d71871004637459b0e9f75b24cffd]]]Note the code in bold in this implementation. In particular, it is important to keep the layers of the neural network as an OrderedDict. OrderedDict is an ordered dictionary. 'Ordered' means that you can remember the order of the elements added to the dictionary. Therefore, in forward propagation of neural networks, processing is completed simply by calling the forward() method of the layers in the order in which they were added. Also, backpropagation simply calls the layers in reverse order. Affine and ReLU layers handle forward and backpropagation correctly inside each other, so all we have to do is concatenate the layers in the correct order and call the layers in order (or in reverse order). is.

[[[00000000000000000923---c96a013204b99d550352d6da5500b5070e0ba9141ee492123eca690f6c2adbea]]]By implementing the components of a neural network as 'layers' in this way, we were able to easily build a neural network. The benefits of this modularized implementation as 'layers' are enormous. Because if you want to make another network -- say 5 layers, 10 layers, 20 layers, and so on and so on -- you can create a neural network by simply adding the layers you need (like like building Lego blocks). After that, the gradients required for recognition processing and learning are correctly obtained by forward and backward propagation implemented inside each layer.

[[[00000000000000000924---50a5da8756182db35215376b334ddb37bf368a421019239b761d3aab9959526b]]]Backpropagation Gradient Check

[[[00000000000000000925---a948191797edef26f31643ec7531516322cc852591e8f0368bd15ebce7eb20ba]]]So far we have discussed two ways to find the gradient. One is a method of obtaining by numerical differentiation, and the other is a method of solving numerical formulas analytically. As for the latter analytical method, by using the error backpropagation method, we were able to perform efficient calculations even when there were a large number of parameters. So from now on, let's find the gradient by backpropagation instead of the time-consuming numerical differentiation.

[[[00000000000000000926---0a91447f61496734df8bf8515973389100f67aa1acaa790f4e207eaca0deecb1]]]Now, numerical differentiation takes time to calculate. And if you have a (correct) implementation of backpropagation, you don't need a numerical differentiation implementation. If so, what's the use of numerical differentiation? In fact, the practical need for numerical differentiation is to confirm the correctness of the implementation of the backpropagation method.

[[[00000000000000000927---8f387f5c6ecc2f3ca0957199000d7fb6a1fa23db61c8c7243f863cdcd63c1b8d]]]The advantage of numerical differentiation is that it is easy to implement. Therefore, implementation of numerical differentiation is less error-prone, while implementation of backpropagation is more complicated and error-prone. Therefore, it is common to check the correctness of the implementation of the backpropagation method by comparing the results of the numerical differentiation and the backpropagation method. It should be noted that the work of confirming that the result of the gradient obtained by numerical differentiation and the result of the gradient obtained by the backpropagation match—more precisely, that they are almost close to each other—is called the gradient check. )Is called. So here's the gradient check implementation (source code is in ch05/gradient_check.py):

[[[00000000000000000928---05c3b68912d36a95e530e768bb3c99298575fcfd017e4b2f5fabaf04b0aaf74c]]]# load data

[[[00000000000000000929---7da40af32f789cff6ffe00a923e7722e81573d2c1da74f8f67dfd91ff91a8535]]]# Find the average absolute error for each weight

[[[00000000000000000930---87852a3e4ece26379fa49af43ab348f2150c2ecd97da87dc3365f23f686bcf34]]]Load the MNIST dataset as usual. Then, using a portion of the training data, we check the error between the gradient obtained by numerical differentiation and the gradient obtained by error backpropagation. Here, as the error, the absolute value of the difference of the elements in each weight parameter is obtained, and the average is calculated. Running the code above will print the following:

[[[00000000000000000931---8383f9e50efae5d7f7ccb88f6b8adccfeead2ccf174449856ed52a390ad893f5]]]From this result, we can see that the difference between the gradients obtained by numerical differentiation and error backpropagation is rather small. For example, the bias error for the first layer is 9.7e-13 (0.00000000000097). This ensures that the backpropagation gradients are also correct, increasing confidence that the backpropagation implementation was correct.

[[[00000000000000000932---ed476a675fa9b44d16abbdaf10cfe878223f090684751a90107dc65265800a8c]]]Numerical differentiation and error backpropagation rarely result in zero error. This is because computer calculations are done with finite precision (eg 32-bit floating point numbers). Due to numerical precision limitations, the above error is usually not zero, but with a correct implementation the error is expected to be small and close to zero. If the value is large, there is an error in the implementation of the backpropagation method.

[[[00000000000000000933---e16f100cbf263b0b6891fbc9a50fa13c5f5a45c6dcd28bcc25cd5fe59f516cee]]]Training using backpropagation

[[[00000000000000000934---7af2315cf6d44f00d592bf8cf080c8c33b72e4ba9fd2d6009543416ac497e7fd]]]Finally, I will post an implementation of neural network training using backpropagation. The only difference is that the backpropagation method is used to find the gradient. Here, only the code is shown and the explanation is omitted (the source code is in ch05/train_neuralnet.py).

[[[00000000000000000935---05c3b68912d36a95e530e768bb3c99298575fcfd017e4b2f5fabaf04b0aaf74c]]]# load data

[[[00000000000000000936---5b7eb5845030ba835fd3fea3bcf6b3cefed63f7d6f47af008a06570942c3c450]]]# find the gradient by backpropagation

[[[00000000000000000937---6d52970b6be23258a830a73507086d3e02737cc1e48d6de8ba1978b871c6a42f]]]# update

[[[00000000000000000938---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000000939---597bb3d3653642b806cc3591b488a3dc5490ca65c34f7c3f4295b2bd46fc371f]]]In this chapter, we learned a method called a computation graph that visually represents the process of computation. Using this computational graph, I explained the error backpropagation method performed by the neural network, and implemented the processing performed by the neural network in units called layers. For example, ReLU layer, Softmax-with-Loss layer, Affine layer and Softmax layer. These layers implement forward and backward methods to propagate data forward and backward to efficiently find the gradient of the weight parameter. This layered modularization allows the layers to be freely combined in a neural network, making it easy to create a network of your choice.

[[[00000000000000000940---19850c73ec605a12530fa271fcc972171b998181be314b2c4c58825fcf2e154b]]]What we learned in this chapter

[[[00000000000000000941---ddae0610fc7b476abc2f906b6d1834833f43888141ccd3e454577cb0e8f229f4]]]By using a computational graph, it is possible to visually grasp the computational process.

[[[00000000000000000942---a79128d80567936741a45cbc71bc7f63fee0b60e097d997bedd4d6d5d2562415]]]Nodes of a computation graph are constructed by local computations. Local computations make up the overall computation.

[[[00000000000000000943---54d75b98f93d65a6595fd5d8bbf3510d2ca1bfe55c833a3a4f62b312213376c8]]]Forward propagation of the computation graph performs normal computation. On the other hand, the differential of each node can be obtained by backpropagation of the computational graph.

[[[00000000000000000944---65bb669ee441d3ab8c8bdd437dc363873d3f0331fcafb0440db2d7a54ac0c255]]]By implementing the neural network components as layers, the gradient computation can be obtained efficiently (backpropagation).

[[[00000000000000000945---489957f72a5496486e24df06b455691b571f803dd59909ab4e6f53cbf57e55ce]]]By comparing the results of numerical differentiation and backpropagation, it is possible to confirm that the implementation of backpropagation is error-free (gradient check).

[[[00000000000000000946---97edc33d5cbc5407b531f0ac3f29f91262da2bd25163647785cdb772074f3800]]]O'Reilly Japan, Inc. has made every effort to ensure the accuracy of the contents of this document, but please understand that we are not responsible for the results of operations based on the contents of this document.

[[[00000000000000000947---dc2b80b894af57cc835682925f920e551f30ad1dafed531db34f2b7458d4e35a]]]Deep Learning from scratch

[[[00000000000000000948---52a34dffd794c6bfc4a6c8a35fbb16469dfb47e9a5888f6a668efe467553a4c0]]]Theory and Implementation of Deep Learning in Python

[[[00000000000000000949---9be8f4cfe4790acfea5d166fc2925948ebba54dcc0b05c9dc4d212c3c07b9a9d]]]September 28, 2016 1st edition first issue

[[[00000000000000000950---126eee6b04ded303d3a8ff498af13baceae81f0ab95c742f65eeeaf1a71e7e4a]]]
December 2, 2022 First edition 15th edition issued

[[[00000000000000000951---f2f5b6f470310eaf5a90b614a718214b9b06a6adc028924fc6a0d8ba94857806]]]Author Yasutake Saito

[[[00000000000000000952---16f1fe5d091f36817279a9042f8e7f2e6ad26cd5721935ce9cf0857d2ba4fffb]]]Published by Tim O'Reilly

[[[00000000000000000953---e892f0b49ac7c195817b2cb6f935741d2a6d67d4e082b402c808644ac63fb9ef]]]Publisher　　　

[[[00000000000000000954---5120b30e23f0646f3a418cbb6d18df0283e91b171be2b9c3a910b3aff3d0337e]]]O'Reilly Japan Co., Ltd.

[[[00000000000000000955---173f76b1e0e52042ce8770cd7df500066657395900d568d00501179717b0fdf9]]]
　　　　　　12-22 Yotsuyazaka-cho, Shinjuku-ku, Tokyo 160-0002

[[[00000000000000000956---e670ad760848546aa0571bd75410cabcb7eaedab59ad888830f53973b3d582cc]]]
　　　　　　e-mail 

[[[00000000000000000957---f6191178ed3d59d9934e432efc352d4e7d09dc7cdbff312412f9a051ce5b5012]]]production cooperation　　

[[[00000000000000000958---525b80b0d33a191efc087976b152945e86bb5fa5894b81a40506dc24e8ae8f94]]]Top Studio Co., Ltd.

[[[00000000000000000959---dba6f0d126a635bb9165e613e13503eec4ebe84a53f470a1bd360d8a7fbea171]]]System names and product names used in this document are trademarks or registered trademarks of their respective companies. Note that the ™, ®, and © marks may be omitted in the text.

[[[00000000000000000960---97edc33d5cbc5407b531f0ac3f29f91262da2bd25163647785cdb772074f3800]]]O'Reilly Japan, Inc. has made every effort to ensure the accuracy of the contents of this document, but please understand that we are not responsible for the results of operations based on the contents of this document.

[[[00000000000000000961---dc2b80b894af57cc835682925f920e551f30ad1dafed531db34f2b7458d4e35a]]]Deep learning from scratch

[[[00000000000000000962---52a34dffd794c6bfc4a6c8a35fbb16469dfb47e9a5888f6a668efe467553a4c0]]]Theory and Implementation of Deep Learning in Python

[[[00000000000000000963---f18f6f9783a1c8de9a24cf9c9210b59e4d725b724e6c50464d4714e65306977a]]]Written by Yasuki Saito

[[[00000000000000000964---ca67ef85c9beb2732d0b96ad2113e21ef67f973eb3711ad3b94163c5d7b4a709]]]Chapter 7

[[[00000000000000000965---7be20f9abf835eb98ef542048cbda54ff342ebb3d7efce4987aad7ad37cd7746]]]convolutional neural network

[[[00000000000000000966---780e2ac6eaf315c7d7e270187037e0c0a1d91a87fedcb2b1aa8fede354b4e0d0]]]The topic of this chapter is convolutional neural networks (CNNs). CNN is used everywhere, such as image recognition and speech recognition. Also, in image recognition competitions, almost all deep learning methods are based on CNNs. In this chapter, we will explain the mechanism of CNN in detail and implement its processing contents in Python.

[[[00000000000000000967---0e7b7d2491a5b7dfbcedb48621310af4853686a057d26f8b774d7c2996cfe10b]]]overall structure

[[[00000000000000000968---c562419db96f6112053979897f10615eb8dd7d8431a1f1470c9b2640bc25691f]]]First, in order to understand the outline of CNN, let's look at the network structure of CNN. CNN is the same as the neural networks we have seen so far, and can be created by combining layers like Lego blocks. However, in the case of CNN, a new 'Convolution layer' and 'Pooling layer' will appear. The details of the convolutional and pooling layers will be explained in the next section, but here we will first look at how the layers are combined to build a CNN.

[[[00000000000000000969---5e12182cb4a832e19a663e5e0d05c7061a88513c794ec87dcf0ad62a1a7e57c5]]]Now, the neural networks we've seen so far have connections between all neurons in adjacent layers. We call this fully-connected, and we have implemented a fully-connected layer with the name Affine layer. Using this Affine layer, for example, a 5-layer fully-connected neural network can be realized with a network configuration as shown in Figure 7-1.

[[[00000000000000000970---81c4cf29ac510538e9cfd41b3d607f58785520f3e86cacea0941ae34fb100397]]]
Figure 7-1 Example of a network with fully connected layers (Affine layers)


[[[00000000000000000971---dd5253b2093fa831ea0cdbbd9cf8d419ddd2fd19ea0fa1a1ff943942ceea5e81]]]As shown in Figure 7-1, a fully-connected neural network consists of an Affine layer followed by a ReLU layer (or Sigmoid layer) of activation functions. Here we stack 4 layers of 'Affine - ReLU' combinations, followed by a 5th Affine layer, and finally a Softmax layer to output the final result (probability).

[[[00000000000000000972---3f5f46e7296f0e0586805250b004f09563656a06ad26837f972f93a1668b5d42]]]So what will the CNN consist of? Figure 7-2 shows a CNN example.

[[[00000000000000000973---394e82324e42b41b5aa7d2938c423415469e2e8d0ffe6f0ffc0a87aaa9b549c6]]]
Figure 7-2 An example of a network using CNN: Convolution layer and Pooling layer are newly added (each drawn as a rectangle with a gray background)


[[[00000000000000000974---1dcd494b17ed75aef4113f038b22a23d0900d63a9d161c27914d6e58e7515687]]]As shown in Figure 7-2, CNN adds a new 'Convolution layer' and 'Pooling layer'. The connection order of CNN layers is 'Convolution - ReLU - (Pooling)' (Pooling layers are sometimes omitted). This can be thought of as replacing the connection of 'Affine - ReLU' with 'Convolution - ReLU - (Pooling)'.

[[[00000000000000000975---119ebfa015f56c6eb7622c509ae409e18497bef9243a68427db3508c0052e976]]]Another thing to notice about the CNN in Figure 7-2 is that the layer close to the output uses the traditional 'Affine - ReLU' combination. Also, in the last output layer, the previous 'Affine - Softmax' combination is used. These are common configurations found in common CNNs.

[[[00000000000000000976---c01c73e603a6389dfda016595767246d471db92ecc5c5041d7a61fe366d508bc]]]convolutional layer

[[[00000000000000000977---d3bf48851bddf4fd98fb0a99a37911cd70d955c4d27aba173c2f6a3ee8c72dc6]]]CNN comes up with CNN-specific terms like padding, stride, etc. In addition, the data flowing through each layer becomes data with a shape (for example, three-dimensional data), which is different from the fully connected networks of the past. Therefore, when learning CNN for the first time, it may feel confusing. Here, I would like to spend some time looking at how the convolutional layers used in CNNs work.

[[[00000000000000000978---f8450e4f5191abb07d6c91cd106f36c8bedc5ca0b190031ab296c08191c70534]]]Problems of Fully Connected Layers

[[[00000000000000000979---9cb8c3169943f2cf908d7a59fe02ae45b4b30c8fa4c3bc308b7de5174bb7cdd9]]]The fully-connected neural networks we have seen so far have used fully-connected layers (affine layers). In a fully connected layer, all neurons in adjacent layers are connected, and the number of outputs can be arbitrarily determined.

[[[00000000000000000980---97874929120d069b3b727a69247cf69a8585dc185f2853fba48e7de76915641d]]]What is the problem with fully connected layers? The problem is that the shape of the data is 'ignored'. For example, if the input data is an image, the image is usually a three-dimensional shape with vertical, horizontal, and channel directions. But when inputting into a fully connected layer, we need to flatten the 3D data—the 1D data. In fact, in the previous examples using the MNIST dataset, the input image had the shape of (1, 28, 28)--one channel, 28 pixels high by 28 pixels wide--and arranged them in a row. We input 784 data into the first Affine layer.

[[[00000000000000000981---31bf6556a53c20a42674439e4851b350f8b72163b0988bcd7c136c8fa08217a8]]]An image is a three-dimensional shape, and this shape may contain important spatial information. For example, pixels that are spatially close have similar values, RBG channels have close relationships with each other, pixels that are far apart have little relationship, and so on. There must be an essential pattern hidden in the shape of the . However, fully connected layers ignore shape and treat all input data as equivalent neurons (neurons of the same dimension), so shape information cannot be used.

[[[00000000000000000982---320cfb1a68c7519910d2f0a573ff661205a1a93afdd8000e955faf6b82557b46]]]Convolution layers, on the other hand, preserve shape. In the case of images, it receives the input data as 3D data and outputs the data to the next layer as 3D data as well. Therefore, CNN can (potentially) correctly understand data with shapes such as images.

[[[00000000000000000983---cdbf1510e035b9a1956b458b96eb3ff3a11cbe121e5f8b33620c0e7f92aae093]]]In CNN, the input/output data of the convolutional layer is sometimes called a feature map. Furthermore, the input data of the convolutional layer is called the input feature map, and the output data is called the output feature map. In this document, the terms 'input/output data' and 'feature map' are used interchangeably.

[[[00000000000000000984---a9d72488fe5236f7246394319af1ea4734f255a186c84e3809a3e04b50202676]]]convolution operation

[[[00000000000000000985---4e06c9d11a079428b76f41b5d69e2f3dd6cfc35bd42b18a40f24c377560aeb38]]]The processing performed in the convolution layer is 'convolution operation'. Convolution operation is equivalent to 'filter operation' in image processing. To explain the convolution operation, let's look at a specific example (Figure 7-3).

[[[00000000000000000986---e69e0c7f469ba0ee06b0328a57941a9ce4171e340b0ab83447a895788ff33ff1]]]
Figure 7-3 Example of convolution operation: notation of convolution operation with '' symbol


[[[00000000000000000987---cea7f9a0a6ded91eced4c473dafc87c5f36be7101ba875f1303f5dc0eff454db]]]The convolution operation applies a filter to the input data, as shown in Figure 7-3. In this example, the input data has vertical and horizontal dimensions, and the filter has vertical and horizontal dimensions as well. Assuming the shape of the data and filter is notated by (height, width), in this example the input size is (4, 4), the filter size is (3, 3), and the output size is (2, 2). . Note that, depending on the literature, the term 'filter' as described here is sometimes expressed by the term 'kernel'.

[[[00000000000000000988---da3e8b341989dab0b1504cc940fe840128fd8aff4f0c7347c1df0c56e67d56cd]]]Now let's explain what kind of calculations are performed in the convolution example in Figure 7-3. Figure 7-4 illustrates the calculation steps for the convolution operation.

[[[00000000000000000989---75c69cb94fbaa337e28daf42677ef20ee35d2dbd1c28f9acb4ce0ff87c4f0962]]]
Figure 7-4 Calculation procedure for convolution operation


[[[00000000000000000990---223d7096607887d545d071bed99286cacfd831a5b5822cd391b9be745d7f1773]]]The convolution operation is applied to the input data while sliding the filter window at regular intervals. The window here refers to the gray 3x3 area in Figure 7-4. At each location, the elements of the filter are multiplied by the corresponding elements of the input and summed, as shown in Figure 7-4 (sometimes called the multiply-accumulate operation). It then stores the results in corresponding locations in the output. Doing this process everywhere gives us the output of the convolution operation.

[[[00000000000000000991---187e78cf37488fac057af3ebdbd9be5160538dcf175fe8f90235df5ec8007ed2]]]Now, in a fully-connected neural network, there was a bias in addition to the weight parameters. For CNN, the parameters of the filter correspond to the 'weights' so far. And in the case of CNN, bias also exists. The convolution example in Figure 7-3 was shown up to the stage of applying the filter. The processing flow of convolution operation including bias is shown in Figure 7-5.

[[[00000000000000000992---3e7ac017c4398d664dcb1e173415d2d1429532555b19561a6a20bac810c25420]]]
Figure 7-5 Convolution Bias: Adding a Fixed Value (Bias) to Filtered Elements


[[[00000000000000000993---2dc9a95aaf73a24f10d85f96ff70f519ad7b35819cad18179e5d9711a7fdb46f]]]As shown in Figure 7-5, the addition of the bias term is done on the filtered data. As shown here, there is always only one bias (1 x 1) (in this example, one bias for four filtered data). That one value is added to all elements after applying the filter.

[[[00000000000000000994---9c0bee2f1a1e931c077c2670cc6249e93e5ddd6e51f557d10c50be9a9b1c5996]]]padding

[[[00000000000000000995---01bcbd448a884d256e1cccfe930f4df6c6101eb47240b6206deecf2bd8228853]]]The input data may be padded with fixed data (e.g. 0) before processing the convolutional layers. This is called padding, and is often used in convolution operations. For example, the example in Figure 7-6 applies padding of width 1 to input data of size (4, 4). 1-width padding means padding with 1-pixel wide 0s around it.

[[[00000000000000000996---82f225a82100b5d44ce7010640e179a5c017e9130c1dd7fc7d3f5b12d7535a30]]]
Figure 7-6 Padding processing of convolution operation: 0 is filled around the input data (in the figure, the padding is indicated by a dashed line, and the description of '0' in the content is omitted)


[[[00000000000000000997---a9b852b11f477f42ff1be03da23755de0382caee7ab0014bc11ee65193c1043b]]]Input data of size (4, 4) is padded to shape (6, 6), as shown in Figure 7-6. And a filter of size (3, 3) produces output data of size (4, 4). In this example, I set the padding to 1, but you can set the padding value to any integer, such as 2 or 3. If the padding is set to 2 in the example in Figure 7-5, the size of the input data will be (8, 8), and if the padding is 3, the size will be (10, 10).

[[[00000000000000000998---b46242fc86f35b34cf765a379c0cb8fe3c698cf1849b1bbcdee5daacae85b2a5]]]The main reason to use padding is to adjust the output size. For example, if you apply a filter of (3, 3) to input data of size (4, 4), the output size will be (2, 2) and the output size will be reduced from the input size by two elements. will be This is a problem for deep networks that perform many iterations of convolution operations. Because if it is spatially shrunk after each convolution, at some point the output size may become 1 and no further convolutions can be applied. Use padding to avoid such situations. In the previous example, if the padding width is set to 1, the output size will remain at (4, 4) for an input size of (4, 4). Therefore, the convolution operation allows data to be passed to the next layer while maintaining a constant spatial size.

[[[00000000000000000999---d1af7f2083febd2dee0a65da06742ebc315f6a8f0316b6275b188875fdc64330]]]stride

[[[00000000000000001000---48b699955d1491b44fddcea029e54e9a72a107e6a919ee0b4bf2322b4b6b7b38]]]The interval between positions where the filter is applied is called the stride. All of the examples we've seen so far have had a stride of 1, but for example, a stride of 2 would cause the filtered windows to be spaced every 2 elements, as shown in Figure 7-7.

[[[00000000000000001001---a33cce1a2e77f0f810f3f851ef0444ab0d39acbf44cf3dad38159407b020deb5]]]
Figure 7-7 Example of a convolution operation with a stride of 2


[[[00000000000000001002---22db308877040215c2f79a3098ae07f5f2b295a9fb6fdbc14498e89121560b38]]]The example in Figure 7-7 applies a filter with a stride of 2 for data with an input size of (7, 7). By setting the stride to 2, the output size will be (3, 3). Thus, stride specifies the interval at which the filter is applied.

[[[00000000000000001003---33a918b5ffdc915ce7686b948c1458c2147e8e62753d0b163c86bf298a9bdf9b]]]As we have seen, increasing the stride decreases the output size. On the other hand, more padding increases the output size. What happens when we formulate such a relationship? Next, let's see how the output size is calculated for padding and stride.

[[[00000000000000001004---5bc69f78b49f745e4d27e8a2e0c0378835196ede883675aa0a29313623d0254e]]]Here, let the input size be (H, W), the filter size be (FH, FW), the output size be (OH, OW), the padding be P, and the stride be S. In that case, the output size can be calculated by the following formula (7.1).

[[[00000000000000001005---7f69a2b1da19ef19831ee2d78c8200e99c9f6f5989fb6a4b1f6b92fd9b99b929]]]Equation (7.1)

[[[00000000000000001006---624da5c1ead7b59f54969fce988e0a8d7033a6790927c82fa97eafdd5b3622b7]]]Let's do some calculations using this formula.

[[[00000000000000001007---d249b60c886fa3eb1279408b38b27a57827de28753e5319d2b9f7ef3b64708ad]]]Example 1: Example of Figure 7-6

[[[00000000000000001008---afe4455d3e1fc9ee59571c67c8a005067bbae69939edbbc1f4b14a818c59c3fe]]]Input size: (4, 4), padding: 1, stride: 1, filter size: (3, 3)

[[[00000000000000001009---c0c66c87172b9d6818749eb4c2745f5c08a0d36b011731065828ebc45c7ad0b5]]]Example 2: Example of Figure 7-7

[[[00000000000000001010---dab71ba9b60e89819e01d3f4adb89b7981dcb47629dc853b9e37baa632b2dbe4]]]Input size: (7, 7), padding: 0, stride: 2, filter size: (3, 3)

[[[00000000000000001011---23ea56530a5ed0a79409d59b35e18662fb5b4d258671e4d0790996e7f791dbf5]]]Example 3

[[[00000000000000001012---9c39e1c5e1a318f718ae63400d379b92d697dc6b6f3ce16161ba87203c1d5412]]]Input size: (28, 31), padding: 2, stride: 3, filter size: (5, 5)

[[[00000000000000001013---cf7d436c960effb0a5aa0ebe8bfcdbfcb390a8460959de0a4008922dd2ffef48]]]As shown in these examples, the output size can be calculated by substituting the values into equation (7.1). The output size can be obtained by simply substituting, but the point to be noted here is that each value must be set so that and in formula (7.1) are divisible. If the output size is not divisible (if the result is a decimal), you need to respond by outputting an error, etc. By the way, depending on the deep learning framework, if the value is not divisible, it may be implemented by rounding to the nearest integer and proceeding without an error.

[[[00000000000000001014---16cd6a8877bed1c650b9565c7d87a6b0bab3635e5dec25dc098ed80d40ff89ba]]]Convolution operation of 3D data

[[[00000000000000001015---45e8b6df4b4e2a6a234366b2d49827acf6c82ccfb8f91e844f0486efa60e160d]]]The examples of convolution operations we have seen so far have been for two-dimensional shapes with vertical and horizontal dimensions. However, in the case of images, it is necessary to handle three-dimensional data that includes the channel direction in addition to the vertical and horizontal directions. Here, we will look at an example of performing a convolution operation on 3D data that also includes the channel direction using the same procedure as before.

[[[00000000000000001016---fcc6973cd79134dfe5dd929999ffbc732c13bedeca26448ba264bcf316587e80]]]Figure 7-8 is an example of a convolution operation. Figure 7-9 shows the calculation procedure. Here, we show the results of the convolution operation using 3-channel data as an example. Compared to the 2D case (example in Figure 7-3), we can see that the feature map has increased in the depth direction (channel direction). If there are multiple feature maps in the channel direction, the input data and filter are convolved for each channel, and the results are added to obtain a single output.

[[[00000000000000001017---e5c1c7ab9897ec2f6dc6ca7fbfa11b11b78a99137f23b0eab0474d716ca6d500]]]
Figure 7-8 Example of convolution operation on 3D data


[[[00000000000000001018---c5e12aa23b9305b9b5c781fa7362c4395623b2751ebd89d3e121bdf6c704f331]]]
Figure 7-9 Calculation procedure for convolution operation on 3D data


[[[00000000000000001019---a2001b4f6661c0527aca70956599df6f3b3697b20699b270fad2dc0e6deafac7]]]The point to be careful about in the 3D convolution operation shown in this example is that the input data and the number of channels of the filter must be the same value. In this example, both the input data and the filter have the same number of channels: 3. On the other hand, you can set the size of the filters to whatever you like (but all filters per channel have the same size). In this example the size of the filter is (3, 3), but you can set it to any value you like, such as (2, 2) or (1, 1) or (5, 5). But again, the number of channels can only be set to the same value as the number of channels in the input data—3 in this example.

[[[00000000000000001020---357664c22d02c3ca406ebabd52d2ba9632d6d384316153148ed5066a7ec098d8]]]think in blocks

[[[00000000000000001021---2421ea9ce73eb2086e18b6c63b50fc2b0e144febd13a07993a31d2bf8a7efc94]]]3D convolution operations are best understood by thinking of data and filters as rectangular blocks. A block is a three-dimensional cuboid, as shown in Figure 7-10. Also, when expressing 3D data as a multidimensional array, write them in the order of (channel, height, width). For example, the shape of data with number of channels C, height H, and width W is written as (C, H, W). Similarly, for filters, write in the order (channel, height, width). For example, if the number of channels is C, the height of the filter is FH (Filter Height), and the width is FW (Filter Width), write (C, FH, FW).

[[[00000000000000001022---0735860bf45018c2b7fd6451800d4df5a99a77d2f8c42dc393d0604f54922d88]]]
Figure 7-10 Think of a convolution operation in blocks. Note the shape of the block


[[[00000000000000001023---981fa9c8b451b96ff2db5ac9295d7f4bff53b3e0d9e2e505a8c49c1ea4a63ad4]]]Now, in this example the data output is a single feature map. A single feature map is, in other words, a feature map with one channel. Then, what should I do to have multiple outputs of the convolution operation in the channel direction as well? To do this, we use multiple filters (weights). Graphically, it looks like Figure 7-11 below.

[[[00000000000000001024---e0ef748e5706df13bf8dd105392648c8d5f42bb4bed42124ec62b8913abae20a]]]
Figure 7-11 Example of convolution operation with multiple filters


[[[00000000000000001025---ac931e0784a0024dd3d90538ea845c2c719225bea3c98c17a36723cc352e1e81]]]Applying FN filters also produces FN maps of the output, as shown in Figure 7-11. The FN maps are then put together to form a block of shape (FN, OH, OW). The processing flow in CNN is to pass this completed block to the next layer.

[[[00000000000000001026---a1b7a67f90d4629319cfbc881efcd3a5f7c87edf6a89e63ccdd9bea7d15d4a3b]]]As shown in Figure 7-11, we also need to consider the number of filters for convolution filters. Therefore, we will write the filter weight data in the order of (output_channel, input_channel, height, width) as four-dimensional data. For example, if you have 20 filters with 3 channels and size 5x5, write (20, 3, 5, 5).

[[[00000000000000001027---2dc75762d113a41e367820e7b732f7e4c9530cc83c98f8dfbe9c211204e791ab]]]Now, in convolution operations (as in fully connected layers) there is a bias. Adding bias addition processing to the example in Figure 7-11 results in the following Figure 7-12.

[[[00000000000000001028---cc798a284323224066829133fd3c84f23cd9bec6debfb48229216e5687fa7a8c]]]
Figure 7-12 Convolution operation processing flow (addition of bias term)


[[[00000000000000001029---9a320c09c24f79d82adee38db64436bc5fa1c141e756d5b18379344d186f72d6]]]Bias has only one data per channel, as shown in Figure 7-12. Here the shape of the bias is (FN, 1, 1) and the shape of the filter output result is (FN, OH, OW). The addition of these two blocks adds the same bias value per channel to the filter output result (FN, OH, OW). Note that addition of differently shaped blocks can be easily achieved by NumPy broadcasting (see 1.5.5 Broadcasting).

[[[00000000000000001030---c51b157077087190f1719b30ba63083d6f915ba9debc9c72f5664f0b8f56f8cf]]]Batch processing

[[[00000000000000001031---6034c5a7c74067cbf464f3df6eb6689117bcc5466e562f44047ba02bbfa7eac0]]]In neural network processing, batch processing was performed in which the input data were grouped together. Previous implementations of fully-connected neural networks also support batch processing, making it possible to improve processing efficiency and support mini-batches during training.

[[[00000000000000001032---5d7ad8cf40ffcc7594eb74e40cdd74b08dd29f73bb505ef760838c2235940e3e]]]I would like to support batch processing in the same way with convolution operations. Therefore, the data flowing through each layer is stored as four-dimensional data. Specifically, the data shall be stored in the order of (batch_num, channel, height, width). For example, if the processing in Figure 7-12 is batch processed for N pieces of data, the shape of the data will be as shown in Figure 7-13 below.

[[[00000000000000001033---bb10339bd44049fc25be511c509ad3786d990f5d699263227b9cef637d0564cc]]]
Figure 7-13 Convolution operation processing flow (batch processing)


[[[00000000000000001034---2477a951a99d63883fe248972a401b8436da03af47e303f76cac3d22e75b9366]]]The batching version of the dataflow in Figure 7-13 adds a batching dimension to the beginning of each piece of data. In this way, the data propagates through each layer as a four-dimensional shape. The point to note here is that the network runs 4-dimensional data, which means that convolution operations are being performed on N pieces of data. In other words, the processing of N times is performed at once.

[[[00000000000000001035---f309dbb24a54a67b7b375aad515a2bdb98b20562c5566997ce4863ff9519ad7a]]]pooling layer

[[[00000000000000001036---9b39b7e14b95119a494d0b577a6fbd69081567782112f66287013353e49d8927]]]Pooling is an operation that reduces the vertical and horizontal space. As shown in Figure 7-14, for example, a 2x2 area is aggregated into a single element to reduce the spatial size.

[[[00000000000000001037---72ca63a921da97019d8c8221ee69df4149c0a9fa5ac6a01515b2c8aa6394eeca]]]
Figure 7-14 Max pooling processing procedure


[[[00000000000000001038---ed28b944a5be6946dc9d110fd1fe1e70bae3897d565c88aa89866480ab26201e]]]The example in Figure 7-14 is the processing procedure when 2 × 2 Max pooling is performed with a stride of 2. 'Max pooling' is an operation that takes the maximum value, and '2 x 2' represents the size of the target area. Take the largest element over a 2x2 area, as shown. Also, the stride is set to 2 in this example, so the 2x2 window moves every 2 elements. In general, set the pooling window size and stride to the same value. For example, set a 3x3 window to a stride of 3, a 4x4 window to a stride of 4, and so on.

[[[00000000000000001039---40e344e70d627dccf9135bed30ebe20aafb45beb04295a6febd1effe8644f6b5]]]Pooling includes Max pooling, Average pooling, etc. Max pooling is an operation that takes the maximum value from the region of interest, whereas Average pooling calculates the average of the region of interest. In the field of image recognition, Max pooling is mainly used. Therefore, when we say 'pooling layer' in this book, we mean Max pooling.

[[[00000000000000001040---fc6762e9d567bac2c6c6e13531e5828ab7761f998516d3f787eabe06b82fdfbb]]]Features of the pooling layer

[[[00000000000000001041---fa141bd6fd2fc42d68f27686df27faf2dcaebbe2ea4fc11119c35b62716b66ae]]]The pooling layer has the following characteristics:

[[[00000000000000001042---14a71fd96c75082043222904651d09bfa7098d430fa37c274b35c3cc6a787307]]]no parameters to learn

[[[00000000000000001043---0a2ab3a9eb20f516f3d55a52edcbd75c40328e7ed45838b2fc99cc6e970c04be]]]Pooling layers, unlike convolutional layers, do not have parameters to learn. Pooling is just a process of taking the maximum value (or average) from the target area, so there is no parameter to learn.

[[[00000000000000001044---0fe9b19267932b6a5525e9ae527494ff2d55bed1c49d899b359d5b8427e519b5]]]No change in number of channels

[[[00000000000000001045---aec48fe5c10b0d2f2ae9fe9f8712f3317dc55b5e95f7354876fe0ae544a00657]]]Pooling operations do not change the number of channels of input and output data. Each channel is independently calculated as shown in Figure 7-15.

[[[00000000000000001046---39dab73cf8c3efbb787cc366d3e52aca905af985a8510d4231e024ca7fe657e4]]]
Figure 7-15 Pooling does not change the number of channels


[[[00000000000000001047---0b04b61cbc1e8a2f9fdc6f9d0679eda3e806c83aba4ca6060bb1c1a1909c09aa]]]Robust against minute position changes

[[[00000000000000001048---daecb3e5f46357fb2340dd617cdfc1b5326af32ddbac426f620fd83d1688c221]]]Pooling gives similar results for small deviations in the input data. Therefore, it is robust against minute deviations in the input data. For example, in the case of 3x3 pooling, as shown in Figure 7-16, pooling absorbs input data discrepancies (depending on the data, the results may not always match).

[[[00000000000000001049---85b4a2d46fcd2129c4c9db98c27af2a1b1ec050561940df47c4515d46af10f0c]]]
Figure 7-16 Even if the input data is shifted by one element in the horizontal direction, the output will be similar (some data may not be the same)


[[[00000000000000001050---17a0d28e403a4e59d3790a56b4a0fee00c1bfe5e2515c019e2964fc21d64fc50]]]Implementation of Convolution/Pooling layer

[[[00000000000000001051---3992b6385d32dcc40f2dc078cce8bd11cf7e5d78c708c209b861ad817bbd464e]]]So far, we've covered convolutional and pooling layers in detail. Now I want to implement those two layers in Python. As explained in 'Chapter 5 Backpropagation Method', the class implemented here also has methods called forward and backward, and is implemented so that it can be used as a module.

[[[00000000000000001052---7b226346b217ed4fbf66b865843d25b2e606c06ba265ae8ef8f75f2c75f053df]]]You may have a feeling that implementing convolutional and pooling layers is going to be complicated, but in fact, you can easily implement it with a certain “trick”. In this section, I'll explain the trick, simplify the problem, and then implement the convolutional layer.

[[[00000000000000001053---f5e23c42b02cb11a8440b678c2dda40ba0b7c9dc6a26048063b35a89b08480ff]]]4 dimensional array

[[[00000000000000001054---3cb7a4b134157f77262e710780c1b8dd5efcda7f42df95c9802a8fe1fe9729a2]]]As explained earlier, in CNN, the data flowing through each layer is 4-dimensional data. 4-dimensional data means, for example, if the shape of the data is (10, 1, 28, 28), this corresponds to 10 pieces of 1-channel data with a height of 28 and a width of 28. Implementing this in Python looks like this:

[[[00000000000000001055---2ebdaf79ce3082692bc4f222f03ccf8db6f47a313b7635023d93d9a947209460]]] # Generate random data >>> 

[[[00000000000000001056---747ae57428d23270e9b6f9e832723972f3122985453edea58063e0a4d64dad1f]]]Now to access the first data, simply write x[0] (note that Python indexes start at 0). Similarly, the second data can be accessed with x[1].

[[[00000000000000001057---c861d6a2e01d1039da017ae8c0aea6ce375dc1f4be2fddfc8b828925356c7771]]]Also, to access the spatial data of the first channel of the first data, write as follows.

[[[00000000000000001058---5bb312ca729bf2d0611561a0441cd224d303557ff79620c44ec0d959f9fa006d]]] # or x[0][0]


[[[00000000000000001059---258d3602c890893be1347fd3e707f1b3a6c9bbeeb6545ea82dccfd9ad67166b5]]]In this way, CNN handles four-dimensional data. So the implementation of the convolution operation seems complicated, but the next 'trick' called im2col simplifies the problem.

[[[00000000000000001060---0be5a43ec3d7dd76127ec6289839f01c66b9deb9890dea650d1ddd594daa3324]]]Expansion by im2col

[[[00000000000000001061---095d2cd0fb8e1084158a512e65e090a63d7b0c4ed1dc6d14e7c792dca9cc73b2]]]Seriously, the implementation of the convolution operation would be an implementation of multiple layers of for statements. Such an implementation is rather cumbersome, and also has the disadvantage that NumPy uses for statements that slow things down (NumPy prefers not to use for statements when accessing elements). Here, we will not implement the for statement, but implement a simple implementation using a convenient function called im2col.

[[[00000000000000001062---417ece93b4af76bb66ed8bc565b40862c0a6fa486908525c831ae11f39c7ef7d]]]im2col is a function that expands the input data in a way that is convenient for the filter (weight). As shown in Figure 7-17, applying im2col to 3-dimensional input data converts it to a 2-dimensional matrix (more precisely, 4-dimensional data including batch numbers is converted to 2-dimensional data). increase).

[[[00000000000000001063---33f2afedc2ece72b484b1b78095a3f9a7b411e9add15b9f8e7da55b9181112c1]]]
Figure 7-17 Schematic of im2col


[[[00000000000000001064---ecd5fc7d4a575a989d4a593c41a42cd0e888bd28ff05b2ba327b5234764c03c7]]]im2col expands the input data in a way that is convenient for the filter. Specifically, as shown in Figure 7-18, the area (three-dimensional block) where the filter is to be applied to the input data is expanded horizontally in one column. im2col does this expansion everywhere you apply a filter.

[[[00000000000000001065---994bf81e5d07a2a39d184fc777db24b04344de2c91db3dd31e56dbb92319f763]]]
Figure 7-18 Expanding the applicable area of the filter in a single column in order from the top


[[[00000000000000001066---4adba61f3f7778b7a8ca7d4c2730dbc8de83115c388e90a16c7c2e25d0a5189e]]]In Fig. 7-18, the stride is set large so that the areas where the filters are applied do not overlap, giving priority to visibility. In a real convolution operation, the filter regions will most likely overlap. When the application area of the filter overlaps, the number of elements after expansion by im2col becomes more than the number of elements in the original block. Therefore, implementations using im2col have the drawback of consuming more memory than usual. However, doing calculations in large matrices has many computational benefits. For example, the matrix math library (linear algebra library) has a highly optimized implementation of matrix math and can perform fast multiplication of large matrices. So, by reducing it to matrix calculations, we can make good use of the linear algebra library.

[[[00000000000000001067---e0066053d895dde6c01552c62f9bbd3526fd8caf46f40249a475d9fd345f665c]]]The name im2col is an abbreviation for 'image to column', which means 'from image to matrix' in Japanese. Deep learning frameworks such as Caffe and Chainer have a function named im2col, and each convolutional layer is implemented using im2col.

[[[00000000000000001068---1395c472f3538d6f7579edc47c42819dcc332c6abe162c0a39b34223ad14d249]]]After expanding the input data with im2col, all you have to do after that is expand the filters (weights) of the convolutional layer into one column and calculate the product of the two matrices (see Figure 7-19). This is pretty much what we did with the Affine layer of the fully connected layer.

[[[00000000000000001069---4ca1973c2823601d0c9a792f4471cc7116b75e2bdb51e2311c5c1b2261c7e9df]]]
Figure 7-19 Details of filter processing for convolution operation: Filters are expanded vertically and arranged in one column, and the product of the data expanded by im2col and the matrix is calculated. Finally, reshape to the size of the output data


[[[00000000000000001070---fcaeed4a9e2b80bf4b07c4a649f887cdf342c64b6023a0ef3be9f35505eaf140]]]The output result of the im2col method is a two-dimensional matrix, as shown in Figure 7-19. In the case of CNN, data is stored as a 4D array, so we shape the 2D output data into an appropriate shape. The above is the flow of implementation of the convolutional layer.

[[[00000000000000001071---c86b7f798c24391a09d9e08062c659479623eed06f31cf0edd1a8341360c5e80]]]Convolution layer implementation

[[[00000000000000001072---9a0db41492a1be985b5ae3d89114a3246aa39effc9ceb4732d66739310fa47b3]]]This document provides a function called im2col. This im2col function is assumed to be used as a black box (without worrying about the contents of the implementation). The contents of im2col implementation are in common/util.py. Its implementation is (actually) a simple function of about 10 lines. Please refer to it if you are interested.

[[[00000000000000001073---baf0b7a7f77c8679f98dd9618885556ff63a4fe3169c2d327da64b6e966aa893]]]Well, the convenience function im2col has the following interface.

[[[00000000000000001074---90e0dad20bd9efd5f649a6156ea8a023a327f55faa3f3c507eb8935c69141cbf]]]input_data —— Input data consisting of a 4-dimensional array of (data count, channel, height, width)

[[[00000000000000001075---784e60230ad62f696b2b99a753a2a28972d00462513fbc0ec38d5eb45cbc88ca]]]filter_h —— filter height

[[[00000000000000001076---1b3d8ef412700be8a23f69cf81a304b93b806f5479b9960898b943e1490d2036]]]filter_w —— filter width

[[[00000000000000001077---be8f8627f1f05559831891438231e72eab57291166be1098863f6cf15b15d6b2]]]stride —— stride

[[[00000000000000001078---7f2c88c61f0483719fe6b53865e4da87e31f35cb868de407e54791b05bcc975e]]]pad —— padding

[[[00000000000000001079---453957742b772c91cd79d92d8114495e68d13171b4289d22fa4a4f2d3ab4f908]]]This im2col considers 'filter size', 'stride' and 'padding' and expands the input data into a 2D array. Now, let's actually use this im2col.

[[[00000000000000001080---ec87e1401673d7034f5a95e8a6d19ff0aa70facb377f5dd9fdabfc3805383430]]]# 10 data

[[[00000000000000001081---680f46136e27be7c6729e7f3c4f5bcd69dca2fe0f543216295eb2bfdbffd2e3d]]]Here are two examples. The first is with a batch size of 1 and 7x7 data for channel 3, the second is with a batch size of 10 and the shape of the data is the same as the first. After applying the im2col function respectively, the number of elements in the second dimension is 75 in both cases. This is the total number of elements in the filter (channel 3, size 5x5). Also, if the batch size is 1, the im2col result is of size (9, 75). On the other hand, the second example has a batch size of 10, so (90, 75) and 10 times more data will be stored.

[[[00000000000000001082---09f3feaba54ac4cd9150e495fd34414670cdc66525926cb7cd266d29295ab1bb]]]Now, use this im2col to implement a convolutional layer. We will implement the convolution layer with a class named Convolution.

[[[00000000000000001083---c9ba9c8d18fee1db21cf0133810d2cd02a2b49998d8905cd2012eca717d94e4f]]]# expand filter

[[[00000000000000001084---49210e26982cc1bcc73b520dc12225e623b367880b95c0ad48cb0b65be4dda6d]]]The convolution layer initialization method takes as arguments the filter (weight) and bias, stride and padding. A filter is a 4-dimensional shape of (FN, C, FH, FW). Note that FN is an abbreviation for Filter Number (number of filters), C for Channel, FH for Filter Height, and FW for Filter Width.

[[[00000000000000001085---d97ef55d194cbf182bae10248aa42dfa3e17b648b1354934db7fe6a73b6e24b6]]]The Convolution layer implementation shows the important parts in bold. In this bold part, the input data is expanded with im2col, and the filter is also expanded into a two-dimensional array using reshape. Then compute the product of the expanded matrices.

[[[00000000000000001086---7f759f130250b7c6ac31b8c5c1397177474528e2f12fc2535738d4397614784e]]]As shown in Figure 7-19, where filters are expanded (bold text in the code), each filter block is expanded and arranged in a row. Here -1 is specified as in reshape(FN, -1), which is one of the useful features of reshape. If you specify -1 when reshaping, the number of elements will be consolidated so that the number of elements in the multidimensional array is consistent. For example, an array of shape (10, 3, 5, 5) has 750 elements in total. increase.

[[[00000000000000001087---7778f26242e0f6adee75782d7e265229cafda6ddd2a5b78cdb85a6ad2de3a10a]]]The forward implementation also finalizes the output size to an appropriate shape. For this formatting, we use the NumPy transpose function. transpose is a function that transposes the order of the axes of a multidimensional array. Change the order of the axes by specifying a sequence of indices (numbers) starting from 0, as shown in Figure 7-20.

[[[00000000000000001088---a514b7899829ac74cef7f8b7455106cf147c3e3327c8874407cf5abfa515a22c]]]
Figure 7-20 NumPy transpose reordering axes: reordering axes by index (number)


[[[00000000000000001089---3e40bcec0bc7044c843c9ce0a947f5193297f55cc69b87f00a69903a4483055e]]]The above is the implementation of the forward processing of the convolutional layer. By unfolding with im2col, it can be implemented in almost the same way as the Affine layer of the fully connected layer (see '5.6 Implementation of Affine/Softmax layer'). Next is the implementation of backpropagation in the Convolution layer, but this is often common with the implementation of the Affine layer, so the explanation is omitted. One caveat is that when backpropagating the Convolution layer, you need to do the inverse of im2col. This is done using a function called col2im provided by this book (implementation of col2im is in common/util.py). Backpropagation for Convolution layers can be implemented in the same way as for Affine layers, except using col2im. The implementation of backpropagation for Convolution layers can be found in common/layer.py if you are interested.

[[[00000000000000001090---14d1a5df87fe6e30585274df9f6fb64812623405ef636c8c1115c11213892369]]]Pooling layer implementation

[[[00000000000000001091---c380cccd0ccb198871fe8788b988b04d8fd5d79f7df1773b4c45e541a7b279fa]]]The implementation of the Pooling layer also uses im2col to expand the input data, just like the Convolution layer. However, pooling differs from convolutional layers in that it is independent in the channel direction. Specifically, the pooling coverage expands independently for each channel, as shown in Figure 7-21.

[[[00000000000000001092---bb412554e3870f0a2c3f750fc7e078ef8ba615da35ac07fcd817f4de861fcd21]]]
Figure 7-21 Expansion of pooling application area for input data (example of 2x2 pooling)


[[[00000000000000001093---87fe8cc519f000858646f1f885451ce9cafcd9a97978afa06605dc6786bc8718]]]Once expanded in this way, all that remains is to find the maximum value for each row of the expanded matrix and shape it into an appropriate shape (Figure 7-22).

[[[00000000000000001094---f942de641a8bdf7f4fa2d8ac2dd4765a1b4d516a3a2aa80047c350963883a1c0]]]
Figure 7-22 Pooling layer implementation flow: The element with the maximum value in the pooling applicable area is drawn with a gray background


[[[00000000000000001095---2c6872d2817ae3624cdce8a193f0fefd9208ef7a1e397c0369f5092aa94ea37a]]]The above is the implementation flow of the forward processing of the Pooling layer. Now, let's look at an implementation example in Python.

[[[00000000000000001096---2b43cc8570d11f9f68c911b7ffeaa6c4743e70c7c66566c7525140bdcab41bc4]]]# expand (1)

[[[00000000000000001097---4c2f0baab4f4c867e230868cbb4dfaa5cd2396a5dc19da59e5e9ba55b80cb777]]]# maximum (2)

[[[00000000000000001098---732d90703599518d2efdaddf0d0825c8034d4d5c6290cf3a8fdc3c1ba0067e2c]]]# Shaping (3)

[[[00000000000000001099---a5220b5e85f79bfc26795283d3cff820a4fff0b660c0e7f0c0855d0f0865fb76]]]Implementation of the Pooling layer is done in the following three-step flow as shown in Figure 7-22.

[[[00000000000000001100---ff6adfaff60bd771667c68e399f49297c48567985a64d19ab9415a5042716ff2]]]Expand input data

[[[00000000000000001101---43b34eb749ccc8bbeb0be32f634b1d065b58955418b5c10640bc1289c1472785]]]Find maximum value row by row

[[[00000000000000001102---5b21b0d6da1174675f9d3a654f964a5e226bc8baabc11e53e725582188c79960]]]Format to proper output size

[[[00000000000000001103---ad392a3f399cb3a6c748148c3fbbd40fdcd3ac435c5043cb3d002d745ea369b3]]]The implementation at each stage is as simple as one or two lines.

[[[00000000000000001104---94f2d1511172272d40c8d8f5f8ea1d3461ba7b0118366e95638e198a500e0e60]]]NumPy's np.max method can be used to calculate the maximum value. np.max can specify axis as an argument, and the maximum value can be obtained for each axis specified by that argument. For example, writing np.max(x, axis=1) will find the maximum value for each axis of the first dimension of the input x.

[[[00000000000000001105---29e074c35d5bce26e29a357e76cfabed2c4a1efb385d00217be4f419ef227aff]]]The above is the explanation of the forward processing of the Pooling layer. As shown here, once the input data has been expanded into a form that facilitates pooling, the rest of the implementation becomes very simple.

[[[00000000000000001106---b66f3cb4014ce74e6d1a84bf79cce90305a2c571eabbc3a86b8f8566cf5cb81f]]]Regarding the backward processing of the Pooling layer, the related items have already been explained, so the explanation is omitted here. For the backward processing of the Pooling layer, backpropagation of max used in the implementation of the ReLU layer ('5.5.1 ReLU layer') can be used as a reference. The implementation of the Pooling layer is in common/layer.py, so if you are interested, please refer to it.

[[[00000000000000001107---264b1ae0063b6a737b5a814d74e8d11f1d06600eeed1b134cc91256e9917dc94]]]CNN implementation

[[[00000000000000001108---e9259d59119fb5a09fbb5bbd1a27bd9c45194a8f536385bf21857166df448146]]]Now that we have implemented the Convolution and Pooling layers, we want to combine them to build a CNN for handwritten digit recognition. Here we implement a CNN as shown in Figure 7-23.

[[[00000000000000001109---9ef586d55cce4dc68a9464930cc0d384fa9fb4b940b9700e4373b5a6963e9319]]]
Figure 7-23 Simple CNN network configuration


[[[00000000000000001110---ec360fe3fa0c83f0bda9ad3de6df20371a48261fcc5308f32656c346e9dc3a5e]]]As shown in Figure 7-23, the network configuration follows the flow of 'Convolution - ReLU - Pooling - Affine - ReLU - Affine - Softmax'. We will implement this in a class named SimpleConvNet.

[[[00000000000000001111---40923903f72d4792efe2eae804adf7c6a4a7c7be3abb32ddde7312bffeb95905]]]Let's first look at SimpleConvNet's initialization (__init__). Suppose it takes the following arguments:

[[[00000000000000001112---7d341bb44cea118093264bfe2372d6f57d3b45fed41f8b5197de111ba1a85a00]]]argument

[[[00000000000000001113---6c0750040c7c204d9391129ecd03627317cc18b1105fa3c95eb2822a10ac849b]]]input_dim —— (channel, height, width) dimension of input data

[[[00000000000000001114---3cf56243952f734bf149d8ee5c45fd772cff9ca1614cf2ae4c773221535f46f9]]]conv_param —— Convolutional layer hyperparameters (dictionary). The keys of the dictionary are: filter_num —— number of filters filter_size —— size of filter stride —— stride pad —— padding



[[[00000000000000001115---e6e6a0eadae48dc54e9c045d39352cc4fd5035852b3a410a57ebe45095cb48c4]]]hidden_size —— Number of neurons in hidden layer (fully connected)

[[[00000000000000001116---fe46721778d201bf736d4832015daa52e22377593d17f4570a8612ae52d6f982]]]output_size —— number of neurons in the output layer (fully connected)

[[[00000000000000001117---33d2f0c91675f3c1d46f120358de267068feaa51b9391862bd4e28c7453ae8b6]]]weight_init_std —— Standard deviation of weights at initialization

[[[00000000000000001118---387d1381c5067b77954e9c944b3c86fb5054a31e9838cf87168293c35a8dc0db]]]Here, we assume that the convolutional layer hyperparameters are given as a dictionary named conv_param. This expects the desired hyperparameter values to be stored, e.g. {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1} .

[[[00000000000000001119---b7216cf7ad7246b863ba28b01739a4a2731a032afcb9c04c7d10fdd82bf8d0a8]]]Now, the SimpleConvNet initialization implementation is a little long, so I'll break it down into three parts. Now for the first part of the initialization.

[[[00000000000000001120---310904a4512d14ba5475a243a16d334ced51f104d13d4294f4d3a77e3efe6d92]]]Here we retrieve the hyperparameters of the convolutional layer given in the initialization arguments from the dictionary (for easy use later). And then calculate the output size of the convolutional layer. Next is the part that initializes the weight parameters.

[[[00000000000000001121---b0ad0f4799d6ef4785ed13b45e4fa6a99880e09981cc6f8dd0d32643fc7c85cc]]]The parameters required for learning are the first convolutional layer and the weights and biases of the remaining two fully connected layers. Store those parameters in the instance variable's params dictionary. Let W1 be the weight of the first convolutional layer and b1 be the bias. Similarly, store the weights and biases of the second fully-connected layer with keys W2 and b2, and the weights and biases of the third fully-connected layer with keys W3 and b3, respectively.

[[[00000000000000001122---d30a8d9da8c1bbde86d520603d0390937ba121869ca2546755f843f9b3186ff4]]]Finally generate the required layers.

[[[00000000000000001123---df05d284847df0f3584d55622e97ea7f991fe28330f616db78773990c6edc1c8]]]Layers are added to the layers of the ordered dictionary (OrderedDict) in order from the top. Add only the last SoftmaxWithLoss layer to another variable called last_layer.

[[[00000000000000001124---457c5c731c6c35f9f6c4a420e2591780a199719f6756ac42192d434744b322df]]]The above is the process to be performed in the initialization of SimpleConvNet. Once initialized like this, we can implement the predict method to make inferences and the loss method to find the value of the loss function as follows:

[[[00000000000000001125---3d4c990a10a7abcd2534488efdc31cd8e7ecf6f719a2f7e5fac155b97715cc48]]]where the argument x is the input data and t is the teacher label. The predict method for inference simply calls the added layers in order from the top and passes the result to the next layer. In the loss that calculates the loss function, in addition to the forward processing performed by the predict method, forward processing is performed to the last SoftmaxWithLoss layer.

[[[00000000000000001126---4a63447a49ed6419ee475576ee5d80b13d99189553ceb9e4150e0a066c30b3a2]]]Next is the implementation of finding gradients by error backpropagation, which looks like this:

[[[00000000000000001127---218e9c76d5eb7001307fd43bd158c9d45ec20893a3e2da4fbc00de3a7142e876]]]# setting

[[[00000000000000001128---2c7d9bbe2de454def748a63ef0aa4ddfe080800a42d8f4efc57edb54f0b63c99]]]Gradients of parameters are obtained by backpropagation (backpropagation). It does forward and backpropagation in succession. Each layer implements the forward and backpropagation functions correctly, so here we simply call them in the appropriate order. Finally, we store the gradient of each weight parameter in a dictionary called grads. The above is the implementation of SimpleConvNet.

[[[00000000000000001129---9283d926df8042cc4fd29e6a1321806d57316ef19bccaa110904e5052e1ad657]]]Let's train the MNIST dataset with this SimpleConvNet. The code for training is almost the same as described in 4.5 Implementing the Learning Algorithm. Therefore, I will not post the code here (the target source code is in ch07/train_convnet.py).

[[[00000000000000001130---ad5eaa43bbfc8ab14e751c3886a44a54222ee5cf2887113ce80062cd99073999]]]Now, when SimpleConvNet is trained on the MNIST dataset, the recognition rate for the training data is 99.82%, and the recognition rate for the test data is 98.96% (there is a slight error in the recognition accuracy after each training). A recognition rate of approximately 99% on the test data is a very high recognition rate for a relatively small network. In the next chapter, we will create a network with a test data recognition rate of over 99% by adding layers to make it deeper.

[[[00000000000000001131---7fced8186e1d24cea5fde8e12324744ab9bd68d5cb5f2251457b28fb74d11801]]]As we have seen here, convolutional and pooling layers are essential modules for image recognition. CNN was able to successfully read certain characteristics of the spatial shape of an image, and was able to achieve high-precision recognition even in handwritten digit recognition.

[[[00000000000000001132---c5cecf3e5d8134b817bdc77748065d553213e1e5dc3acc2ac6c6507e3a861d00]]]CNN visualization

[[[00000000000000001133---08609381097a45b0c8806567f02a70c0b879e6c467668bd7400e041a4ca6263c]]]What do the convolutional layers used in CNN “see”? Here, I would like to explore what is done in CNN through visualization of convolutional layers.

[[[00000000000000001134---05afe494107226a2edd67340c51b3e9b0dbd1a023ccdf17c4064be1698bf9cf8]]]Visualization of first layer weights

[[[00000000000000001135---b1b4425d0f8f7d4bd5b87cce91a50c6be7b0163e722e5dbddf95ead14611c94b]]]Earlier, we trained a simple CNN on the MNIST dataset, where the shape of the weights in the first convolutional layer was (30, 1, 5, 5)——the size was 5×5 and the channel There were 30 filters with a value of 1. A filter size of 5x5 and 1 channel means that the filter can be visualized as a 1-channel gray image. Now, let's display the filter of the convolutional layer (first layer) as an image. Here, I would like to compare the weights before and after learning. The result looks like Figure 7-24 (the source code is in ch07/visualize_filter.py).

[[[00000000000000001136---137f4c70b8d868a2cdf62fc111a5a4d7460d101cb66615c63041fae51b32b086]]]
Figure 7-24 Weights of the first convolutional layer before and after learning: The weight elements are real numbers, but in the image display, the smallest value is black (0) and the largest value is white (255 ) and display


[[[00000000000000001137---391fe5ca2a1e75512c2f724988312bb30f76681ddea80ca511edff93822480c8]]]As shown in Figure 7-24, the pre-learning filter is randomly initialized, so there is no regularity in the shades of black and white. On the other hand, the filter that has finished learning is an image with regularity. It can be seen that the filter is updated with regularity through learning, such as a filter that changes from white to black with a gradation, and a filter that has a lumpy area (this is called a 'blob'). increase.

[[[00000000000000001138---8b28c66f38c4673a974ac408f6db5f6ff85e38179ba500b71260686576256df2]]]What does the regular filter on the right side of Figure 7-24 see? I'm here. For example, a filter with the left half white and the right half black will result in a filter that is sensitive to vertical edges, as shown in Figure 7-25.

[[[00000000000000001139---b19e2377de6348c59e97dd8beea9bff279b5b58d5bdd6d6d169e76046fbcacb1]]]
Figure 7-25 Filters sensitive to horizontal and vertical edges: Output image 1 has white pixels on vertical edges. On the other hand, output image 2 has many white pixels on the horizontal edges.


[[[00000000000000001140---aff4981d3ee2e26c83c49da0012f43c87700b20993dde421ecb1e755d48fae42]]]Figure 7-25 shows the result of convolving the input image with two pre-trained filters. You can see that 'Filter 1' reacts to vertical edges and 'Filter 2' reacts to horizontal edges.

[[[00000000000000001141---5b8859577c9eea22642f344ded456358df0f743862b23c2f2417d99ec1a70cfe]]]As you can see, the convolutional layer filters extract primitive information such as edges and blobs. Passing such primitive information to the subsequent layers is what is done in the previously implemented CNN.

[[[00000000000000001142---c3ffc65f931fb14abd144882d7774d0b057cc51fbbd4a9aaa34690c9686af12d]]]Information extraction by hierarchical structure

[[[00000000000000001143---2803f91e437955a98e9c63c57a7b2ad4f141273b0d07043f5e7d21073ccf5926]]]Now, the results above were for the first convolutional layer. The first convolutional layer extracts low-level information such as edges and blobs, but what kind of information is extracted at each layer in a multi-layered CNN? Studies on visualization in deep learning [17][18] show that the deeper the layers, the more abstract the extracted information (more precisely, the strongly responding neurons).

[[[00000000000000001144---ce51e8c8cf890148c6c6d1a7cb17081055375570f66f85d62acea55635d0c1a9]]]
Figure 7-26 Information extracted by the convolutional layers of a CNN. Layer 1 is for edges and blobs, layer 3 is for textures, layer 5 is for object parts, and finally, neurons respond to object classes (dogs, cars, etc.) in the final fully connected layer [19]. ] quoted)


[[[00000000000000001145---55844adb26b45e6876be7542c9ef11265274c8b46d5d8bec9d9df5274c4bce2d]]]Figure 7-26 shows an 8-layer CNN for general object recognition (cars, dogs, etc.). This network structure is named AlexNet, which is described in the next section. The network configuration of this AlexNet consists of many layers of convolutional layers and pooling layers, and finally the result is output after passing through a fully connected layer. The blocks in Figure 7-26 represent intermediate data on which convolution operations are applied successively.

[[[00000000000000001146---d666905c863d375e55d921b6cfd2316ea481e77c4a173485fffb47202258f50a]]]An interesting aspect of deep learning is that stacking many convolutional layers extracts more complex and abstracted information as the layers get deeper, as shown in Figure 7-26. The first layer responds to simple edges, then textures, and then changes to respond to more complex body parts. In other words, neurons change from simple shapes to “sophisticated” information as layers become deeper. In other words, the object to which it reacts changes as it understands the “meaning” of the object.

[[[00000000000000001147---6119af1622d7ffc53e18aa56363223e9a5f890202d52d0e22d2ab4ef9b13a432]]]Representative CNN

[[[00000000000000001148---bd5ed4e709ccfa4e1b5afba4007e010086f0037cbd7929a2f34ef645d6d74401]]]Various CNN networks have been proposed so far. Two of the most important networks are introduced here. One is LeNet [20], the ancestor of CNN proposed for the first time in 1998. And the other is AlexNet[21] in 2012, when deep learning came to attract attention.

[[[00000000000000001149---ea7104d4155d23edda653a3e0fbfc3807955f9104be79576a1ded2b03abf860f]]]LeNet was proposed in 1998 as a network for handwritten digit recognition. As shown in Figure 7-27, the convolutional layer and the pooling layer—more precisely, the subsampling layer that simply “decimates the elements”—are performed in succession, and finally the result is output through the fully connected layer. increase.

[[[00000000000000001150---fe4d914e573a4b0b57e64f0f20920dbf869a3bee92dc2905910ed09bf0fb1c00]]]
Figure 7-27 LeNet network configuration (quoted from Reference [20])


[[[00000000000000001151---610c39155b5caccf7421bae0d7d961477e46d1be303d9b87b7dd280f4eb6534f]]]Comparing LeNet with 'current CNN', there are some differences. The first difference is in the activation function. LeNet uses the sigmoid function, whereas today mainly ReLU is used. Also, the original LeNet uses subsampling to reduce the size of the intermediate data, but now max pooling is the mainstream.

[[[00000000000000001152---7fff8fe05c2b91d9068d01ba8a72b3468e6b4da6d572fc66e34f16ff769731e3]]]As you can see, there are some differences between LeNet and 'modern CNNs', but they aren't that big of a difference. This is surprising considering that LeNet was the 'first CNN' proposed nearly 20 years ago.

[[[00000000000000001153---d5d8e6576ed6edcfabb48b26e458907745552d5f7003763e960cb4874b6c6949]]]Nearly 20 years after LeNet was introduced, AlexNet was announced. AlexNet sparked the deep learning boom, but its network configuration is basically the same as LeNet, as shown in Figure 7-28.

[[[00000000000000001154---32b3c1230aa14d2937d105e399b6adc4f04503c3197f70e2e7fc91fc2bd91fa4]]]
Figure 7-28 AlexNet (created with reference to Reference [21])


[[[00000000000000001155---e7f1a90ec51f6416bc2215fe93be36032a95580b6dcaf182c0d30050fd80de07]]]AlexNet stacks convolutional and pooling layers, and finally passes through a fully connected layer to output the result. LeNet has the same structure as LeNet, but AlexNet differs in the following points.

[[[00000000000000001156---408c176e6ccd20200398ca5d31b3c00e819f2ac40c514fbeb197d7d062c94f3b]]]Use ReLU as activation function

[[[00000000000000001157---fe6e57d1580bda42e97927d556e794a01c850b7d32d74832a413666a45604cd4]]]Use a layer that performs local normalization called LRN (Local Response Normalization)

[[[00000000000000001158---0ef715198aa482da22f7e9f60e9d8079501ab00a6e63555cf33198a1393ce7a5]]]Using Dropout (see '6.4.3 Dropout')

[[[00000000000000001159---6a25f547319f8e7d840d1ebfbda8ebc263c1e5cb0c7130af7bc1ccf9f12dff02]]]As we have seen, there is not much difference between LeNet and AlexNet in terms of network configuration. However, there have been great advances in the environment and computer technology surrounding it. Specifically, massive amounts of data are now available to everyone. GPUs, which excel at large-scale parallel computation, have become widespread, making it possible to perform large-scale computations at high speed. Big data and GPUs—this has been the driving force behind the development of deep learning.

[[[00000000000000001160---5a99b8268877b6a77ca96b86a1ddc62767c7945119a767333b647c78b27839eb]]]Deep learning (a network with deep layers) often has a large number of parameters. Therefore, training requires a lot of calculations and a large amount of data to 'satisfy' those parameters. GPUs and big data have shed light on those challenges.

[[[00000000000000001161---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000001162---f88c2517bdf70c348bd4dd6c70732b7300ca4cba36f74c10441aa6a27e76c236]]]In this chapter, we learned about CNN. The basic modules that make up a CNN, the 'convolutional layer' and the 'pooling layer', are somewhat complicated, but once you understand them, the only problem is how to use them. In this chapter, we have taken the time to explain convolutional and pooling layers so that you can understand them at the implementation level. CNN is used almost without exception in the field of handling images. After understanding the contents of this chapter, let's move on to the final chapter.

[[[00000000000000001163---19850c73ec605a12530fa271fcc972171b998181be314b2c4c58825fcf2e154b]]]What we learned in this chapter

[[[00000000000000001164---dc650b54306cd1847813849f0712417034f1d03cf7933d7f6751ebf9a0bf23b0]]]CNN adds a new convolutional layer and a pooling layer to the conventional fully connected layer network.

[[[00000000000000001165---84e6ab2589d13bda872764a1833fcce9c4839e4871742b638f91705fb70728de]]]The convolution layer and pooling layer can be implemented simply and efficiently by using im2col (a function that expands an image into a matrix).

[[[00000000000000001166---8752aa9037d8a7bca4ca961d4c63023feeb978feb31176743415cb8c96b209ce]]]CNN visualization shows how advanced information is extracted as the layers become deeper.

[[[00000000000000001167---da1df5269695704a23de5cd44a29763cf5004876144a2b480bc54508a09e014b]]]CNN's representative networks include LeNet and AlexNet.

[[[00000000000000001168---d1eea1217fff0efe4b0e55ae4ddb247ce9e0a1457c1bdcbff31202c6d679f101]]]Big data and GPUs have greatly contributed to the development of deep learning.

[[[00000000000000001169---8f61b6bb90e9b1bac938f68867a8ad69b1b90e36b77931f7b26dbdabed771767]]]Chapter 3

[[[00000000000000001170---0b0739891461f74a49a5d6b095aca75ec4b1959eec0fe5da0dd51a1bacb59217]]]neural network

[[[00000000000000001171---533165c70be0f1c1b56be2514b075474ea49b052fa9c8b5b19b38937c57f9bdb]]]We learned about perceptrons in the previous chapter, but there was good news and bad news about perceptrons. The good news is that perceptrons have the potential to represent even complex functions. For example, I explained in the previous chapter that perceptrons can (theoretically) express even seemingly complicated processing that computers do. The bad news is that the work of setting the weights -- determining the proper weights to meet the expected inputs and outputs -- is currently done by humans. In the previous chapter, we humans determined appropriate weights while looking at the truth tables of AND and OR gates.

[[[00000000000000001172---87566e34e21305507e8f46268ca23f29fa513c81b62c26b86c2f3dcd3c4dc156]]]Neural networks are there to solve bad news ahead. Specifically, one of the important properties of neural networks is that they can automatically learn appropriate weight parameters from data. This chapter provides an overview of neural networks and focuses on what they do when they make decisions. Then, in the next chapter, we will learn how to learn the weight parameters from the data.

[[[00000000000000001173---dbb17798c967d91af63459153a7a59e5859edbc983e07e9231764335ff3017e0]]]From Perceptrons to Neural Networks

[[[00000000000000001174---0869488d13a478c55c6e839748b0b871524fcb4feedda5478c10d6183b7c4615]]]Neural networks have many things in common with the perceptrons discussed in the previous chapter. Here, we will explain the mechanism of the neural network, focusing on the differences from the perceptron in the previous chapter.

[[[00000000000000001175---4d89ab7656351a17ee6969e4b0a440470f06d8eba2fde44e7e92cbae2264d44e]]]Neural network example

[[[00000000000000001176---89836af084de1fe66ebe24f46ae5e17f84f0a56d73f76050472564a3f7e338eb]]]A diagram of a neural network is shown in Figure 3-1. Here, the leftmost column is called the input layer, the rightmost column is called the output layer, and the middle column is called the hidden layer. The middle layer is also called the hidden layer. The term 'hidden' means that the neurons in the hidden layer (unlike the input and output layers) are invisible to the human eye. In this document, we refer to the input layer, the output layer, and the layers as layers 0, 1, and 2. because it is convenient). In Figure 3-1, the 0th layer corresponds to the input layer, the 1st layer corresponds to the intermediate layer, and the 2nd layer corresponds to the output layer.

[[[00000000000000001177---3ad2cd342899b3dd6c25e906a41bb1c7ebc7e392b3bb9f5b9afd26dd42fbd99c]]]
Figure 3-1 Neural network example


[[[00000000000000001178---8cda66abfa6a3da5fa3f1d9c67338fe1f133cbedb6967df5c34b36c20a810dae]]]The network in Figure 3-1 consists of 3 layers in total, but the layers with weights are actually 2 layers, so we will call it a '2-layer network'. Note that some books refer to Figure 3-1 as a 'three-layer network', according to the number of layers that make up the network. In this book, we will refer to network names by the number of layers that actually have weights—the sum of the input, hidden, and output layers minus one.

[[[00000000000000001179---c9beac053b0ef3918d6ab0695d4be0f479aff4143b2f137d3a79cc257efac581]]]As you can see in Figure 3-1, it has the same shape as the perceptron we saw in the previous chapter. In fact, in terms of how the neurons are connected, it's no different than the perceptron we saw in the previous chapter. So how do neural networks transmit signals?

[[[00000000000000001180---c29bb1f235f93d91133c2015fe27162caceaa2971116aad21a4a3f004e73db04]]]Perceptron review

[[[00000000000000001181---71fa7b028531de84ab8503be0020df999551c22d4ca51ccd08c71f1d5f33b4ac]]]Before we look at how signals are propagated in neural networks, I would like to start by reviewing perceptrons. First, let's consider a network with the structure shown in Figure 3-2.

[[[00000000000000001182---fb5cfe247df9748fc58598b22e40f611f2e7d81a968fc02d20e71d3c4f0a88a6]]]
Figure 3-2 Perceptron Review


[[[00000000000000001183---690f0168738cb7770182f35b0ed6b36db7a2d1c08038604e541f7c0d20d68cca]]]Figure 3-2 is a perceptron that takes two input signals x1 and x2 and outputs y. The perceptron in Figure 3-2 is represented by the following formula (3.1).

[[[00000000000000001184---c9f85c5c558a04f835958db492d26e25c3a598bf443ff54c8339d865811f94b2]]]Equation (3.1)

[[[00000000000000001185---d4d2919e9706886cac4c04e726a2a9bed28e032815a86fc5b9445ef4ac159c02]]]where b is a parameter called 'bias', which controls how easily the neuron fires. On the other hand, w1 and w2 are parameters representing the 'weight' of each signal, which control the importance of each signal.

[[[00000000000000001186---8ade17ecefac9ba5095c9d6b53124b9791f84207a214a4e54fa090c54f8d1a39]]]By the way, the network in Figure 3-2 does not show the bias b. If we specify the bias, it can be represented as in Figure 3-3. In Figure 3-3, a signal with weight b and input 1 is added. The operation of this perceptron is that three signals x1, x2 and 1 are input to a neuron, and those three signals are multiplied by their respective weights and sent to the next neuron. The next neuron computes the sum of those weighted signals and outputs 1 if the sum is greater than 0, and 0 otherwise. By the way, the input signal for the bias is always 1, so we will color the neuron in gray to distinguish it from the other neurons.

[[[00000000000000001187---7a8f11504955a1317c9568a3bfc2377f200b8903f779f0008c867299dfddca83]]]
Figure 3-3 Explicitly Showing Bias


[[[00000000000000001188---9b2959c03898b0ecda0cce4b0a9d1462f0d214560a034a438c96942be874b652]]]Now, let us rewrite equation (3.1) in a simpler form. In order to simplify equation (3.1), we express the case-by-case behavior—the behavior of outputting 1 if it exceeds 0, and outputting 0 otherwise—in a single function. Here we introduce a new function h(x) and rewrite equation (3.1) as equations (3.2) and (3.3) below.

[[[00000000000000001189---e53d3325f50cbe872a292de1995dc4df780b70f3084ba4379aa435ea1e5b6d17]]]Equation (3.2)

[[[00000000000000001190---794afc7674d30d890d770062b76405d9f8ba9d8a172f9ae271484fa337e6654a]]]Equation (3.3)

[[[00000000000000001191---fd1662dc409f471081ea3da47717d0ab9535ef40a8812346fc232070aaa45dc4]]]Equation (3.2) expresses that the sum of the input signals is transformed by the function h(x), and the transformed value becomes the output y. And the h(x) function expressed in equation (3.3) returns 1 if the input exceeds 0, otherwise it returns 0. So equations (3.1) and (3.2) and (3.3) are doing the same thing.

[[[00000000000000001192---43e27e2b3407d2cb22cc0c87b87d1e892aca7df6bf12f8c5433a677d6312fcde]]]Emergence of Activation Functions

[[[00000000000000001193---de510401e70622ac229838b42cd2ddd1025ff5e4580932d83eb294bcb15e52a6]]]By the way, the function h(x), which appeared here, is generally called an activation function. As the name 'activation' implies, the activation function is responsible for determining how the sum of the input signals activates (fires).

[[[00000000000000001194---2cdc57c9104856f985e62d34eaef71b51f6f9aeb5ff64f01a68bef078a4eb48d]]]Now let us rewrite equation (3.2). Equation (3.2) is a two-step process that computes the sum of the weighted input signals and then transforms that sum by the activation function. Therefore, if we write equation (3.2) carefully, we can divide it into the following two equations.

[[[00000000000000001195---0809a90b216d54ac9112090225566e61f41b4034e3638503129dc1747b2ff146]]]Equation (3.4)

[[[00000000000000001196---89a79e44fc302a205fb3e7f9b14ee924dffa915bc64005de8a44b36ac93a068b]]]Equation (3.5)

[[[00000000000000001197---eb1d08513c1eafe84fd92725b07d6b38d39d55fc5cd80433ec3a9510796a077d]]]In equation (3.4), calculate the sum of the weighted input signal and bias, and call it a. Then, in formula (3.5), a is converted by h() and y is output.

[[[00000000000000001198---af524054fedc578248c6ec5dcf80fb3b9219ef1003e8da647707110b72604d5c]]]Up until now, neurons have been illustrated with a single circle, but if we express equations (3.4) and (3.5) explicitly, they can be represented as shown in Figure 3-4 below.

[[[00000000000000001199---29cc5643b9b0d6f51d3c76d7c44e04274c91dd7705827fb71321f65c24285439]]]
Figure 3-4 Explicitly illustrate the process with an activation function


[[[00000000000000001200---834031a41c5e4c6327cb5a4334b33cfa3db65ae4ae79bde0cdb01a994f812163]]]As shown in Figure 3-4, the process by the activation function is explicitly illustrated in the circles of the neurons so far. That is, it clearly shows that the sum of the weighted signals results in a node called a, which is transformed by the activation function h() into a node called y. Note that the terms 'neuron' and 'node' are used interchangeably in this document. Here, the circles of a and y are called 'nodes', but this is used in the same sense as 'neurons' so far.

[[[00000000000000001201---0571eea0e0d21db3eec645ee8bc532d7b9b49128fc41dc0fbdb6abe55e2b82d2]]]Also, regarding the method of drawing a neuron, it is usually represented by a single circle, as in the left diagram of Fig. 3-5. In this book, when the operation of a neural network can be clarified, it will be illustrated including the activation process, as shown in the right figure of Figure 3-5.

[[[00000000000000001202---91dbf59230f5f56c1973495823e1b434d500a3936fb8deb6f92571dde858a82c]]]
Figure 3-5 The left figure is a diagram of a general neuron, and the right figure is a diagram that explicitly expresses the activation process inside the neuron (the sum of input signals is a, the activation function is h(), and the output is y notated)


[[[00000000000000001203---a96e65258b6cf64df760743473837eced18ddb7dcdea81b51b4866924977ad08]]]Now let's take a closer look at the activation function. This activation function is the bridge from the perceptron to the neural network.

[[[00000000000000001204---8d4171816fb60ed3f08c1bf3286e3e16e68c33ad56d793b55373352301abf3fd]]]The algorithm referred to by the term 'perceptron' is used loosely throughout this book. In general, the term 'simple perceptron' refers to a single-layer network model that uses a step function (a function whose output switches at a threshold) as the activation function. When we say 'multilayer perceptron' we usually mean a neural network -- a network that is multi-layered and uses a smooth activation function, such as a sigmoid function.

[[[00000000000000001205---af45d3d711d56bc820d723bef8b4a64620cd3a5a78116134dbe2b3179bd1eb64]]]activation function

[[[00000000000000001206---0d6dd8c4a4c661fb976e965f93c6afa28170ab296e72903e4d73ee268b7d983b]]]The activation function represented by equation (3.3) is a function whose output switches at the threshold, and is called a 'step function' or 'staircase function'. Therefore, we can say that the perceptron uses a step function as its activation function. In other words, among the many functions that can be candidates for the activation function, the perceptron adopts the 'step function'. If the perceptron uses a step function as the activation function, what happens if a function other than the step function is used as the activation function? In fact, by changing the activation function from a step function to another function, you can enter the world of neural networks! Without further ado, let's introduce the activation functions used in neural networks.

[[[00000000000000001207---4317063b8f3d74f49da045a611901aaf43a583ed895fb17db411e9bcff670429]]]sigmoid function

[[[00000000000000001208---d9c928c3bed47532927ab1733ffba15dc699e12c29dfa17b397c978d82b14e14]]]One of the activation functions often used in neural networks is the sigmoid function expressed in Equation (3.6).

[[[00000000000000001209---33e1e7734db68f29774e50a178fef79968c7b094ca47546a67224b6551a8ec38]]]Equation (3.6)

[[[00000000000000001210---f6269761cda7abbc5b261748fd4745a2b7036d8347c47d90cfd68dc914e45e9a]]]exp(−x) in expression (3.6) means e represents the real number of Napier's number 2.7182…. The sigmoid function expressed in Equation (3.6) looks complicated, but it is also just a 'function' -- a function is a transformer that gives some input and returns some output. For example, if you input 1.0 and 2.0 to the sigmoid function, it will output some value like h(1.0)=0.731…, h(2.0)=0.880….

[[[00000000000000001211---f35c158c4317538e3be4c2608398647252cb179c7441060a160dacb294141c14]]]In the neural network, the signal is transformed using the sigmoid function as the activation function, and the transformed signal is transmitted to the next neuron. In fact, the activation function is the only major difference between the perceptron we saw in the previous chapter and the neural network we're going to see. Other points---the structure in which neurons are connected in multiple layers and the method of signal transmission---are basically the same as the perceptron in the previous chapter. Now, let's take a closer look at the sigmoid function used as the activation function, comparing it with the step function.

[[[00000000000000001212---1171bbb9ea225a756d494b2568d6b19e0a02ba6405b9f8cbec11b0787844ea78]]]Step function implementation

[[[00000000000000001213---8e1c73cf339bfea550db65d91b1ef33b1b5ce413d13a47a12bcdd734745b914d]]]Here we use Python to represent the step function graphically (visually confirming the shape of the function is important for understanding the function). The step function was a function that outputs 1 when the input exceeds 0, and outputs 0 otherwise, as expressed in equation (3.3). A simple implementation of the step function would look like this:

[[[00000000000000001214---60831a18b5819777c107a3147dc5f345841b0b1f7df9a8908b71bdc1157c2ff3]]]This implementation is simple and easy to understand, but the argument x can only be input as a real number (floating point number). In other words, you can use step_function(3.0), but you can't use it to take a NumPy array as an argument—for example, step_function(np.array([1.0, 2.0])). . Here, I would like to consider the future and modify the implementation to support NumPy arrays. For that purpose, for example, the following implementation might be considered.

[[[00000000000000001215---3040e7096f47c3868c8294cf750af2f48e713aa69de0c06c277c98aa48f5f345]]]The function above is only two lines long, but it can be a little confusing because it uses a nifty NumPy “trick”. Here, I'll explain what kind of tricks I'm using, looking at the following Python interpreter example. The following example prepares a NumPy array called x and performs an inequality operation on that NumPy array.

[[[00000000000000001216---eac839f4c4cd92097c26985d0c9aa185b1de12c19eacd67b8f31ff7c492abbd5]]]When you perform an inequality operation on a NumPy array, the inequality operation is performed on each element of the array, yielding an array of booleans. Here, for the elements of the array x, elements greater than 0 are converted to True, elements less than or equal to 0 are converted to False, and a new array y is created.

[[[00000000000000001217---e965c8211f49909b7be32f79a41cb63a2b3e6577c3c6c6fc1577de33165e21d8]]]Now, the previous array y was a boolean array, but the step function we want is a function that outputs 0 or 1 'int type'. So we convert the type of the elements of the array y from boolean to int.

[[[00000000000000001218---c88a3fa8e57652a498a89393f7a50e3c344fb7e81dac7f4fb9d859e552994fe8]]]As shown here, the astype() method is used to convert NumPy array types. The astype() method specifies the desired type for the argument—np.int in this example. In Python, when converting from boolean type to int type, True is converted to 1 and False is converted to 0. So that was the description of the NumPy “tricks” used in the step function implementation.

[[[00000000000000001219---082cba6f853533ef460ec974ad06476b587996f32a45016bc8644dc638b74ef6]]]graph of step function

[[[00000000000000001220---f21f6fc2bc998857c15e102dc1750c245e5106c11440a0225d50716644575c46]]]Now let's graph the step function defined above. For that I use matplotlib as a library.

[[[00000000000000001221---2bac4ac0e9d73a76abec173395718d0adcf4ff183d7e271bd2bad7d42d431c82]]]# specify the y-axis range

[[[00000000000000001222---ad2d1d4a3469d5cc8861950324ddf5d7e4c68167eab150f9973f06dff33669e4]]]np.arange(-5.0, 5.0, 0.1) produces a NumPy array ranging from −5.0 to 5.0 in steps of 0.1 (producing [-5.0, -4.9, …, 4.9]). step_function() takes a NumPy array, runs a step function on each element of the array, and returns the result as an array. Plotting this x,y array results in the following Figure 3-6.

[[[00000000000000001223---2bc6053b317124db729ac58122fa0a5ebe03bd005cf2a6a9470c19e7bcdab673]]]
Figure 3-6 Step Function Graph


[[[00000000000000001224---41220c608476445836a799792916423377669ee2601537e3ee5e1319be2dc6ce]]]A step function switches the output from 0 to 1 (or 1 to 0) at 0, as shown in Figure 3-6. Note that the step function is sometimes called a 'staircase function' because the value changes stepwise as shown in Figure 3-6.

[[[00000000000000001225---4389409db901131dce5d6f636b30369989a51b73e9d91554880f761ba313a042]]]Implementation of the sigmoid function

[[[00000000000000001226---73cc37fcd959cbb891abefeaa76ed99133bcfe2f0bbbb62034f26bff0d6943be]]]Next, let's implement the sigmoid function. The sigmoid function of equation (3.6) can be written in Python as

[[[00000000000000001227---312bd639f09ea9ea3e3851af2b0b68a27b5bd419826dfc12abd7e3a14e74ae70]]]where np.exp(-x) corresponds to exp(-x) in math. This implementation is not particularly difficult, but be aware that the result will be calculated correctly even if you enter a NumPy array as the argument x. In fact, when I feed this sigmoid function with a NumPy array, it correctly computes:

[[[00000000000000001228---543b61d497a38c6c2597899a62f396ed751231f10662bf974d6a59d079c31e22]]]The secret behind the implementation of the sigmoid function supporting NumPy arrays is NumPy broadcasting (see 1.5.5 Broadcasting for details). Due to the broadcasting feature, when an operation is performed on a scalar value and a NumPy array, the operation is performed on each element of the scalar value and the NumPy array. Let me give you a concrete example here.

[[[00000000000000001229---033f267665323c3407398794b9b997b095eba3e0165c228f1fd1c2cc59ff43c9]]]In the example above, a numeric operation (such as + or /) is being performed between a scalar value (1.0 in the example) and a NumPy array. As a result, an operation is performed between the scalar value and each element of the NumPy array, and the result of the operation is output as a NumPy array. In the previous implementation of the sigmoid function, np.exp(-x) still produces a NumPy array, so the result of 1 / (1 + np.exp(-x)) is computed between each element of the NumPy array. will be

[[[00000000000000001230---63031e5f6b9826119145d43b0d55215a46dee5e9d66d3522a21fa6900d7f9ebf]]]Now draw the sigmoid function on a graph. The code for drawing is almost identical to the step function code above. The only difference is changing the function that outputs y to the sigmoid function.

[[[00000000000000001231---2bac4ac0e9d73a76abec173395718d0adcf4ff183d7e271bd2bad7d42d431c82]]]# specify the y-axis range

[[[00000000000000001232---30a6b550a3a9c9f7d8b3ad631d9b2b1a310a21d575831742f849a7845bf806da]]]After running the code above, we get the graph in Figure 3-7.

[[[00000000000000001233---c0c0ec3d2ebf3af0232157ccec8a7ba18f97d6f546e9651ba5fd652607b129de]]]
Figure 3-7 Graph of Sigmoid Function


[[[00000000000000001234---658d56c19c0820e4e3fb135ce89a6d7bc6a49ff65bef94dccab75ff935bfda18]]]Comparing Sigmoid and Step Functions

[[[00000000000000001235---e2bb4182ba5b5ad69f91461faa0be1ed4ac9c4bc82190bfdba0edf6464f4f372]]]Compare the sigmoid function and the step function. The step function and sigmoid function are shown in Figure 3-8. What is the difference between the two functions? What kind of characteristics do you think they have in common? Observe and consider Figure 3-8.

[[[00000000000000001236---5bc039757a0a49e5eedfa2185ad3d5aa1f0b8ab556e0c8d880248f9b5c917118]]]
Figure 3-8 Step function and sigmoid function (dashed line is step function)


[[[00000000000000001237---6e807655eb441bde64d0f2fb80179b64d0c89a6877effa565ea942a67e0525b5]]]I think the first thing you notice when you look at Figure 3-8 is the difference in 'smoothness.' The sigmoid function is a smooth curve that continuously varies the output with respect to the input. On the other hand, the step function suddenly changes the output from 0. The smoothness of this sigmoid function has important implications for neural network learning.

[[[00000000000000001238---10f12a64f5d4059fc49787a5c2be92a0ba25eff07a658d5a8d2380576957e608]]]Also (related to smoothness), the step function returns either 0 or 1, while the sigmoid function returns real numbers—0.731, 0.880, etc. The points are also different. In other words, in a perceptron, a binary signal of 0 or 1 flows between neurons, whereas in a neural network a continuous real-valued signal flows.

[[[00000000000000001239---1415b559e1f132065f264a1e3aebcfb877e76d14043845e8a0e070747248aebd]]]By the way, if we talk about the operation of these two functions in relation to 'water', we can compare the step function to 'water wheel' and the sigmoid function to 'water wheel'. , the sigmoid function is proportional to the amount of water flowing like a 'water wheel', and the next Adjust the amount of water flowing to the

[[[00000000000000001240---4b970f17c028f13aa7a9d45603ba57451f6e4bd453a6ad1865a764bf8cf177c8]]]Next, let's look at the common properties of the step function and the sigmoid function. The step function and the sigmoid function differ in terms of 'smoothness', but if you look at Figure 3-8 from a larger perspective, you can see that they have similar shapes. In fact, both have a structure in which the output is close to 0 (is 0) when the input is small, and the output approaches 1 (becomes 1) as the input increases. In other words, the step function and the sigmoid function will output a large value if the input signal is important information, and a small value if the input signal is not important. And, no matter how small or large the input signal value is, the output signal value can be pushed between 0 and 1.

[[[00000000000000001241---c06202376b8451f0f6877b579e9f8656e3d9e55c63f6d84986ae08b091ebad5f]]]nonlinear function

[[[00000000000000001242---ad69e2ced7164ea515ecd9cefa910ce2329935d5a0af23207845f4b326e8bd38]]]Step functions and sigmoid functions have other things in common. The important commonality is that both are nonlinear functions. A sigmoid function is represented by a curve, and a step function is represented by a curved straight line like a staircase, both of which are classified as nonlinear functions.

[[[00000000000000001243---81f9f32225e4e8dc726c4ba44027c1b94bbd2884a69399626f9f1342e0cd2a9a]]]The terms 'nonlinear function' and 'linear function' often appear when discussing activation functions. In the first place, a function is a 'transformer' that returns some value when it inputs some value. A function such that when something is input to this converter, the output is a constant multiple of the input is called a linear function. A linear function is therefore a straight line. On the other hand, nonlinear functions, as the name suggests (“not linear functions”), refer to functions that are not a simple straight line, such as linear functions.

[[[00000000000000001244---1c55d3809e73f963cc0e471a961c7a091c1f2d5816d347ff42e5bab25fab49ce]]]Neural networks require non-linear activation functions. In other words, the activation function should not be a linear function. Why not use linear functions? The reason for this is that using linear functions defeats the purpose of deepening layers in neural networks.

[[[00000000000000001245---b1192280eaf124f1a1aa01f213f8e350fe586424bfb0a58f023190195896b13e]]]The problem with linear functions stems from the fact that no matter how deep the layers are, there will always be a 'network without hidden layers' that does the same thing. To see this concretely (and somewhat intuitively), consider the following simple example. Here, we will consider the calculation of y(x) = h(h(h(x))) with the linear function h(x) = cx as the activation function for a three-layer network. . This calculation does a multiplication of y(x) = c x c x c x x, but the same thing is a single multiplication of y(x) = ax (where a = c3), i.e. the hidden layer It can be expressed in a network without As in this example, if we use a linear function, we cannot take advantage of multiple layers. That's why we need to use a non-linear activation function to get the benefits of layering.

[[[00000000000000001246---1c9e875b8b4aaa5ec75bba65f17d42eafbe09d041c2b09b562910d83ef2d62e6]]]ReLU function

[[[00000000000000001247---ac9d4187a683b2d368dedf72f5e6bee609204251ddbd3a3bc37340132850911b]]]So far, we have introduced the step function and the sigmoid function as activation functions. The sigmoid function has been used for a long time in the history of neural networks, but recently a function called ReLU (Rectified Linear Unit) is mainly used.

[[[00000000000000001248---363279766144c98b56c92a3e29b8fce2cbfc43344df725f468c474d4b84d3bff]]]ReLU is a function that outputs the input as it is if the input exceeds 0, and outputs 0 if the input is less than 0 (see Figure 3-9).

[[[00000000000000001249---83a541df63f9f536e6e46c395cd01828b6af32e2f77b08a0e331f93fcfcafbfe]]]
Figure 3-9 ReLU function


[[[00000000000000001250---17423b6728f1dfa6309b675bc2bf944803188d5e9a9bb8804862e4d8f8e26844]]]The ReLU function can be written as the following formula (3.7).

[[[00000000000000001251---d2833dfabf04a1fb949091f414772ad0fe9acd6f4cd501615c47b8353954ddc1]]]Equation (3.7)

[[[00000000000000001252---518afc63951821ebb8a0f3f0300f754f1dd688247959b30267381da631520e24]]]As you can see from the graphs and formulas, the ReLU function is a very simple function. So the ReLU function is also easy to implement and can be written as:

[[[00000000000000001253---6c3aa2dd502b3a9acd274939386c596d67c48422a48b40d3701ad663fd768027]]]Here, we use the function maximum of NumPy. This maximum is a function that selects and outputs the larger value from the input values.

[[[00000000000000001254---bc2024f8f21b647441e4ffaa19436f4a79602322e9c2e1a9fc34be8f6e45f9b0]]]Now, for the remainder of this chapter, we'll be using the sigmoid function as the activation function, but later in the book, we'll be using the ReLU function primarily.

[[[00000000000000001255---d273424a2bd05dc984541bd2855af46980223400c348ff854c22540c2321cac0]]]Calculations on multidimensional arrays

[[[00000000000000001256---94e4835b420921ba6d707a0c150403e069a7a81149b28e03b8e93e4d13095e4e]]]Mastering computations with multidimensional arrays in NumPy will allow you to efficiently implement neural networks. Therefore, here we will explain the calculation of multidimensional arrays with NumPy, and then implement the neural network.

[[[00000000000000001257---1db2ee40511931009454489eaa72492f2fc6c6803cd77a18584cfbb3ab1d2554]]]multidimensional array

[[[00000000000000001258---1a7aebc7edd5931c68b6a66291f4c536009189fe0e34a520d86d8598f3507148]]]A multidimensional array is simply a 'set of numbers'. Multi-dimensional arrays are those in which numbers are arranged in a row, in a rectangular shape, in three dimensions, or (more generally) in N dimensions. Now use NumPy to create a multidimensional array. Let's start with the one-dimensional arrays we've seen so far.

[[[00000000000000001259---a9625120e04032fb0af71699fcb131af3034cca38024d51a6a29b5ee48fde582]]]The number of dimensions of an array can be obtained with the np.ndim() function, as shown here. Also, the shape of the array can be obtained from the shape of the instance variable. In the example above, we can see that A is a one-dimensional array and consists of four elements. Note that here the result of A.shape is a tuple. This is because even for one-dimensional arrays, it returns the same unified result as for multi-dimensional arrays. For example, a tuple such as (4,3) is returned for a 2D array, and (4,3,2) for a 3D array. is returned. Next, create a two-dimensional array.

[[[00000000000000001260---7ec1c26ff6bc39fc3fce7c60550c2d31a8152384c937af2f3e544836d46bcc4b]]]Here we are creating B, which is a '3x2 array'. A 3x2 array means that the first dimension has 3 elements and the next dimension has 2 elements. Note that the first dimension corresponds to the 0th dimension and the next dimension corresponds to the 1st dimension (Python indices start at 0). A two-dimensional array is also called a matrix. As shown in Figure 3-10, the horizontal alignment of the array is called a row, and the vertical alignment is called a column.

[[[00000000000000001261---084dfde7090c3ee9384e9c083e22203f982569dbbadd3395f43563ec0333a7e9]]]
Figure 3-10 Horizontal arrangement is called 'row' and vertical arrangement is called 'column'


[[[00000000000000001262---ff3fd12e3cde230f92432b6ceff6a6a310741ebdb16bd0fe8f9fec2354fb29c9]]]matrix product

[[[00000000000000001263---c84d06b4508ee328868050744783f1a3aa59ec888cf4a03338d5ba48075b4b6e]]]Next, I will explain the product of matrices (two-dimensional arrays). The matrix product is calculated as shown in Figure 3-11 for a 2x2 matrix, for example (it is defined to be calculated in the following steps).

[[[00000000000000001264---367017d2eed2b9b70d4ad053c9c61f78c924ad4a0021467dcdd59eb4a96fce12]]]
Figure 3-11 How the matrix product is calculated


[[[00000000000000001265---cc922eac46854c163adca7afe935a8c106337fca80119d7b526281f8823a5df4]]]As shown in this example, the matrix product is computed by summing the element-wise products between the rows of the left matrix (horizontally) and the columns of the right matrix (vertically). The results of that computation are then stored as elements of a new multidimensional array. For example, the result in row 1 of A and column 1 of B is the element in row 1, column 1, row 2 of A and column 1 of B is the element in row 2, column 1, and so on. In this manual, matrices are indicated in bold when notating formulas. For example, matrices are denoted as A to distinguish them from single-element scalar values (such as a and b). Now, implementing this calculation in Python looks like this:

[[[00000000000000001266---4491de9497b758f75ad986ebd565bd2644ffb8f6d3e1d094b25a701edc220e6b]]]where A and B are 2x2 matrices and we compute the matrix product of A and B with the NumPy function np.dot() (where dot stands for 'dot product'). np.dot (dot product) computes vector product for 1D arrays and matrix product for 2D arrays. Note that np.dot(A, B) and np.dot(B, A) can be different values. Unlike normal operations (such as + and *), matrix multiplication produces different results if the order of the operands (A, B) is different.

[[[00000000000000001267---c27064895c09d234b019cd03f61dacc0dfbf3dbe5404d961620d56b141898414]]]Now, here we showed an example of calculating the product of matrices of 2×2 shape, but the product of matrices of other shapes can be calculated in the same way. For example, the Python implementation of the product of a 2x3 matrix and a 3x2 matrix looks like this:

[[[00000000000000001268---01876f41fae1ae7511875a82c95e3cea6780ad1656b8dd0874351b4ed9332a75]]]The product of a 2x3 matrix A and a 3x2 matrix B can be implemented as above. The point to be noted here is the 'shape of the matrix'. Specifically, the number of elements (number of columns) in the 1st dimension of matrix A and the number of elements (number of rows) in the 0th dimension of matrix B must be the same. In the above example, matrix A is 2×3, matrix B is 3×2, and the number of elements in the 1st dimension of matrix A (3) is the same as the number of elements in the 0th dimension of matrix B (3). is the value. If this value is different, the matrix product cannot be calculated. For example, if you try to multiply a 2x3 matrix A with a 2x2 matrix C in Python, you'll get the following error:

[[[00000000000000001269---5f97eba78e2994286df06c4fe5509d31e4c94e84af33be56a976c09172dc1f97]]]What this error says is that the number of elements in the 1st dimension of matrix A and the 0th dimension of matrix C do not match (the dimension index starts from 0). This means that multidimensional array multiplication requires that the two matrices have the same number of elements in corresponding dimensions. This is an important point, so let's check it again in Figure 3-12.

[[[00000000000000001270---3916ee0bc5724608880c5d5f25d0a74a7459760195ce4456e85d18cbf78cd854]]]
Figure 3-12 Matching the Number of Elements in Corresponding Dimensions in Matrix Multiplication


[[[00000000000000001271---c32064d75569feaa51d188cb583421461d70784706359e77cb56ceece6ca2460]]]Figure 3-12 shows an example where the product of a 3x2 matrix A and a 2x4 matrix B produces a 3x4 matrix C. As the figure shows, the number of elements in corresponding dimensions of matrices A and B must match. And the resulting matrix C consists of the number of rows of matrix A and the number of columns of matrix B—this is also important.

[[[00000000000000001272---b674bb79d61ce95e79d2cc8bdfd1af9b93bc2a81a049639bef8ff14bbbc5c608]]]Note that even if A is a two-dimensional matrix and B is a one-dimensional array, the same principle of matching the number of elements in corresponding dimensions holds, as shown in Figure 3-13 below.

[[[00000000000000001273---3f30bd39e8de6cdd5bf7fa1c2f9073fc68630267e2d7515dcc298212e874600e]]]
Figure 3-13 Even if A is a two-dimensional matrix and B is a one-dimensional array, the number of elements in the corresponding dimensions must be the same


[[[00000000000000001274---10051cca78c65a6ddc7ab73397447798ac4196edcd0b24166fb9b6ff53b055ad]]]A Python implementation of the example in Figure 3-13 looks like this:

[[[00000000000000001275---b9ffb12f623ef74ed40d804ce864974e98e618870b29918bde1698f4d2308f3b]]]Neural network matrix product

[[[00000000000000001276---0e625c62166a538250c559ba796e796d55d712f53d8385a12f11d82697a3460e]]]Now let's implement a neural network using NumPy matrices. We are interested in the simple neural network in Figure 3-14. This neural network omits the bias and activation functions and assumes only weights.

[[[00000000000000001277---90b1857977be247a79690bd1db9bb262a72bda60364f2ea5b33c70580f78c04e]]]
Figure 3-14 Calculation of neural network by matrix multiplication


[[[00000000000000001278---d17f212deb86185996c1f649ea551fd960697022b51c47e3d91b0175f7677ff8]]]Regarding the implementation, pay attention to the shape of X, W and Y. In particular, it is important that the number of elements in corresponding dimensions of X and W match.

[[[00000000000000001279---79f2fbed6ba9cbf2e5dfd13660af8f51191c7f368d90861ccff3f42e9b2e5f02]]]As shown here, np.dot (dot product of multidimensional arrays) can be used to compute Y results in one step. What this means is that if Y has 100 or 1000 elements, it can be computed in one operation! If you don't use np.dot, you have to pick each element of Y and do the calculation (or use a for statement to do the calculation), which is very cumbersome. Therefore, it can be said that the technique of being able to perform calculations at once by multiplying matrices is very important for implementation.

[[[00000000000000001280---f62a330bf56ee2c0ca120db9e2b9a614e45bdb9daeddfafa5ca5f0958e418dbf]]]Implementation of a 3-layer neural network

[[[00000000000000001281---1ba6bbd80d459df4fe4af72959a1d5ff0359a7a450d27dbc21ce6b55a78dfb83]]]Now let's do a 'practical' neural network implementation. Here, we will implement the processing from the input to the output (processing in the forward direction) for the 3-layer neural network shown in Figure 3-15. As for the implementation, we use NumPy's multi-dimensional arrays described in the previous section. By making good use of NumPy arrays, you can complete the forward processing of a neural network with very little code.

[[[00000000000000001282---783af15a0404c92a79b51c6d415551ac72163f4f3432d13a55f5c41e3a3815dd]]]
Figure 3-15 Three-layer neural network: 2 input layers (0th layer), 3 first hidden layers (1st layer), 2 second hidden layers (2nd layer), output Layer (3rd layer) consists of two neurons


[[[00000000000000001283---3e701dcec300a4b300aff303f77ed1ae60fbbdf44c76561c3665af9df309083e]]]symbol confirmation

[[[00000000000000001284---e85b488071b19d2cae19c4eaa628ba94e556a207dbc47c3330740b5815473c99]]]Here, symbols such as w12(1) and a1(1) are introduced to explain the processing performed by the neural network. It may look a little complicated, but these symbols are only used in this section, so you can skip them.

[[[00000000000000001285---94e15b53409df434030c466dfa6a7b1e5fd04e884c215442ed9a95ad3db6c980]]]The important point in this section is that neural network computations can be lumped together as matrix computations. Calculations for each layer of a neural network can be performed collectively by multiplying matrices (thinking from a larger perspective), so even if you forget (or don't remember) the detailed symbol rules, you can understand the explanations below. No problem at all.

[[[00000000000000001286---aba6088cb9359888a1ec8de99519e35e1f72c483c9d346b1db8b57a973af1e6b]]]Let's start with the definition of symbols. See Figure 3-16 below. Figure 3-16 picks up only the weight from the input layer x2 neuron to the next layer neuron a1(1).

[[[00000000000000001287---454cc36a1d63f08738d9ec5ad4a7ccde53ea1bb2347c03c5807dc3737c797e4d]]]
Figure 3-16 Weight Symbols


[[[00000000000000001288---f527dd2e76cfdfa555dc8bcf4e324538fd0187def8102ae2c276800479670210]]]As shown in Figure 3-16, weight and hidden layer neurons have '(1)' in the upper right corner. This is a number that means the weight of the first layer, the neuron of the first layer. Also, there are two numbers on the bottom right of the weight, which consist of the index numbers of the neurons in the next layer and the neurons in the previous layer. For example, w12(1) means the weight from the 2nd neuron in the previous layer (x2) to the 1st neuron in the next layer (a1(1)). The index number at the bottom right of the weight is arranged in the order of 'next layer number, previous layer number'.

[[[00000000000000001289---6c65242b7d9b71c6d2e70cb87d1375fb544391ff6f5238e58d6480de5a3fa80a]]]Implementation of signaling in each layer

[[[00000000000000001290---c6ac61f4cf6480e19591be6c175b84785bca4f2b94023167703e3016c9aa4ba1]]]Now let's look at the transmission of signals from the input layer to the 'first neuron in the first layer'. When represented graphically, it looks like Figure 3-17.

[[[00000000000000001291---fc809d76bf811e7a0e8eea45c42dac773c6f3b2d89d8dfa23faf1def8e095d63]]]
Figure 3-17 Transmission of signals from the input layer to the first layer


[[[00000000000000001292---512bc2ccf6ebd86067ea9bdf208632cc9c203c03404153f07efc844d972b4b2d]]]As shown in Figure 3-17, a neuron for bias ① has been added. Note that there is only one lower right index of the bias here. This is because there is only one bias neuron (① neuron) in the front layer.

[[[00000000000000001293---b234b7d4e14a3b3bb28ef6eb635e4e566dc45226161091902e2e60ec51ecb8bd]]]Let's express a1(1) as a formula including the confirmation so far. a1(1) is the sum of the weighted signal and the bias, computed as

[[[00000000000000001294---1df540f9250400e09bdb55b8d212e2e638c4613fa843bcbafe3861b1cbb679e5]]]Equation (3.8)

[[[00000000000000001295---9d0e1e31a912f0a9ef4666bec325af4bf87f7c59bf5d4baa0d9cc104b610314a]]]In addition, using the matrix product, the first layer 'weighted sum' can be summarized by the following formula.

[[[00000000000000001296---d59bf63468543a869126d1b066384aa57dca5350baff3c607049e338ac1c83a9]]]Equation (3.9)

[[[00000000000000001297---09c686896ec0f8aa5a420e973baf8864bff480982204b06bdbe06bf17102e30d]]]However, is as follows.

[[[00000000000000001298---706d6873696fd4e5bb6b05638f4e3befb9fd3751095171db248d252dfbf16a26]]]Now let's use NumPy's multidimensional arrays to implement equation (3.9) (where the input signal, weights, and biases are set to arbitrary values).

[[[00000000000000001299---c95c5ce5069ddaf5a44835fc6c08e073207f24448903906aa160963c32e3ad04]]]This calculation is the same as the calculation done in the previous section. W1 is a 2x3 array and X is a one-dimensional array with 2 elements. Again, the number of elements in corresponding dimensions of W1 and X match.

[[[00000000000000001300---27e09157d422e3bdaf45ccb1ba4adda138cd7180c0f53cd9cf885c399dba0f69]]]Next, we will look at the process by the activation function of the first layer. The process by this activation function can be represented graphically as shown in Figure 3-18 below.

[[[00000000000000001301---de697eb7abdfcc9bbb49c9530d242f058148a4be390dd6d84aa5f0ad1e0d7f48]]]
Figure 3-18 Signal Propagation from Input Layer to First Layer


[[[00000000000000001302---68e1d2ea51becc9c31a202da34adda6335f25c43d8a5e37aac591289b4968122]]]Let a denote the weighted sum (sum of weighted signal and bias) in the hidden layer and z denote the signal transformed by the activation function, as shown in Figure 3-18. Also, in the figure, the activation function is represented by h(), and here we will use the sigmoid function. Implementing this in Python looks like this:

[[[00000000000000001303---cea2952fa5e6e2fe5044121877b63147bec39b1e98d6feba694b533c0e58dee2]]]This sigmoid() function is the function we defined earlier. This function takes a NumPy array and returns a NumPy array with the same number of elements.

[[[00000000000000001304---8b6e26461cff01fc5165494890ae3423246bc1073828d9294d41c210e1310f49]]]Next, we will implement the first to second layers (Figure 3-19).

[[[00000000000000001305---0ec30db12cc9472443bae1b31f109738fef91195b842e154964db9921e05f9fe]]]
Figure 3-19 Signal Propagation from Layer 1 to Layer 2


[[[00000000000000001306---3c308075861272e039fc272d0e625086bc36046af6bc75e5f6743040a052fcc2]]]This implementation is exactly the same as the previous implementation, except that the output of the first layer (Z1) is the input to the second layer. You can see that using NumPy arrays makes it easy to write signal propagation from layer to layer.

[[[00000000000000001307---1fc127bc3d1b697616f16d8d251abbf3d279234fa1acc7822e6703e5d7f3ac71]]]Finally, the transmission of signals from the second layer to the output layer (Figure 3-20). The implementation of the output layer is also almost identical to the previous implementation. However, only the final activation function differs from the previous hidden layers.

[[[00000000000000001308---27c80b92db37c7fc92a0f67b1055522cd38fd96b9627fde243fcdc3f607d5d7a]]]
Figure 3-20 Propagation of signals from the second layer to the output layer


[[[00000000000000001309---eaa7abbfb0cb3a8ad61f6a1e1bd1c079db7ba0761b683142fd1b3e6ca5f6388f]]]# or Y = A3

[[[00000000000000001310---e7e295911a730a5cc19fd169cd01b688523a9674c3826c78b7f4759b9afbf9ac]]]Here, we define a function called identity_function(), and use this function—called the “identity function”—as the activation function for the output layer. The identity function is a function that outputs its input as is. Therefore, in this example, there is no need to define identity_function(), but it is implemented in this way in order to be consistent with the flow so far. In the notation of Figure 3-20, the output layer activation function is represented by σ(), which indicates that it is different from the hidden layer activation function h() (σ is called 'sigma'). .

[[[00000000000000001311---de42ab0c7a9eb416282812b21614d105e457314fca85830a9642fd1d0c865dee]]]The activation function used in the output layer is determined according to the nature of the problem to be solved. For example, it is common to use the identity function for regression problems, the sigmoid function for two-class classification problems, and the softmax function for multiclass classification. The activation function of the output layer will be explained in detail in the next section.

[[[00000000000000001312---8c9cad8f91b14c7c5ac9cc56b5571a846025658809c6558a8ef44d64d6b3d3d3]]]Implementation summary

[[[00000000000000001313---7b864640742f2b08ff6b074948cafa3f16a75b67b0b65ac024e855f74ca40069]]]This concludes the explanation of the 3-layer neural network. Let's summarize the implementation we've done so far. Note that here, as a convention for implementing neural networks, only weights are written in capital letters, such as W1, and other weights (bias, intermediate results, etc.) are written in lower case.

[[[00000000000000001314---54afa5ad3acec078c0c73ba406df3b410c74647d3e637a68796eba5f7f323b0c]]]Here we define the functions init_network() and forward(). The init_network() function initializes the weights and biases and stores them in the dictionary variable network. This dictionary variable network contains the parameters needed for each layer—weights and biases. And the forward() function collectively implements the process of transforming the input signal into the output.

[[[00000000000000001315---fb706beb45e3c1393d9aba4f23d7942bce1463963251452bfd17b4626243ec00]]]By the way, the word 'forward' is used here, but this expresses the transmission process from the input to the output direction. Later on, we will look at processing in the backward direction—from output to input—when training a neural network.

[[[00000000000000001316---ec21c6aa1775ebd8c5e65be0aaeaf9e0eafd4ad80451cb75dc4e06661d13d1e4]]]This concludes the implementation of the forward direction of the neural network. By skillfully using NumPy's multidimensional arrays, we were able to efficiently implement a neural network!

[[[00000000000000001317---4f5efd8fd530fd22103bc0572415eca9128c1c12a118e443d1929bd8170a82f9]]]Output layer design

[[[00000000000000001318---486109cd46123e9ea04cbb3c1692e9379b098e9937c9096a039b8185aa0de68a]]]Neural networks can be used for both classification and regression problems. However, it is necessary to change the activation function of the output layer depending on whether it is used for a classification problem or a regression problem. In general, we use the identity function for regression problems and the softmax function for classification problems.

[[[00000000000000001319---2191a7e424c415333ab1990d90e7705b0ff2b86a45386ce4fe7538c01a60d8ab]]]Machine learning problems can be roughly divided into 'classification problems' and 'regression problems'. A classification problem is the question of which class the data belongs to. For example, the problem of classifying whether an image of a person is male or female corresponds to the classification problem. A regression problem, on the other hand, is a problem of making (continuous) numerical predictions from some input data. For example, predicting a person's weight from an image of a person is an example of a regression problem.

[[[00000000000000001320---02fefb140734e30f31b458bcf8d7a0190c87e48643a4a77534754e46d76ab00e]]]identity and softmax functions

[[[00000000000000001321---f31bb9a17a07eb4a54d43f24561d58d4d885365de34e59368629864732999e8d]]]The identity function simply outputs its input. A function that outputs what it comes in without doing anything else—that's the identity function. Therefore, when using the identity function in the output layer, it just outputs the input signal as it is. In addition, if we represent the process by the identity function in the diagram of the neural network we have seen so far, it can be written as shown in Figure 3-21. The process transformed by the identity function is the same as the activation function in the hidden layer so far, drawn with a single arrow.

[[[00000000000000001322---922decf72a610077e99ee074fb1cfac92ec22e9df1ee8b401d0c20f65d08c67d]]]
Figure 3-21 Identity Function


[[[00000000000000001323---c96e731dc90aa918a64b7889963d9f2019f334d50119b77e689c4d12984d6428]]]On the other hand, the softmax function used in classification problems is expressed by the following equation.

[[[00000000000000001324---1b70cdb55cd0601239f3e3fcc961855b97e4da730d5ac6be452447f5b646b705]]]Equation (3.10)

[[[00000000000000001325---dcd54aecd64dd6e90fdf933e596bb4454477aa15ada6e8fd5affe71d5c6c5772]]]exp(x) is the exponential function representing ex (e is Napier's number of 2.7182…). Here, assuming that there are a total of n output layers, the formula for calculating the k-th output yk is shown. The numerator of the softmax function consists of the exponential function of the input signal ak and the denominator consists of the sum of the exponential functions of all input signals, as shown in equation (3.10).

[[[00000000000000001326---06ff6903cace966639825974b326c4e4d67211de790c998ed89199d2125cfd9a]]]A diagram of the softmax function is shown in Figure 3-22 below. As shown in the figure, the softmax output has arrow connections from all input signals. This is because each output neuron is affected by all input signals, as can be seen from the denominator of equation (3.10).

[[[00000000000000001327---9859a1383a1cd0e1bcc10d9c21423e6e666dc3d8fe299baf8f24a664042c1789]]]
Figure 3-22 Softmax function


[[[00000000000000001328---4a74de5ecc2bed497966545629403e881420ebe5747453de7c71e93276cd1d2f]]]Now let's implement the softmax function. Here, I would like to proceed while checking the results one by one using the Python interpreter.

[[[00000000000000001329---84e749386b31631375668db34c925c325a9ec0630baf1b00d11675073773f26d]]] # exponential >>> 

[[[00000000000000001330---a9a74640b21c47eddddb9f8a764af051db28155ff1c0a3d61978fdca378ecefb]]] # sum of exponentials >>> 

[[[00000000000000001331---dcff363cfd22db02a25f686e8588c83cdbefc264090e82676ce92ffe912834e2]]]This implementation is a Python representation of the softmax function of Eq. (3.10). Therefore, no special explanation is needed. Here, considering using the softmax function later, we will define it as a Python function as follows.

[[[00000000000000001332---7c15860f9ad6b046d0d4112a646f41c188afe31d07104f2f87d49d5097a68952]]]Notes on implementing the softmax function

[[[00000000000000001333---3cf50a48ca0b2dc0ba7bcf620c6deeed7d2a9ced33a5c6828b50809e7f5ab630]]]The implementation of the softmax function above expresses Eq. (3.10) correctly, but it has flaws in computation. That flaw is an overflow problem. The implementation of the softmax function involves calculating the exponential function, and the value of the exponential function can easily become a large value. For example, e10 exceeds 20,000, e100 is a large value with 40 or more zeros, and the result of e1000 is inf, which represents infinity. And when you divide by such large numbers, the result will be 'unstable'.

[[[00000000000000001334---71f3365bd545f9d6c33110abc014c1fc29b6c34de10e5a4412fc6acdd04d2720]]]When dealing with 'numbers' on a computer, the numbers are stored in a finite data width such as 4 bytes or 8 bytes. What this means is that numbers have significant digits, that is, there is a limit to the range of numbers that can be represented. This leads to the problem that very large values cannot be represented. This is called overflow, and you should (sometimes) be careful when doing computations on your computer.

[[[00000000000000001335---f245c59d7cc08ec0d568e7e3dbf96f8c4ac983f2f281469e74b592fcc2bb1010]]]An improved implementation of the softmax function follows from equation (3.11):

[[[00000000000000001336---959ee038a6c61083008342e6c751ca5c036a1d531da8fc77dd51e61eee52b5d2]]]Equation (3.11)

[[[00000000000000001337---86d58082ac6392ae3e6e314cef4d3fcc2ed710aab439cb4aeb6d7ed6cd6e124b]]]The first variant of equation (3.11) multiplies both the numerator and denominator by an arbitrary constant, C. increase). Then move that C into the exponential function (exp) and call it logC. Finally replace logC with another symbol C'.

[[[00000000000000001338---a8d49a7ffbf19f075ba7a79b83fea216c894987af8ad6d0e8b8aff3433d16b20]]]What Eq. (3.11) states is that when calculating the softmax exponential function, adding (or subtracting) some constant does not change the result. Any value can be used for C' here, but as a countermeasure against overflow, it is common to use the maximum value in the input signal. Let's look at a concrete example.

[[[00000000000000001339---74e3b2cd4fda06ec9a482661eb8dc6e0b8046a9d23c9fcc5d696b91c80739b8d]]] # softmax function calculation array([ nan, nan, nan]) # not calculated correctly >>> >>> 

[[[00000000000000001340---f385500a65aac4a87d85ae308c5dc105e8c1aed2853a1fb173416f3d271bf1ac]]]As shown in this example, it is possible to calculate correctly by subtracting the maximum value of the input signal (c in the example above), which would have been nan (not a number: indefinite) if calculated normally. . With all that said, implementing a softmax function would look something like this:

[[[00000000000000001341---b3dc2ea28c48d3eb9cc955662322d7624768b97dbb45778457d342bcdfd0bf34]]]# Overflow protection

[[[00000000000000001342---3936f95beecab866c33bc0c1c41cf71595ba0b83a7b24993bb6ccbdb5eea4f4b]]]Features of the softmax function

[[[00000000000000001343---885ddaa6df54729afc88b6be5431e13af55c0b0891af88162d74af05fc4b3e30]]]Using the softmax() function, the output of the neural network can be computed as

[[[00000000000000001344---d9840bf03420b8c08fe26a5e197ad5526d133b0cdca2833fbf262a414112ee1a]]]As shown here, the output of the softmax function will be a real number between 0 and 1.0. Also, the output of the softmax function sums to 1. Now, this property that sums up to 1 is an important property of the softmax function. This property allows us to interpret the output of the softmax function as a 'probability'.

[[[00000000000000001345---6db10dc9681639f59c594b8755d3368cc1f1df066647bf6f99e4e4c9e6d223fb]]]For example, the above example can be interpreted as y[0] with a probability of 0.018 (1.8%), y[1] with a probability of 0.245 (24.5%), and y[2] with a probability of 0.737 (73.7%). increase. And from this probability result, we can say, 'The answer is the second class, because the second element is the most probable.' You can also give probabilistic answers like '74% chance of being in the 2nd class, 25% chance of being in the 1st class, 1% chance of being in the 0th class.' In other words, by using the softmax function, it becomes possible to deal with the problem probabilistically (statistically).

[[[00000000000000001346---2e4787094f30d769ce1d7c2ba48262e9fee83f1e8f6d883d92332b42f40f0a2c]]]It should be noted here that the magnitude relationship of each element does not change even if the softmax function is applied. This is because the exponential function (y = exp(x)) is a monotonically increasing function. In fact, in the above example, the size relationship of the elements of a and the size relationship of the elements of y have not changed. For example, the maximum value of a is the second element, but the maximum value of y is also the second element.

[[[00000000000000001347---cc037f87ddcdb1123f0325103803cd69cc95b8081e4232ea28bf586c091242d0]]]In class classification of neural networks, generally only the class corresponding to the neuron with the largest output is regarded as the recognition result. And applying the softmax function does not change the location of the neuron with the highest output. So when the neural network does the classification, we can omit the softmax function in the output layer. In practical problems, the softmax function in the output layer is generally omitted, since computing the exponential function requires a certain amount of computation.

[[[00000000000000001348---377b42796d02f4185ac17c80efd8fcf2e2e9737d0ba97269857546cf472f2cdc]]]The procedure for solving machine learning problems can be divided into two phases: 'learning' and 'inference'. First, the learning phase trains the model, and the inference phase uses the trained model to infer (classify) unknown data. As mentioned earlier, it is common to omit the softmax function in the output layer during the inference phase. The reason for using the softmax function in the output layer is related to the training of the neural network (see the next chapter for details).

[[[00000000000000001349---9e39be436c2ac7a3cca7eb8278f16983488603612186a0118e18a1ba2c530fec]]]number of neurons in the output layer

[[[00000000000000001350---77e230a2edb03d5a91d79e9a9df516ffb0b9dd6d7796b5090bec55af654548c1]]]The number of neurons in the output layer should be determined appropriately according to the problem to be solved. In class classification problems, it is common to set the number of neurons in the output layer to the number of classes you want to classify. For example, given an input image, the problem of predicting which of the digits 0 to 9 is in the image—a 10-class classification problem—has 10 neurons in the output layer, as shown in Figure 3-23 below. set to individual.

[[[00000000000000001351---2adf3dec34dcca181f02067e2726c1c303fed16f689a704e00ac18ed19912c95]]]
Figure 3-23 A neuron in the output layer corresponds to each number


[[[00000000000000001352---719e7fe207662549ed1af8f3969816f35bbceaba4c6a4efdc0200f969b3b509b]]]In this example, suppose the output layer neurons correspond to the numbers 0, 1, …, 9 from top to bottom, as shown in Figure 3-23. Also, in the figure, the values of neurons in the output layer are expressed in shades of gray. In this example, y2 is drawn the darkest, and the y2 neuron outputs the highest value. This means that the neural network is predicting the class that corresponds to y2, which is '2'.

[[[00000000000000001353---e846524460a545a5982ee019a503b4322d5fe87169738ac6c2b10c525b0f577c]]]handwritten digit recognition

[[[00000000000000001354---bd2b135464feee8fd3bd6deac69f513c27fdbd9a8ee67d5673a4a2f7a603dbb0]]]Now that you've learned how neural networks work, let's tackle a practical problem. Here, I would like to classify images of handwritten digits. Assuming that training has already been completed, we will implement only the “inference processing” of the neural network using the learned parameters. This inference process is also called the forward propagation of neural networks.

[[[00000000000000001355---d4632cc64fa673e373fe2ed140474c029069d0cc09e5bdaba4e17a303d8e5b4c]]]Similar to the procedure for solving a machine learning problem (performed in two phases, “learning” and “inference”), when solving a problem using a neural network, training data (learning data) is first used to determine weight parameters. It learns, and at the time of inference, it uses the previously learned parameters to classify the input data.

[[[00000000000000001356---2922d37c96664d4822b69487561d8b903431ce1b63a0122a0b7d84529080cc80]]]MNIST dataset

[[[00000000000000001357---3819a07d1f15a70d786b60833b657b8a64fc86523be3b08ff5c8676ba78853d6]]]The dataset used here is an image set of handwritten digits called MNIST. MNIST is one of the most famous datasets in the field of machine learning and is used in various places from simple experiments to research published as papers. In fact, the MNIST dataset often appears as experimental data when reading papers on image recognition and machine learning.

[[[00000000000000001358---c70958803188e8b6433eb3f8896541870378bf42f015f9866f6468a98e8139f6]]]The MNIST dataset consists of digit images from 0 to 9 (Fig. 3-24). There are 60,000 training images and 10,000 test images, which are used for learning and inference. A common use of the MNIST dataset is to train using the training images and measure how well the trained model classifies against the test images.

[[[00000000000000001359---62fa7dd32412c0e1ae7616a901c053efe88e83b8691b8865ba67a60d0cb4d46c]]]
Figure 3-24 MNIST image dataset example


[[[00000000000000001360---2cf53ccbcc51b95053b3366eb8e6549e789d8a63a88a98d27a2d9ecad64646a3]]]The MNIST image data is a 28x28 gray image (1 channel), with each pixel taking values from 0 to 255. For each image data, a corresponding label is given, such as '7', '2', '1'.

[[[00000000000000001361---07a83318b6542632b855a875bff4689fdded76dbb46c0fbdb9cf3a3cff83be59]]]This book provides a handy Python script, mnist.py (mnist.py can be found in the dataset directory), that will help you from downloading the MNIST dataset to converting the image data to NumPy arrays. When using this mnist.py, the current directory must be one of the ch01, ch02, ch03, ..., ch08 directories. Using the function load_mnist() of this mnist.py, you can easily load MNIST data as follows.

[[[00000000000000001362---fa38f5b379e5709dce127a3731eebdeb932f1a86348e03a54fc5bd4f7c006080]]]# settings for importing files in parent directory

[[[00000000000000001363---8e65124217920555e2f899e0dee753cf68535c8dd606791b5b72835d825863f6]]]# First call waits a few minutes...

[[[00000000000000001364---eb98a0edd6f55633b014f7ac71dfd55cc6bf976b76c19fc0e705844d2d068a3d]]]# output the shape of each data

[[[00000000000000001365---c77663f2c5bd6cb6ac7a0c502847d6769dc1dc39e547eca75f95a045a63ebddd]]]First, make settings for importing files in the parent directory. Then import the load_mnist function in dataset/mnist.py. Finally, load the MNIST dataset with the imported load_mnist function. The first call to load_mnist requires an internet connection to download the MNIST data. The second and subsequent calls only read the locally saved file (pickle file), so the process ends immediately.

[[[00000000000000001366---fd976044173514f80fdd96a0bfdbcc980919226cec7c598dc76e12ea52a52c09]]]The file for loading MNIST images exists in the dataset directory of the source code provided by this document. And this MNIST dataset is supposed to be available only from the ch01, ch02, ch03, ..., ch08 directories. Therefore, when using it, it is necessary to import the file in the parent directory (dataset directory), and a sentence sys.path.append(os.pardir) is required.

[[[00000000000000001367---1a463575b277915d371a248dd26b0318485d2f193be7f0f9b1009e6e84c421ce]]]The load_mnist function returns the loaded MNIST data in the format '(training image, training label), (test image, test label)'. Also, as an argument, you can set three arguments like load_mnist(normalize=True, flatten=True, one_hot_label=False). The first argument, normalize, sets whether to normalize the input image to a value between 0.0 and 1.0. If you set this to False, the input image pixels will remain the original 0-255. The second argument, flatten, sets whether the input image should be flattened (made into a 1D array). If set to False, the input image will be stored as a 1x28x28 3D array, if set to True it will be stored as a 784 element 1D array. The third argument, one_hot_label, sets whether to store the label as a one-hot representation. A one-hot expression is an array of 1s only for correct labels and 0s otherwise, for example [0,0,1,0,0,0,0,0,0,0]. When one_hot_label is False, labels that are simply correct answers are stored, such as 7, 2, etc., but when one_hot_label is True, labels are stored as one-hot representations.

[[[00000000000000001368---c39c7c92cefa63d56282e2064c8c490c73c680353fb4b8e030a155148116f73b]]]Python has a useful feature called pickle. This is the ability to save the running object of a program as a file. Once you load a saved pickle file, you can instantly restore the objects as they were when the program was running. Note that the load_mnist() function that reads the MNIST dataset also uses pickle (at the second and subsequent loads). By using the pickle function, you can prepare MNIST data at high speed.

[[[00000000000000001369---0aa6be92eea94738471dc89f2ed0cac9aec09c41c6ad457584422ee1f3aa1d8e]]]Now, to check the data, let's display the MNIST image. It uses the PIL (Python Image Library) module for displaying images. After running the following code, the first training image is shown in Figure 3-25 (the source code is in ch03/mnist_show.py).

[[[00000000000000001370---777184afcce265bca64e4746e7a5f6dc965209f97afbf02207e7e1fe7e5fda35]]]# Transform the shape to the original image size

[[[00000000000000001371---49743e3002aa161dad8ec1e76c01e61d2ce3c40c5e5c79d224ba72de191ff9df]]]
Figure 3-25 Display of MNIST image


[[[00000000000000001372---996881efff3771f64956a1ef1d5687c8a7b1c64c924e0d605cd886b2394cfbcd]]]Note that the image loaded with flatten=True is stored in one column (one dimension) as a NumPy array. Therefore, when displaying the image, it must be reshaped to its original size of 28x28. Reshape a NumPy array with the reshape() method, specifying the desired shape as an argument. Also, the image data stored as NumPy needs to be converted to a data object for PIL, which is done with Image.fromarray().

[[[00000000000000001373---faa495253abcf09136285a269750161e0fe9c52d23fc6cd561787a98e995b37d]]]Neural network inference processing

[[[00000000000000001374---e25b23f72f5e40477ab07dd1b92823954dd0f08d3c471e303e980f61154e6e98]]]Now, let's implement a neural network that performs inference processing on this MNIST dataset. The network consists of an input layer of 784 neurons and an output layer of 10 neurons. The number 784 in the input layer comes from the image size of 28 x 28 = 784, and the number 10 in the output layer comes from the 10-class classification (10 classes of numbers 0 to 9). Also assume that there are two hidden layers, one with 50 neurons and the second with 100 neurons. The numbers 50 and 100 can be set to any value. So first, define three functions -- get_data(), init_network(), predict() -- (the code shown here is in ch03/neuralnet_mnist.py).

[[[00000000000000001375---6581e51014d3930e0b783089d71396c4b66cffcfa0c1640d525d374e60b7382f]]]init_network() loads the learned weight parameters saved in the pickle file sample_weight.pkl. This file stores the weight and bias parameters as dictionary variables. The other two functions are almost identical to the implementations we've seen so far, so no explanation is needed. Now, use these three functions to perform inference processing with a neural network. And I would like to evaluate the recognition accuracy--how well it can classify correctly.

[[[00000000000000001376---70f682e7e178cb2e77378ee038c22779b904076f5069bc1079dd878955cca931]]]# Get the index of the most probable element

[[[00000000000000001377---60fd0d46cf3be5d11201d8d329f4e8e50e369f7481c5b423353aef8488999eeb]]]Here we first get the MNIST dataset and generate the network. Next, extract the image data stored in x one by one with the for statement and classify it with the predict() function. The result of the predict() function is the probability of each label as a NumPy array. For example, it outputs an array like [0.1, 0.3, 0.2, …, 0.04], which I interpret as a 0.1 probability of 0, a 0.3 probability of 1, and so on. Then, from this probability list, the index of the largest value ——which element has the highest probability—is extracted and used as the prediction result. To get the index of the maximum value in the array, use np.argmax(x). np.argmax(x) gets the index of the element with the maximum value in the array given to argument x. Finally, the answer predicted by the neural network is compared with the correct label, and the percentage of correct answers is the recognition accuracy.

[[[00000000000000001378---73ff7f6d86535c445ac90b7b969eb8502858bd9f085f10b65aa482713f890254]]]Running the above code will display 'Accuracy: 0.9352'. This means that we were able to classify correctly 93.52% of the time. Since the goal here was to operate a trained neural network, we will not discuss recognition accuracy. We will see how the recognition accuracy improves further. In fact, we plan to end up with over 99% accuracy!

[[[00000000000000001379---ee285e26d36aa9fed8d06a318ee04ec5a9cf95001648ac0a06d3ee09308292e2]]]In this example, the parameter normalize of the load_mnist function is set to True. When normalize is set to True, the function internally divides the value of each pixel in the image by 255 and converts the data value to be within the range of 0.0 to 1.0. The process of transforming such data into a certain range is called normalization. Pre-processing is the process of transforming the input data of a neural network in a certain way. Here, the input image data has been normalized as preprocessing.

[[[00000000000000001380---8c18435e254a0c4111179ce4fe3412c5da4457df3de16f61168f261560be41c6]]]Preprocessing is often used practically in neural networks (deep learning). The effectiveness of preprocessing has been demonstrated by many experiments, such as improved classification performance and faster learning. In the previous example, the preprocessing was a simple normalization of dividing each pixel value by 255. In practice, preprocessing often takes into account the distribution of the entire data. For example, normalization is performed by using the average and standard deviation of the entire data to move the entire data so that it is distributed around 0, or to keep the spread of the data within a certain range. There are other methods such as making the shape of the distribution of the entire data uniform—this is called whitening.

[[[00000000000000001381---c51b157077087190f1719b30ba63083d6f915ba9debc9c72f5664f0b8f56f8cf]]]Batch processing

[[[00000000000000001382---a1ad281cb929705f5d95788dded6ba488592b112f62aaf02deab2eb7ede1541c]]]That's all for the neural network implementation for the MNIST dataset, but let's revisit the previous implementation, paying attention to the 'shape' of the input data and weight parameters.

[[[00000000000000001383---b6df8e38a4d56fa023ae8b98bd6446ca870e352998d0e9ff1a0ac92b5861b661]]]Now, let's use the Python interpreter to output the weight shape of each layer of the neural network.

[[[00000000000000001384---af5706dc40ff1013e5522b31549f421e87c5035fb3511daee25c43d9c37def9e]]]From the results above, let's check that the number of elements in corresponding dimensions of the multidimensional arrays match (bias omitted). If we were to represent it graphically, it would look like Figure 3-26. Indeed, the number of elements in the corresponding dimensions of the multidimensional arrays match. Also notice that the final result is a one-dimensional array y with 10 elements.

[[[00000000000000001385---721b1b896b19d51e2342e5409246d3c964c83e6bc87ae3104f4a8729272814f5]]]
Figure 3-26 Changes in array shape


[[[00000000000000001386---6be51829a7873a876e61125b2de583fa214ad7f39f73fe66ac39fa3d853b4c4d]]]Looking at Figure 3-26 as a whole, a 1D array consisting of 784 elements (originally a 28×28 2D array) is input, and a 1D array (10 elements) is output. It is This is the flow of processing when only one image data is input.

[[[00000000000000001387---1423a8fb468a5bb924772345cb708ed67c863ec1f9d6b9208de441c8c56f5f26]]]Now let's consider the case of inputting multiple images at once. For example, I want to batch 100 images and process them with one predict() function. For that purpose, the shape of x can be set to 100 x 784, and the data for 100 sheets can be collectively used as input data. When represented graphically, it looks like Figure 3-27.

[[[00000000000000001388---c389a9088f104918ea747135fe68d10f518e1274f0309c83702f74821fd7f2c5]]]
Figure 3-27 Transition of array shape in batch processing


[[[00000000000000001389---f23c712a8def93c430553e29f0bf72d579d85a50e162dd8ed6aef02893200d42]]]The shape of the input data is 100x784 and the shape of the output data is 100x10, as shown in Figure 3-27. This means that the results of input data for 100 sheets are output at once. For example, x[0] and y[0] contain the 0th image and its inference result, x[1] and y[1] contain the 1st image and its result, etc. .

[[[00000000000000001390---a2a3dd444656039da70f209288b2f024cd51a09ccaea1f555e8d314dffc46dd7]]]A batch of input data, such as the one explained here, is called a batch. Batch has the meaning of 'bundle', and the image is an image that is bundled like bills.

[[[00000000000000001391---3cbf674b4ecd6b4d83cb956d90ec00f6fab81e3e68e330fa9c7061f2b05321ab]]]Batch processing has significant computational advantages. The advantage of batch processing is that the processing time per sheet can be greatly reduced. The reason why processing time can be reduced is that many libraries that handle numerical calculations are highly optimized so that they can efficiently process large array calculations. Also, if data transfer becomes a bottleneck in neural network calculations, batch processing can reduce the load on the bus bandwidth (exactly, the ratio of operations to reading data is can be increased). In other words, batch processing involves computing large arrays, but computing a large array at once completes the computation faster than computing smaller arrays in pieces.

[[[00000000000000001392---f8887a7c3d0362e17c94d55d96bc843b5bf7696e4ecfcd1c1cdad5d0286b462a]]]Now let's implement the batch process. The differences from the previously implemented code are shown here in bold.

[[[00000000000000001393---605330c156f3a4c9c4d6857690bb3b26d07af62ffd3fa9c9db3cd7dd0612fa0c]]]# number of batches

[[[00000000000000001394---0fbeb42c4ccd5db898068c06d581e96db8c1e80ce5089c8fdcf204b6b1c9c879]]]Let's go over the bolded parts one by one. Let's start with the range() function. The range() function creates a list of integers from start to end-1, given as range(start, end). Also, if you specify three integers like range(start, end, step), it creates a list in which the next value in the list element is incremented by the value specified by step. Let's look at an example here.

[[[00000000000000001395---46f8ba53b7e57357a46ad028494eaba21af19a30a196ba435f420472ecee817b]]]Based on the list output by this range() function, extract batches from the input data like x[i:i+batch_size]. x[i:i+batch_n] retrieves data from the i-th input data to the i+batch_n-th data, but in this example x[0:100], x[100:200], ... Then, 100 sheets are taken out as a batch from the beginning.

[[[00000000000000001396---bc8d2e688e66876940786cb598e3bfd37b2246f27aba5cf3f210ced37964e4a4]]]And get the index of the maximum value with argmax(). However, note that here we are giving the argument axis=1. This specifies finding the index of the maximum value for each element in the first dimension (with the first dimension as the axis) in a 100x10 array (the 0th dimension is the first dimension). Correspond). Here is another example.

[[[00000000000000001397---1252cdd4bc0ea18d481a093f0b05a117162492b19d2ce5354f17469995308562]]]Finally, compare the batch-wise classification result with the actual answer. For that purpose, a boolean array consisting of True/False is created using the comparison operator (==) between NumPy arrays, and the number of True is calculated. Let's see these processing steps in the following example.

[[[00000000000000001398---83f9121cb74c6673386eede5a0216e182ba631feb75ed419a2ab39f1d8624d01]]]This is the end of the explanation of implementation by batch processing. By performing batch processing, we were able to process efficiently at high speed. Also, when training the neural network in the next chapter, we will train the image data as a cohesive batch. In that case, the same implementation as the batch processing implemented here will be performed.

[[[00000000000000001399---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000001400---559d4ed738aaead55d2e564879180f93f4e65e608cfdab0077889dc9fea93582]]]In this chapter, we discussed forward propagation in neural networks. The neural network described in this chapter is similar to the perceptron in the previous chapter in that neuron signals are propagated hierarchically. However, there was a big difference in the activation function that changes the signal when sending the signal to the next neuron. For the neural network, we used a sigmoid function whose activation function changes smoothly, and for the perceptron, we used a step function whose signal changes abruptly. This difference becomes important in training neural networks, which we will discuss in the next chapter.

[[[00000000000000001401---19850c73ec605a12530fa271fcc972171b998181be314b2c4c58825fcf2e154b]]]What we learned in this chapter

[[[00000000000000001402---536a4a9a898acfb0c4d3dbf8eb6dd6fd023ce72977468967762bfcac4082cc84]]]Neural networks use smoothly varying functions such as sigmoid functions and ReLU functions as activation functions.

[[[00000000000000001403---87664802988e888b1440031ed2616f7107d710a0bb1110234406b3016638199e]]]NumPy's multidimensional arrays can be used effectively to implement neural networks efficiently.

[[[00000000000000001404---e8263aff3b5db080092d0c547b01b8653ff12d06230f8d7a7d8992cb7f5698da]]]Machine learning problems can be broadly divided into regression problems and classification problems.

[[[00000000000000001405---03ef5e6fd89c1feda6b947dbba32b73c2f6c2287ecba81f3dd436062f78a551a]]]The activation function used in the output layer is generally the identity function for regression problems and the softmax function for classification problems.

[[[00000000000000001406---1c34b63e9416da875c7febbd0dc5889dda2a4f3ce342e26a86e1fd914671a43a]]]For classification problems, the number of neurons in the output layer is set to the number of classes to be classified.

[[[00000000000000001407---51511da1cc7aaea0d47915bb7bfebb2dbe8b2a439ec6883506eedd42d207744b]]]A group of input data is called a batch, and inference processing can be performed in units of batches, enabling high-speed calculations.

[[[00000000000000001408---ed57a1570552eea464f1f2851658d827c8dc4137c96167d284c699c37d79b1ac]]]Chapter 1

[[[00000000000000001409---2fab3637f3e5db53b3aa48f0fa3fbe5340a1339adb1436a44b02b9f87896d39b]]]Introduction to Python

[[[00000000000000001410---c7c49ae718e9b0ce0a866e37ba13bb3d983bfc7d725ea88204eb3ebd4d7e7d02]]]It's been more than 20 years since the Python programming language appeared in the world. During that time, Python has gained a large number of users while undergoing its own evolution. And now it has become one of the most popular programming languages used by many people.

[[[00000000000000001411---51ebdba7241a61d08dffd68e0f9caed7b86ded9acfd2cb1d57261d81bc37f6c2]]]From now on, we will use Python to implement a system based on deep learning. Before that, in this chapter, I would like to briefly introduce Python and see how to use it. If you are familiar with Python, NumPy, and Matplotlib, you can skip this chapter and proceed.

[[[00000000000000001412---fdae850d2e92ed3bf06d9ea1db894b37cfc2164b25907f35f1963e5fa528bae6]]]What is Python

[[[00000000000000001413---85f6e075fb3ac32c1bae8d25deea43369899d9d31592936a87715beb86bce6d2]]]Python is a simple, easy-to-read, and easy-to-learn programming language. It is open source and free to use. Programs can be written with an English-like grammar, without laborious compilation. Therefore, Python is easy to use and is the best language for those who are new to programming. In fact, computer science courses at universities and colleges often adopt Python as the first language.

[[[00000000000000001414---e653d06c9c01c95d1acc43095497711c7c94e44c81d5da1adfa6e8981e63890e]]]Also, by using Python, you can write highly readable code and at the same time you can write code with high performance (fast processing speed). If you need to process large amounts of data or have a fast response time, Python can handle those tasks with ease. That's why Python is loved not only by beginners, but also by professionals. In fact, companies such as Google, Microsoft, and Facebook that compete on the cutting edge of IT frequently use Python.

[[[00000000000000001415---bf62fafbd845cef9c6bef7184724d42ce97d1f87ba342429a2f26b6e6bee42d3]]]And Python is often used in scientific fields, especially machine learning and data science. In addition to Python's high performance, excellent libraries such as NumPy and SciPy for numerical and statistical processing make Python a solid position in the field of data science. Furthermore, there are many situations where Python is used for deep learning frameworks. For example, famous deep learning frameworks such as Caffe, TensorFlow, Chainer, and Theano provide interfaces that can be operated from Python. Therefore, learning Python will definitely help you when working with deep learning frameworks.

[[[00000000000000001416---3c117d84cf1e0a7df875b5ba289190c57078dd52fca62f15f74dbc86d18ad65a]]]As such, Python is the programming language of choice, especially in the field of data science. And it has excellent qualities that can be used by a wide range of users, from beginners to professionals. Therefore, Python is the programming language of choice to achieve the goal of this book—to create deep learning from scratch.

[[[00000000000000001417---ff6a2efed6502e947ff8c258d1853b7049e8e853a2d80c86f0ecccf68ff54555]]]Install Python

[[[00000000000000001418---f843e46b1b7c0bb051a9d21e0f93b811276ccd40994d06e653d954b684bcbe0c]]]Now, let's install Python in your environment (PC). This section describes points to note when installing.

[[[00000000000000001419---9440ad2e007e398dade000aa5d7c3c52a34a094b7c182c5aafe812626f3c3f50]]]Python version

[[[00000000000000001420---5be15140d635ce07067036f5a4207c522ba4a5bb0d065363800d105662405a21]]]Python has two versions, 2 and 3. Looking at how Python is currently being used, not only the latest 3-series, but also the old 2-series are being used. Therefore, when installing Python, you should carefully choose which version to install. Because the two versions are not fully compatible (more precisely, they are not 'backwards compatible'). In other words, it happens that a program written in Python 3 series cannot be executed in Python 2 series. This book uses the Python 3 series. If you have only Python 2 series installed, we recommend installing Python 3 series separately.

[[[00000000000000001421---4778d2b511629ded76bf2f211d7dd02f788e17c38e3c258b116d8ca5161e107c]]]external library to use

[[[00000000000000001422---dd0f7d31e3dd404b6c2f913506131195fcac109b8c432d872606d017f7d047dc]]]The goal of this book was to implement deep learning from scratch. Therefore, our policy is to avoid using external libraries as much as possible, but we will use the following two libraries as exceptions. One is NumPy and the other is a library called Matplotlib. The reason for using these two libraries is to efficiently implement deep learning.

[[[00000000000000001423---0c3ad9c93c2b045c9b4af9269d107a636f3fc43552b7c6574ac6d66a519c549b]]]NumPy is a library for numerical computation. NumPy provides many convenient methods for advanced mathematical algorithms and for manipulating arrays (matrices). In the implementation of deep learning in this book, we will use these convenient methods to proceed with implementation efficiently.

[[[00000000000000001424---5703ae5ed2f28938e62d32bc949afaad43cc6ab6d9734e45678eaf8c1c0ff308]]]Matplotlib is a library for graph drawing. Using Matplotlib, you can visualize experimental results and visually check data during deep learning execution. In this book, we will use these libraries to implement deep learning.

[[[00000000000000001425---4414b7e06ebd5e0763725b72098bb8f71d34ab7f9edb7d30aab9e62c2ef0e219]]]This document uses the following programming languages and libraries.

[[[00000000000000001426---34bbdcb23e340f76bc2177ff531e77bc5e436618917b9e9322a51aabe7d0f3c5]]]Python 3 series (latest version is 3.5 as of August 2016)

[[[00000000000000001427---d4cb14c52716820d55ca4af6a12246c3c093ad2ebccffec2f3bfd266d2f1cda5]]]Next, I will explain how to install Python for those who want to install Python from now on. Skip if you have already met the above requirements.

[[[00000000000000001428---fec973d9f6036ef2d474381efef883d04a04fd6da40ce231788dcb158e0c4011]]]Anaconda distribution

[[[00000000000000001429---d727398a46e3fb50679458115a0410b36c9021072143d15d5b10f874b41045a7]]]There are several ways to install Python, but this book recommends using the Anaconda distribution. By the way, a distribution is a collection of necessary libraries etc. so that users can install them all at once. Anaconda is a distribution focused on data analysis. It also includes useful libraries for data analysis, such as NumPy and Matplotlib, which I mentioned earlier.

[[[00000000000000001430---c77d9de782d4d3ff6cf156234fea7a74d26b002c1cf602a1ae2505bbb21a7e66]]]As mentioned earlier, this book uses Python version 3.0. Therefore, Anaconda distribution also installs 3 series. Then, download the distribution that matches your OS from the link below and install it.

[[[00000000000000001431---4a130da275e244a6a84cd240b87490fae351b4f8ea20102506e1a3990b13cd2a]]]Python interpreter

[[[00000000000000001432---7b4bcdcc2db1a218cf3ca5f2700a39c6c6997d4ce3e87dbce4007f0aac98c999]]]After installing Python, check the Python version first. Open a terminal (command prompt on Windows) and enter the command python --version. This command will print the version of Python installed.

[[[00000000000000001433---18f26fcbfc66141b2d984451205999076783e1be64b84d5fadf6eb41fcf1f050]]]As shown above, if Python 3.4.1 (the number differs depending on the installed version) is displayed, it means that Python 3 series has been successfully installed. Then type python to start the Python interpreter.

[[[00000000000000001434---6f97bfbcd4bd525958b9978ddf392941be3e7f5ed674ee0e20ec0f55f8f66965]]]The Python interpreter is also called 'interactive mode' and allows you and Python to interactively program. Interactive means, for example, that the user can ask, 'What about 1+2?' and the Python interpreter will answer, 'It's 3.' Now, let's actually enter it.

[[[00000000000000001435---750edab9194ad8996a5a2ff1789b631b949d7941daca926fe670c2ac09c47d66]]]In this way, you can program interactively with the Python interpreter. We'll use this interactive mode to walk through a simple example of Python programming.

[[[00000000000000001436---56f6ca23aaf853832647d4e8ae4029439699e2b0a58009bd30d632f0d216d449]]]arithmetic calculation

[[[00000000000000001437---b01d7e5d94c54dd8ef5c8bdb539dd3aac8eccd46c7b04a46e85dc374c1a81045]]]Arithmetic calculations such as addition and multiplication are performed as follows:

[[[00000000000000001438---950356b0a6fc33b7d4c198fb8021548a1352dcab8601f3f8c8bf1e1d4617e98d]]]* means multiplication, / means division, ** means exponentiation (3**2 is 3 squared). Note that in Python 2, the result of division between integers is an integer. For example, 7÷5 results in 1. On the other hand, in Python 3 series, the result of integer division is a decimal number (floating point number).

[[[00000000000000001439---24d989c55571a336128af1ff48ee045b6d188b0087fd8e03ab801a7485e058a7]]]data type

[[[00000000000000001440---14abad2207efbdc884d74cd6e18ccefa5f67b0b60c54cf26a1b1896de41928eb]]]In programming, there are things called data types. A data type represents the nature of data, such as integers, decimals, and strings. Python has a function called type(), and you can check the type of data with this function.

[[[00000000000000001441---3d298af5b67210dd4766fd26786ba7010f844a25c43fe06e414a9afd8e0bc5c4]]]From the above results, we can see that 10 is of type int (integer type), 2.718 is of type float (floating point type), and 'hello' is of type str (string type). Note that the terms 'type' and 'class' are sometimes used interchangeably. here,<class ‘int’> , which can be interpreted as '10 is a class (type) called int'.

[[[00000000000000001442---1d1ef987633443e3cf3941a1eef5d4cbb1dee991f3677b7c6f5c3a4839cd715c]]]variable

[[[00000000000000001443---43c068ffe57d4cd9c2131b3788ab87b350d93f2517c511d35f6339898081b986]]]You can define variables using alphabets such as x and y. You can also do calculations with variables and assign different values to variables.

[[[00000000000000001444---1ee73dd9803cfd36c892e4c6f6d78bbaa17a8a7727f7a916b44d0f1f93344f2c]]]   # initialize >>> 

[[[00000000000000001445---4140343bf4e701a7314206eff2fc2ea36196022769de7b3c25fe08f3db183c59]]] # print x 10 >>> 

[[[00000000000000001446---7a0f2fc116948b02fbd4aa31cbbb6d6f8ae77a90c043d96ea1aa692416bf73c4]]]  # assignment >>> 

[[[00000000000000001447---74ff93c0d4c389ee11cad7a8829d4899cc30d11cdff96ad973228825df8c282a]]]Python is a programming language classified as a 'dynamically typed language'. Dynamic means that the type of the variable is automatically determined depending on the situation. In the example above, the user did not explicitly specify that x is of type int (integer). Python knows that the type of x is an int because we initialize it with the integer 10. Also, you can see that the result of multiplying an integer and a decimal is a decimal (automatic type conversion). In addition, '#' is said to be a comment out, and the characters after it are ignored by Python.

[[[00000000000000001448---6ab7e53c7595d5d91c5e821311210c89a87b23c9af099c750d35094f1a3aca55]]]list

[[[00000000000000001449---21031125f0e05a3f27c9a5ebdc54d452f23eaf1774b96cfb8ddfbb22d5c71cdb]]]Data can be organized as a list (array), not just as a single number.

[[[00000000000000001450---e2940a8e4b9b5b4620550ba0ae7769d5e1787ecf3679624aaaf67e63e616c5ec]]] # Create a list >>> 

[[[00000000000000001451---70585a77cbf27a95a4ea00aeb5d41ee6863e8b8444d3d8590d11003ace84e53e]]]  # print the contents of the list [1, 2, 3, 4, 5] >>> 

[[[00000000000000001452---02f6cfde18e017310eeeeb19eb49e082d8cbc69f8e7173f486ac17129dd4dcf3]]]    # Get the length of the list5 >>> 

[[[00000000000000001453---e328ca9ed3f7132927086098bb7338545e32123d14b6015e9834ac4f656ed717]]]      # access the first element1 >>> 

[[[00000000000000001454---373ff903c3c8f24926eb04ab2fff90e4c5eaf0040364c03da6dcfeca51cb8b12]]] # assign values >>> 

[[[00000000000000001455---628eb86de01c139d409ebc13ee9b6487667b997cdb0c754dd41cc5b1e8225356]]]Accessing elements is done like a[0]. The numbers in these [ ] are called indexes (subscripts), and the index starts from 0 (index 0 corresponds to the first element). Python lists also have a convenient notation called slicing. With slicing, you can access not only single values, but also sublists of lists (sublists).

[[[00000000000000001456---4b10a2e6346ecdecbd950b89b3dfc8ca33573f4b6cf7e4a04bc9840bbcc06bef]]] # get from index 0 to 2 (not including 2!) [1, 2] >>> 

[[[00000000000000001457---e94287594a357d19c4a4909d5cf1f9e80883f54801aeb26e5eb161489b25c6a9]]]  # get index 1 to last [2, 3, 4, 99] >>> 

[[[00000000000000001458---42ee86a3f2bc5b80eb5e792d99c8d7b98f428a2b65abe9c0a15c6285f2666833]]]  # get from first to 3rd index (not including 3rd!) [1, 2, 3] >>> 

[[[00000000000000001459---24c95234017156c37b1be510538c7baf4811224edc8b730a0dec5f9fa2cf4ea4]]] # get from first to last element [1, 2, 3, 4] >>> 

[[[00000000000000001460---402888982f14d1e60717e3b10f5d5c85ec918d8f0687a84561d919c2b05b0170]]] # get from first to two elements before last [1, 2, 3]


[[[00000000000000001461---85c01a95b37481255d7a22b5e8fda05ce78c770a554540fa486811ac17893c4d]]]To do list slicing, write a[0:2]. With a[0:2], the element from the 0th index to the second element before the 2nd one is extracted. Note that -1 in the index number corresponds to the last element, and -2 corresponds to the element before the end.

[[[00000000000000001462---12142e06e8db48d3fb476686997f66e06737a91ed94f99d52cb75ed6f0a65238]]]dictionary

[[[00000000000000001463---43fdb7b49c34e08e551a34c4b4761b7d60745e75946ffaf30414095c69e81b56]]]The list was indexed starting from 0, and the values were stored in the order 0, 1, 2, . A dictionary stores data as key-value pairs. A dictionary stores words and their meanings in correspondence, like a dictionary like 'Kojien'.

[[[00000000000000001464---f9164c24db2ec6a66237bc7ff1a2b744eb159f673c0fb91a0af853b1bec16f91]]] # Create a dictionary >>> 

[[[00000000000000001465---47aa7b87498f5f8cd08f67f0073dacf1eb4ad46da9c9b119a2f93bb4eb33aac5]]]        # access element 180 >>> 

[[[00000000000000001466---d05faa8002e801372e253d4d5fc518bf54d645bc79d9befb829cdf011c9f8aea]]]   # add new element >>> 

[[[00000000000000001467---f46dbbceb1ef4ff71ade542c69aee5f858e6842c179343790a13d9495e2f3510]]]Boolean

[[[00000000000000001468---af21b361768bb995ecbbf5e739a12e513625c029f42714d30983139a795f080f]]]Python has a type called bool. It takes one of two values, True or False. Also, there are and, or, and not as operators for bool types (the operators that can be used for numeric values are determined according to the type, such as +, -, *, /, etc.).

[[[00000000000000001469---e0d600a79ed6f89d3c08ecbd65b7eb31807c5dd03f9f12aca2667dd576800623]]]     # Are you hungry? >>> 

[[[00000000000000001470---de8c1b52c1426afcff04e7dcd31b41110e9c5aad97da092495c5719d7d4c25aa]]]    # sleepy? >>> 

[[[00000000000000001471---3e4371e29beec7ba5aad9336d0a7a96a16628889d262d3c130bd181e2418bd5d]]] # hungry and sleepy False >>> 

[[[00000000000000001472---75145f54a3bc33fdcd2698dd009fe3620b65d6131dc1169bfea7fb3bb769d55d]]]  # hungry or sleepy True


[[[00000000000000001473---79f47ab62701934d3bf6b0c9a41dfeb9d646b5b9ef81ec4b73795238ff3df329]]]if statement

[[[00000000000000001474---22a91cdbbb4e38c9fe11db5e6fe6acc386ec185485f015207a0984d1c27dbc82]]]Use if/else to branch the processing according to the conditions.

[[[00000000000000001475---b02cc78387f0035bed98db6fc508e41cf9727b2eb6c257e691db42b52bbeeb10]]] # Indent with whitespace... 

[[[00000000000000001476---d4d9e401f11a01a9734b080eafbb0abf10d4ae31654566ca54765a0e44dd6c57]]]Whitespace is significant in Python. In this if statement, the statement after if hungry: has 4 spaces at the beginning. This represents the indentation and the code that will be executed if the previous condition (if hungry) is met. This indentation can also be expressed using the tab character, but Python recommends using the space character.

[[[00000000000000001477---755128ca7e2a5bb8c9ebc0a2d5625c704a5915ad29a51a4be6878dd3a75bee94]]]Python uses whitespace to represent indentation. It's common to use 4 spaces per level of indentation.

[[[00000000000000001478---b41296c007beb28989686531353d07aa311f604bde2678a672da3cc742472528]]]for statement

[[[00000000000000001479---edf4c06a00c633d0894970048e5be94b52659956910009a65da425b1bb64d786]]]The for statement is used to perform loop processing.

[[[00000000000000001480---d728962723cd3e742b7029c8923c002ac80c9efce6c9b1eab9a88c7c54430c9f]]]Here is an example that prints the elements in the list [1, 2, 3]. The for … in …: syntax allows you to access each element of a data set, such as a list, in turn.

[[[00000000000000001481---e272ad108e92a957c633c48296c39cffbdc7b7bf2cf5618b7f9b718da5b43e28]]]function

[[[00000000000000001482---9448831dca41940e06611879a7e4278e6bf06b99b68a005777168c001bc1b9ea]]]Cohesive operations can be defined as functions.

[[[00000000000000001483---ff3c6b1b72e1dd1fee7db4172c851ba8f39baa7c0f8d4e59f63fa8fcd45e8f84]]]Also, functions can take arguments.

[[[00000000000000001484---f1ead4e8af798e2d6bfa377dd4abaad9aa459e7acc63346dfa4b357a408f3d6f]]]Note that + is used to concatenate strings.

[[[00000000000000001485---83095b2c295bf909bd5eebadd7aaeb35a6ff462109763dc34a4b2ba1a39d0cb4]]]To exit the Python interpreter, type Ctrl-D (hold down the Ctrl key and press D) on Linux and Mac OS X. For Windows, type Ctrl-Z and press Enter.

[[[00000000000000001486---6a22c3f4bfaa535721bfb7ec85f1e024395fe2f336545331d9dfaaac7221fa40]]]Python script file

[[[00000000000000001487---87911a63ebfa34b7658c54290835b66689aef4585e95e18b8e647a7c04f53fdd]]]So far we have seen examples with the Python interpreter. The Python interpreter is a mode in which you can run Python interactively and is very useful for doing simple experiments. However, it is a little inconvenient because it is necessary to input the program each time when trying to perform a large amount of processing. In such cases, save the Python program as a file and run that file (as a whole). Here we will look at an example with such a Python script file.

[[[00000000000000001488---74a140953d6eb7a897c643516ad1033e1e858a9e2c64adcbc0fcd7c94b76eaa9]]]save to file

[[[00000000000000001489---476f312bcb371d6bcb9ef02ef3797cda964447b9281d3a08cb224877730bf8ad]]]Now open a text editor and create a file called hungry.py. hungry.py is a single line file:

[[[00000000000000001490---751cbfa9377bf25df3553f3fdaff5dbd39db1b0ad47759922c2be0217ef3c388]]]Next, open a terminal (Command Prompt for Windows) and navigate to the location where hungry.py was created. Then run the python command with the file name hungry.py as an argument. Here, we assume that hungry.py is located in the ~/deep-learning-from-scratch/ch01 directory (the source code provided by this book has hungry.py under the ch01 directory).

[[[00000000000000001491---753c6845c6ece362e9f46fef43d89ae178eeee8cc8b17081793875f3db3eb76e]]]  # change directory$ 

[[[00000000000000001492---f5ffec4e0ecd599f72ab13c5e368472732b8cca54b8ece4ab6eba385d8fb0a65]]]Thus, you can run a Python program with the command python hungry.py.

[[[00000000000000001493---428926567c1a54452c7589a019ffcf0c3e6dc810a2ae267f6a48feb85a24ec07]]]class

[[[00000000000000001494---736e84cb7a8bff0afb138cc0b2809e03a026ab57a36b1f5a411b9ad21d23b498]]]So far, we've seen data types such as int and str (the type() function lets you find out the type of an object). These data types are data types built into Python from the beginning, called 'built-in' data types. Here we define a new class. Users can create their own data types by defining their own classes. It is also possible to define original methods (functions for classes) and attributes.

[[[00000000000000001495---18f2656a021c14da01dcca58bdb5afc396eb2f127d85048eb3de6525655e5ea2]]]In Python, classes are defined using the keyword class. The class follows the format (stencil):

[[[00000000000000001496---7bc0c1e7cbe57528ff1ff66f7e9f24221128f3cc9772852c70d411eef32ebf25]]]class Class name: def __init__(self, arguments, …): # constructor ... def method name1(self, arguments, …): # method1 ... def method name2(self, arguments, …): # Method 2...


[[[00000000000000001497---18808e36d0f618cfd2fef78c951b646fc34378d4d2db61d1620405f0ffd4f85b]]]Here there is a special method called __init__, which is the method that does the initialization. This initialization method, also called a constructor, is called only once when an instance of the class is created. In addition, Python is characterized by explicitly writing self (an instance of itself) as the first argument of a method. may seem strange).

[[[00000000000000001498---c1845f4c929a54f6a6ee5627d66ae091a9231a97481cf22711a912801f4704c8]]]Let's create a class as a simple example. For now, save the following program as man.py.

[[[00000000000000001499---f1493a653914701ce941b932ac412ae31cb3eae6bbfbb2d5511effde1c228ec1]]]Run man.py from terminal.

[[[00000000000000001500---0df3b5216f913f4c45e345cdf07b3246eead490d80244f9d8566d83ea67de050]]]Here we define a new class called Man. In the above example, an instance (object) called m is created from this class called Man.

[[[00000000000000001501---64a6a38c5442e0570b9f0742d36155ce00689b8228ec3a61bb54a95e14e7f11c]]]The constructor (initialization method) of the Man class takes an argument named name with which it initializes the instance variable self.name. Instance variables are variables that are stored in individual instances. In Python, instance variables can be created and accessed by writing an attribute name after self, such as self.name.

[[[00000000000000001502---817673bb46a9143dd99863337db6b5aefe066aa7b5a69eddfd72178c63403584]]]Array and matrix computations come up a lot in deep learning implementations. NumPy's array class (numpy.array) has many useful methods, and deep learning implementations also use those methods. Here is a brief description of NumPy, which we will be using in the future.

[[[00000000000000001503---e9381592d0825b7504e0316ce2bb359a82d9270f0e31098d118e7ff096fa2e54]]]Import NumPy

[[[00000000000000001504---9deca2338c118f6b269fac2c923a5ee7b037701e3fc546e8b2b10128a53a3e1e]]]NumPy is an external library. 'External' here means not part of standard Python. Therefore, the first step is to read (import) the NumPy library.

[[[00000000000000001505---cef8a2dae2991eda1a71107c14808a9aaa93a915862347087d8ee81dd49f5caa]]]Python uses the import statement to load libraries. Here, I wrote import numpy as np, but if I translate it literally, it means 'load numpy as np'. Written as such, methods related to NumPy can be referred to as np from now on.

[[[00000000000000001506---6c274a561281271a605561fe09c9a96e83f1fd0ebd8df4afa3947174140d2aab]]]Generating NumPy arrays

[[[00000000000000001507---bd1344e22c2373d008840d1709c9c2193361bc0cfdc859222df848f7e24f991c]]]To create a NumPy array, we use the method np.array(). np.array() takes a Python list as an argument and creates an array for NumPy (numpy.ndarray).

[[[00000000000000001508---707ce0b050a322d0c4dc886213d8cb9915b15084f3565f3617eaa25c39ff613d]]]Arithmetic in NumPy

[[[00000000000000001509---6479a1bbdea63fccdab3cc667f8219e639f6616f257306124d50f6522b31c194]]]Here's an example of arithmetic on NumPy arrays.

[[[00000000000000001510---2bc9e09653e1b9d00ddc80efacd4528c2b3aaad565e7181c6f795800c6dcc88c]]]  # element-by-element addition array([ 3., 6., 9.]) >>> 

[[[00000000000000001511---63586ff2290296198bab71ed2ce48c4274f8add9cf33332ce7b040c22818e07c]]]Note that the x and y arrays have the same number of elements (both are 1D arrays with 3 elements). If x and y have the same number of elements, arithmetic calculations are performed on each element. If the number of elements is different, an error will occur, so it is important to match the number of elements. By the way, the word 'element by element' is called element-wise in English. For example, 'element-wise product' is called an element-wise product.

[[[00000000000000001512---6489004b4d80377013d86022522729a9d3daa40c6ff75a8544f0146da3e7c499]]]NumPy arrays can perform not only element-wise calculations, but also arithmetic calculations on combinations of NumPy arrays and single numbers (scalar values). In that case, calculations are performed between each element of the NumPy array and the scalar value. This feature is called broadcasting (more on that later).

[[[00000000000000001513---7478d2f6f8d83fa368fc338e47c67c32b98c58186fc68dff4a3454055cd7ff1b]]]N-dimensional array in NumPy

[[[00000000000000001514---6d46aa60033772a3532370675874c5564043bb8ca89bc4f5f2a9b30911560412]]]NumPy can create not only one-dimensional arrays (arrays in one column), but also multi-dimensional arrays. For example, a two-dimensional array (matrix) can be created like this:

[[[00000000000000001515---8f9a6b4b5dcf9db6b151e910b3e584e254c165c9ff50f8cb250666aa593ac374]]]Here we created a 2x2 matrix called A. You can refer to the shape of matrix A by shape, and the data type of the elements of matrix A by dtype. Now let's look at matrix arithmetic.

[[[00000000000000001516---4f480184879db5530136b403749a677ce91a82f34b738d0cfbf9d155f8621847]]]As with arrays, arithmetic operations on matrices of the same shape are performed element by element. It is also possible to perform arithmetic calculations on scalar values (single numbers) on matrices. This is also a broadcast function.

[[[00000000000000001517---64f737b55c8c5cce9943f4352131c0dcb9bb16fce2075401fb13eaea3daa15dc]]]NumPy's array (np.array) can create an N-dimensional array. N-dimensional array means that you can create arrays with any number of dimensions, such as 1-dimensional array, 2-dimensional array, 3-dimensional array, and so on. In mathematics, one-dimensional arrays are called vectors, and two-dimensional arrays are called matrices. A generalization of vectors and matrices is called a tensor. In this book, we generally refer to a two-dimensional array as a 'matrix' and an array with three or more dimensions as a 'tensor' or 'multidimensional array'.

[[[00000000000000001518---f3d2d683d2c8f601672621d9e9f6249c13bbcad6c0b7c452e165665dd9fc3605]]]broadcast

[[[00000000000000001519---ecc490273d06e0c3c60211a6322715f5198045fb1ae19288bef8934c583cdd5a]]]NumPy also allows operations on arrays of different shapes. In the previous example, we multiplied the 2x2 matrix A by a scalar value of 10. What is done at that time is, as shown in Figure 1-1, the scalar value of 10 is expanded to 2 x 2 elements and the operation is performed. This clever feature is called broadcast.

[[[00000000000000001520---558c8d1c3cbbaa518d3e5f51cfabfddf89910dba87d0d6d8ed36a2daed571aa0]]]
Figure 1-1 Broadcast Example: A Scalar Value of 10 Treated as a 2x2 Matrix


[[[00000000000000001521---9fa27c1eb9f4cc87598e32908a23df34baf8dad48aee5ce64dfff68d469a49a6]]]As another example of broadcasting, consider the following computation.

[[[00000000000000001522---60814c98c6618f4c3226b7efafcf48446e64bbda92c276ea6c57bf457e1cf7bb]]]Here, as shown in Figure 1-2, the one-dimensional array B is 'intelligently' transformed so that it has the same shape as the two-dimensional array A, and an element-by-element operation is performed.

[[[00000000000000001523---e104e7e54b277431bd5ee860eb40ceedcac50d11b14af01497555807ed603e10]]]
Figure 1-2 Broadcast Example 2


[[[00000000000000001524---f07dddc43f35434697e17d8daecc5cffb84a39ed49dd65e79cb77859a9190e6b]]]In this way, NumPy has a function called broadcasting, so you can smartly perform operations on arrays with different shapes.

[[[00000000000000001525---97053f25751282634874f0a8ea9331cea961c68f8f4ca2250e4339526ee865f2]]]Accessing elements

[[[00000000000000001526---60598305f2dd2ef776b24f762afefa763961140389bc102495369611f19ef2d2]]]Element indices start at 0 (as usual). Access to each element is as follows.

[[[00000000000000001527---65e30f15970a7850bd82dd69a30567ee07e534a82f84b51a16732c06212c85fe]]]    # 0th line array([51, 55]) >>> 

[[[00000000000000001528---35065f2d22f4618a1e898efd6f69df2e1300b8135fc18e298054a9f32be52dd5]]] # element 55 at (0,1)


[[[00000000000000001529---5ed6f089faaf90ea523b30d4c4de2bb47d8b705c90727b888979d5374939965e]]]You can also access each element using a for statement.

[[[00000000000000001530---2b7567f19113bd77275fcda1556d067d3a6833d5083ad0bc9917cc01d4cd20eb]]]In addition to the indexing operations we've seen so far, NumPy also allows you to access each element by array.

[[[00000000000000001531---18424047d2ff14078cb624b6fe055708adf237eeb53c507af5739605a595c690]]]        # Convert X to a 1D array

[[[00000000000000001532---d35c374ef53decaf8246350e190ee04e94dec29653c4075060b8aa3779b57a26]]] # get elements with index 0, 2, 4 array([51, 14, 0])


[[[00000000000000001533---e29d3055bf3b8d8abd652b46b1f957944dc5686435a194bdedc7ec4b69c79dae]]]By applying this notation, you can get only the elements that satisfy a certain condition. For example, to extract only values from X that are greater than or equal to 15, we can write:

[[[00000000000000001534---549d1360f110e32cd6569411f28859a43e330d134238109a677646295cec14cf]]]Using operators such as inequality on NumPy arrays (X > 15 in the example above) results in an array of booleans. Here, we use this boolean array to retrieve each element of the array (retrieving the element corresponding to True).

[[[00000000000000001535---352ba38b8dc1d78be64c6b1ea3a860246b0ca2834db9ada8816c1f9862aa9991]]]Dynamic languages such as Python are said to be slower to process than static languages (compiled languages) such as C and C++. In fact, for heavy processing, it is better to write programs in C/C++. Therefore, when performance is required in Python, the contents of processing are implemented in C/C++. In that case, Python takes on the role of a 'middleman' that calls programs written in C/C++. As for NumPy, the main processing is implemented in C or C++. So you can use Python's convenient syntax without sacrificing performance.

[[[00000000000000001536---d8581fccffa9af4b47e21dc9238480753821574947bbf9d500e99f15570ed5d8]]]Graph drawing and data visualization are important in deep learning experiments. Matplotlib is a library for graph drawing. Matplotlib makes it easy to draw graphs and visualize data. This section describes how to draw graphs and how to display images.

[[[00000000000000001537---ccfeea27ca9ddfdac2ddbf6f1a1a3fa3de71da4cdf7c190e382f8e4025f84d20]]]Drawing a simple graph

[[[00000000000000001538---51ed261c12c2b86d779268cf53ed32593d286ca1cd38446daafd79314c9ea14f]]]The pyplot module of matplotlib is used to draw graphs. Let's take a look at an example that draws the sine function.

[[[00000000000000001539---4e9dc788891bd1f1fe01d64915735ddcaffc870c124e3ecda9ab23472fc23423]]]# create data

[[[00000000000000001540---970871491d9e255517e504ce2c8f42d3ad1eed2bc6700099ac5fbb3f8252cdd9]]]# generated from 0 to 6 in increments of 0.1

[[[00000000000000001541---551fbf6def7d02d0e96307ddaee805a7a29d2bfc387c6d3f186b9ce52912d633]]]# draw the graph

[[[00000000000000001542---109618d08bc66594d8e5876e9f8db16a7727265bf9bb4035ef937d3e27c58994]]]Here, the data [0, 0.1, 0.2, …, 5.8, 5.9] is generated by NumPy's arange method, and this is defined as x. Apply NumPy's sin function ——np.sin()——to each element of this x, give the data columns of x and y to the plt.plot method, and draw a graph. Finally, display the graph with plt.show() and finish. After running the code above, you will see the image in Figure 1-3.

[[[00000000000000001543---2c1bebf23a2582c8093b0d6877dbd6681f40ecb24e027829a04fe1ccf693625f]]]
Figure 1-3 Graph of sin function


[[[00000000000000001544---9a5fefd19eec62d9d8c15c72042fb3ba4f3ffb63f0d97e50b07e93fbaf65f188]]]Features of pyplot

[[[00000000000000001545---58520d169b19162aba957781c53b6b1bb83e65a4edca0aa9268cfaa9d21c638d]]]In addition to the sine function, let's add the cos function and draw. In addition, we will also try to make use of other features of pyplot, such as drawing titles and x-axis label names.

[[[00000000000000001546---4e9dc788891bd1f1fe01d64915735ddcaffc870c124e3ecda9ab23472fc23423]]]# create data

[[[00000000000000001547---970871491d9e255517e504ce2c8f42d3ad1eed2bc6700099ac5fbb3f8252cdd9]]]# generated from 0 to 6 in increments of 0.1

[[[00000000000000001548---551fbf6def7d02d0e96307ddaee805a7a29d2bfc387c6d3f186b9ce52912d633]]]# draw the graph

[[[00000000000000001549---56a916dbd6f1665d5d2f2f476d319a95141fd4d2f46c0f37504c6dd5a5038062]]]# draw dashed line

[[[00000000000000001550---6b0903f6bf9b5b7cb55430a1bd55bfad1896b234149e80c8cc4d867451c1c919]]]# x-axis label

[[[00000000000000001551---1a441358df9defc464ce0b333e7d9693e7edd33e903e399597c5d6ef6d3079da]]]# y-axis label

[[[00000000000000001552---dc3f3af0d12c5aee61de47b14ec6416c39dec5961fa2a407c030822d3a405cf5]]]# title

[[[00000000000000001553---8f9666f6b5bb6bef405112ba9910bdc117168f456568c84c2b1459fab4504cf1]]]The result is the graph in Figure 1-4. You can see that the title of the figure and the label name of the axis are described.

[[[00000000000000001554---dc5c43ac39056fbaa0a01088054c4bed00ae6b1e1fc3f3b29b6a6cb5f0cd6a75]]]
Figure 1-4 Graphs of sin and cos functions


[[[00000000000000001555---0dc3988118a41f0e321d59934d6803d1205317eef622ea54f6a6fdbd166c8188]]]Image display

[[[00000000000000001556---397a70349f243fc0e05422f892c170bab3ffde0500943dcf90b92bef3d3eacec]]]pyplot also provides a method imshow() for image display. Also, you can use imread() of the matplotlib.image module to read the image. Let me give you an example.

[[[00000000000000001557---1efd1dd607852dce8657bec0fba9d21a6085e41158f1aceaf6e2f4f01874f307]]]# load images (set proper path!)

[[[00000000000000001558---d0216e711e38cd09f95c8522cc8355bd99fcef5b431ece9e369463baa5fa6efa]]]After running this code, you will see the image in Figure 1-5.

[[[00000000000000001559---8c1b8229ef9b652daeadff7c65e5c1c2a760f4a6560f1ec1df2d11ed37dc0a8a]]]
Figure 1-5 Displaying an image


[[[00000000000000001560---04cc4cd3cf5c72815a711d6e77b4796f5ac93d04f1e3167dca1220a04aae9966]]]Here we assume that the image lena.png is in the current directory. You will need to change the file names and file paths accordingly in your environment. In the source code provided by this book, there is lena.png as a sample image in the dataset directory. For example, if you run the code above from the ch01 directory with the Python interpreter, change the image path 'lena.png' to '../dataset/lena.png' and it should work.

[[[00000000000000001561---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000001562---e5a608a9528fc006930327685d1618d1a47131636250867c32c41333db7fb3cb]]]This chapter is a page of preparation for deep learning. In particular, the focus was on explanations of programming necessary for implementing deep learning (neural networks). From the next chapter, we will step into the world of deep learning while showing code that actually works using Python.

[[[00000000000000001563---9e2238a1381c55b3ec799ab073e5e8bcc357e21158166fd5d9d8c9d2c411ae2a]]]In this chapter, we have kept the explanation of Python to the minimum necessary, but if you want to deepen your knowledge, the following books will be helpful. For Python, 'Introduction to Python 3' [1] is recommended. This is a practical introductory book that carefully explains Python programming from the basics to applications. For NumPy, 'Introduction to Data Analysis with Python' [2] is organized in an easy-to-understand manner. Outside of books, the website titled 'Scipy Lecture Notes' [3] provides a thorough explanation of NumPy and Matplotlib on the subject of scientific computing. Please refer to it if you are interested.

[[[00000000000000001564---678d863f2640bc553da5b29c720830fdf699710b442eb629e4de57428f81b2c0]]]So, to summarize this chapter, here's what I've learned:

[[[00000000000000001565---19850c73ec605a12530fa271fcc972171b998181be314b2c4c58825fcf2e154b]]]What we learned in this chapter

[[[00000000000000001566---c66ef8d7b21152f4879b615e483a7f124ef70d6e28bef4b600614537c73c5254]]]Python is a simple and easy-to-learn programming language.

[[[00000000000000001567---5b5e470e5f11b50efa085caff5cece182bce8b19c8bc51e8e7c2d2440668f5e1]]]Python is open source and freely available.

[[[00000000000000001568---f7d97c90a91073d9e582e9b2bd1c9d3e6cfce8c25bab97f86daabdf7a57fcc9d]]]The implementation of deep learning in this book uses Python 3 series.

[[[00000000000000001569---6491235ff5cbf483189a1d8e65ccf68556738b2826f1165993b30d1605e4990d]]]Use NumPy and Matplotlib as external libraries.

[[[00000000000000001570---aaab373e28db438cba90edd780b94883bcb6b3961f5c5ebac43e65864ad752bc]]]Python has two execution modes: interpreter and script file.

[[[00000000000000001571---6f1601f03937a7b3ed058508bf4ee0e4b9a89f1bd9e94edd60bdab32ef21b92f]]]In Python, implementations can be organized as modules such as functions and classes.

[[[00000000000000001572---78e5c449f3dd3073187f6df872cbe42014653cddd39d0114a5f9db7518e0b16f]]]NumPy has many convenient methods for manipulating multidimensional arrays.

[[[00000000000000001573---6763aa62211b44a20c71505eed18421683192c2f2f37668012e8aaa008367120]]]table of contents

[[[00000000000000001574---8436e0b0ef902ebd6da9f6f0ec21e99f841c4c2565715de6ee9ef693060fba69]]]　large door

[[[00000000000000001575---c4cf23daec95a26831302f10c2c2ac50a27c1900d0b8edb5d828fb23984bdae2]]]　credit

[[[00000000000000001576---a714161224255075961929dbba0d0997d0781ec435a517f55ecf5a7aee11f0e9]]]　Foreword

[[[00000000000000001577---098dd438561ca75b04afd8111a6e3c61aa6f3e33f91403f7644962ba43a33380]]]　Chapter 1 Introduction to Python

[[[00000000000000001578---abf795835d9aae3845ea7d22afe5a03f8ae3dc0ad70c6c3da5fea21f7eda447c]]]　　1.1 What is Python

[[[00000000000000001579---357942695f7cb4d748acbce76da0cd4021e3c4a0d0fe43e73db8eb624390fe5d]]]　　1.2 Installing Python

[[[00000000000000001580---9cffb7653a6ea18d29dce2c55b1cefa5c41bac3eaba43051ef2801fb1d1ae2e0]]]　　　1.2.1 Python version

[[[00000000000000001581---2ecf3e126ebe8aa22e3f358729bbd7e0eb1d4c98af8ba07f0b96ce6ce54c4545]]]　　　1.2.2 External Libraries Used

[[[00000000000000001582---dfe0efd27ca9985bcbed6bd326cdd3d50497d69855206d7ac741df29fa3931b4]]]　　　1.2.3 Anaconda Distribution

[[[00000000000000001583---813fc5dc42e54651b25fdcfa8da41458f2f3abe711a292855e88d0b377ca28f0]]]　　1.3 Python interpreter

[[[00000000000000001584---2f04cf03da870bc20be41bec7fde2921f5aae72b96e3a703fba47485e9ca5e2d]]]　　　1.3.1 Arithmetic calculations

[[[00000000000000001585---645c0bcaaa2eac8f1fef02070cc4141eea61a25c7d34e34be5c632815bee44fa]]]　　　1.3.2 Data types

[[[00000000000000001586---bf543d940a1cf387e9b72e479784cccb842bc66868732080dc5efad01048f30b]]]　　　1.3.3 Variables

[[[00000000000000001587---07e6fcb26484265b714eb3457d4114c3da28cec35c1aa01d95a7d45db825829b]]]　　　1.3.4 List

[[[00000000000000001588---a4036b19705c73ca22d1c293ad71297b05ae41cb3136b021b28f86d13a1e93d4]]]　　　1.3.5 Dictionary

[[[00000000000000001589---0724bac30ecc67dd7b669a2285a7b282ca04bc02f775e4a547d1fcb11e9a083e]]]　　　1.3.6 Boolean

[[[00000000000000001590---0abd5e5c71954cf5d3aace113c2b510afa175480a8d559d28ceefbb73e09a066]]]　　　1.3.7 if statement

[[[00000000000000001591---f541e5e7de915eb020ffa1cac2ea1fe05955ca9017055fe9ccef522ccaf25038]]]　　　1.3.8 for statement

[[[00000000000000001592---8766fc03c5fba5e0511870c20945b3ae17832a1b87e917eccbe7ceccd0d6444c]]]　　　1.3.9 Functions

[[[00000000000000001593---9c1358e27ea03e8c40eff151f6993a95a3df7c6fb9a6431957a14e93ac5f2465]]]　　1.4 Python script file

[[[00000000000000001594---dd174518cfbc197fecbbfbcca3a1205fb825766f1c3929b1d999a80762ad27ff]]]　　　1.4.1 Save to file

[[[00000000000000001595---287be7d28835c59bd36da1348909e99480c359cee5897f41629851db563e9f27]]]　　　1.4.2 Class

[[[00000000000000001596---1d84ad68bcf6e6e2be6172126b9fe6fbd352cefcd597ea908169d7c9378c31d0]]]　　　1.5.1 Importing NumPy

[[[00000000000000001597---ba30e27d4661fc0f775260e1012605f83bab0a72f1d85380bd570387a52aac18]]]　　　1.5.2 Generating NumPy arrays

[[[00000000000000001598---3dd50f8fa988bedc8025c96d13260a260e879e8135dcd5fdc10769d4bafe91c0]]]　　　1.5.3 NumPy Arithmetic

[[[00000000000000001599---50f110d0db1440bd7f95ca2e75e12440f4ed23c3b655aa4cea2c2880805a2a0c]]]　　　1.5.4 NumPy N-dimensional arrays

[[[00000000000000001600---71df90756d3b4defc615c6aab0e94d78019e09390fcdc04132a13ad606bec56a]]]　　　1.5.5 Broadcast

[[[00000000000000001601---cc43e1e5432987f113410d839f08a5da3e7e5ffb3a52e506e00a28d82ad987a3]]]　　　1.5.6 Accessing Elements

[[[00000000000000001602---7e170c30c2443feac83a2e9562456a9e4fd14f99dbbd8d6a813c28b91bb098e1]]]　　　1.6.1 Drawing a simple graph

[[[00000000000000001603---717f6de4a686e92b63e4b2937ccae6a85feba9c4cbfb88e6041bebd1bac4e329]]]　　　1.6.2 pyplot features

[[[00000000000000001604---5b2b8a2830e726704f3b8a5f80a46e80d4e531a37db286b68ceceb91eddc7122]]]　　　1.6.3 Displaying images

[[[00000000000000001605---d811938cd9db9d228d96ed98d32be06e910b82c43f1f1dbf9b3997e2fc47cdf4]]]　　1.7 Summary

[[[00000000000000001606---8f70c9855d70166039aa0e7ad38672a3eb9a0f1f4627a209a74df99082910e69]]]　Chapter 2 Perceptron

[[[00000000000000001607---01999e4653f5013d240f5dff15898bd10a771d3f85499e3b02c0ecb6463e8f06]]]　　2.1 What is a perceptron?

[[[00000000000000001608---f659056f7f13d29d2085c145dd7c36f4dec16002fe1969a3eb0203a7e788dd0f]]]　　2.2 Simple logic circuits

[[[00000000000000001609---69103ba50c4809fe021023d771dd291ec5ac0a51e11dd85d01723e4bda982ca1]]]　　　2.2.1 AND Gate

[[[00000000000000001610---bdfe253d32109f9d3589300d77d9830ac5bab182d3a462569cd544bb0d390c46]]]　　　2.2.2 NAND gates and OR gates

[[[00000000000000001611---4b2bd8e3317ca0e932a106b87e99ae62de2cabe6457c96c47ef0c02241edbd4d]]]　　2.3 Implementation of Perceptron

[[[00000000000000001612---95281f5d97f0d71ee59bb1611f95deae174dd5b2051b864bd6381ab4219cf143]]]　　　2.3.1 Simple implementation

[[[00000000000000001613---edf39f0b58a79a338e8dceaa2db76719f397b837b481edac5a280c959d9ed476]]]　　　2.3.2 Introducing weights and biases

[[[00000000000000001614---d901a2137fef59ad143f004a53d20dc7ecedba9374d9f9b61d75ee48581c0552]]]　　　2.3.3 Implementation with weights and biases

[[[00000000000000001615---325492b6227efbf29aea4c11676a1f8b7e63d00492b1bb24a3e17c1ded4052f9]]]　　2.4 Limitations of perceptrons

[[[00000000000000001616---f140d549c0572e05e95470efa11c18102cb50fffc999cc59280bd3d544d8706d]]]　　　2.4.1 XOR gate

[[[00000000000000001617---69fb6e477b755ef8c6d5d23c5a2c85ca71aadcc1b6d0ff37360706ad12963d4e]]]　　　2.4.2 Linear and nonlinear

[[[00000000000000001618---71d986a1b63b20d5b0535cbd57b3b8631a24651aeb54a670caa3b00fabc7211b]]]　　2.5 Multilayer Perceptron

[[[00000000000000001619---0dc678a0ea5cc87f982c5de91cda4e83fa4065b60cc34c87af0da5be0568aed6]]]　　　2.5.1 Combination of existing gates

[[[00000000000000001620---8a621a80ffbc4e9ec5c3211844cba9f9f1673f93112e3ef66053df8faa42f72e]]]　　　2.5.2 Implementing an XOR gate

[[[00000000000000001621---ee14586bd70b45e5372bb2accf06bf1dbb12b73d4e4189c2170c43e363b94a12]]]　　2.6 NAND to computer

[[[00000000000000001622---68d1a008e9436562866e93cdbedad527c7386efa526dbc9ff5bcf73ca3b284e4]]]　　2.7 Summary

[[[00000000000000001623---f19251e722fe1f274588e7edbdac332cb21349b5ae182bb0dec9c4ce321699bb]]]　Chapter 3 Neural Networks

[[[00000000000000001624---a247cadee8fa9497b8e0d9df0d8c97ebfc0c4b03e74df63b23678d46f91dcdf1]]]　　3.1 From Perceptrons to Neural Networks

[[[00000000000000001625---40ed500c88476b9b4646c8b1ed39306a5a0896f0cd842cf7cf96663ec7c3af32]]]　　　3.1.1 Neural network example

[[[00000000000000001626---d50007a55d1b8b8a92b53db4bed76538bc74e74a1ae79cecbd414a8c69dc241c]]]　　　3.1.2 Review of Perceptron

[[[00000000000000001627---381785d8c90a2a27883dc38d1f94ff18711a222fd1ae551dfe9915d06bdb171e]]]　　　3.1.3 Emergence of activation functions

[[[00000000000000001628---b3effbf068314cba3825a77c62c8d2eff2ff38975e87cc5773da8b040a4f9d90]]]　　3.2 Activation function

[[[00000000000000001629---26df5a4a0241dc4ba0e5d85a1d6c654b7dac6a0303918b2ff922400cccd1b176]]]　　　3.2.1 Sigmoid function

[[[00000000000000001630---bdfd176175d65cdab324acc0f1a5f7792be9a7e8c3c06fa78bb6b4c41a84c355]]]　　　3.2.2 Implementation of step function

[[[00000000000000001631---0529da9e2decbef8fef3bbd85e1a89cf2f52f3c8479edd6695cd8ad9907e8602]]]　　　3.2.3 Graph of Step Function

[[[00000000000000001632---6a6a4b15959a1471afc409ca97518fd1eed05afde5d619a5c0af63aa54ad5ddb]]]　　　3.2.4 Implementation of sigmoid function

[[[00000000000000001633---0eb01678bafb513541b9008fd7c585f06605f047795c4368fd4d9173d6fdcea1]]]　　　3.2.5 Comparison of sigmoid function and step function

[[[00000000000000001634---f143f147b330ddc7a9f74f202a8e13a4afb17c20d31bd678291bbc2c731bfa86]]]　　　3.2.6 Nonlinear functions

[[[00000000000000001635---707f35e3052ac0ce4d5053be8ab723bbaf1709dd4ba55712a2d4030399bcaf31]]]　　　3.2.7 ReLU-function

[[[00000000000000001636---3d4458cee556e427f145e5c02f70f42d61f16aaeffa064502adb432d8ffcabe1]]]　　3.3 Calculations on multidimensional arrays

[[[00000000000000001637---ea51910032fa8e30f5afaad29dc6bc04e5662133e36c5ab4588364f1c6ef648d]]]　　　3.3.1 Multidimensional arrays

[[[00000000000000001638---b8ab6ed23083cdf535702a5807a6e038f5f3d34659fdb427b4835128e5d1118a]]]　　　3.3.2 Matrix multiplication

[[[00000000000000001639---a9b30ea774e33425a193e3c4395a2a6b4f90067f57ad221498c2fde44a49fadc]]]　　　3.3.3 Neural network matrix multiplication

[[[00000000000000001640---f6a51fc7afc560196b1ff2b2a95b1737646744371228df9f4e124a47d60777da]]]　　3.4 Implementation of 3-layer neural network

[[[00000000000000001641---9ce7ffe200f9244f2ac1412494a4620103625b42cd255e7dc185571c2070ddc0]]]　　　3.4.1 Symbol confirmation

[[[00000000000000001642---9a0b05389c95841ba266561a842009629f75455cfed2f1b2316428f7c9cabc19]]]　　　3.4.2 Implementation of signaling in each layer

[[[00000000000000001643---a117a7edea258742cfc6f614df2c62d883d4ea180b641ce54602280c8077086f]]]　　　3.4.3 Implementation summary

[[[00000000000000001644---c1b96ba51df5b3086eb5b47643654cd166fb0c4f79845e0c415ba0b94d68f059]]]　　3.5 Designing the output layer

[[[00000000000000001645---13401997c686c37e0489a8b176254eddf37f8c91dafacd50759123818d696282]]]　　　3.5.1 Identity and softmax functions

[[[00000000000000001646---572906d0099ff6f05ed621b8ef3aa1d21135d5e9349ef5c910e56013d6c795f3]]]　　　3.5.2 Notes on implementation of the softmax function

[[[00000000000000001647---af3a2a03cc1aaa3798ae327d73c5b125e6a5c88f50e4cfa9c89042561ca2c331]]]　　　3.5.3 Characteristics of the softmax function

[[[00000000000000001648---bb216f74eef8ae3e90392d0f740f69a58240f6fee7feccb56a3590aeaf49facb]]]　　　3.5.4 Number of neurons in the output layer

[[[00000000000000001649---1e907f8356e12d7037c557781736d913dc18cccfdf7ae95e64a318afa88896c1]]]　　3.6 Handwritten Digit Recognition

[[[00000000000000001650---c74069b6523ea68b0e776c64cb77ae28132e98729a7a6bee01ac9f0338e7f8d8]]]　　　3.6.1 MNIST dataset

[[[00000000000000001651---6205e7cb92abdddd3b8d4412593108f627e7df694652eab44f5b5226fd5a23af]]]　　　3.6.2 Neural network inference processing

[[[00000000000000001652---de6458576b329fcac5bb4fb86546f5260f738ef489c2dca736b97d06fe0df63a]]]　　　3.6.3 Batch processing

[[[00000000000000001653---6fb95aab62d47488fdd787c2a1bd32e303a6d15777307fbedd410a8dd12a2824]]]　　3.7 Summary

[[[00000000000000001654---2a5f06f0259a4591b7c9eb4c3a7abaa7db7a56f68f0dc64873ba4b617d91c247]]]　Chapter 4 Training Neural Networks

[[[00000000000000001655---4e7a24da6bb210a5e37062f490c740466a7cc6597e817dbe97a0eea38ce11127]]]　　4.1 Learning from data

[[[00000000000000001656---f11c4b896453ed42f43fb7f5819727b21cd4613406817287c14e7c8f469f4b31]]]　　　4.1.1 Data driven

[[[00000000000000001657---4fb98d37656eab1990ee093683a7d2ab35a90b3c9a1c6ba879fb0ad0ddce62d1]]]　　　4.1.2 Training and test data

[[[00000000000000001658---8ff230721f25cbeffcf951320da0a5374743d7066f24695487a01d93f01eef1f]]]　　4.2 Loss function

[[[00000000000000001659---ef977b46e7992afa76e5f5323a400fac24911076a769a9a8be49cddea59f52fd]]]　　　4.2.1 Sum of squared error

[[[00000000000000001660---99fe33b7ee96a79befd600c16c765775de0f162ca803c9d0d90fdefd594b2843]]]　　　4.2.2 Cross entropy error

[[[00000000000000001661---968cf53f5261d0bc46a5b276b25e401fe456e4368b0a37808d9b0a82e1ebbc8a]]]　　　4.2.3 Mini-batch learning

[[[00000000000000001662---b6e88fc90604ceedab03b441f055c1e789fb49e12a2fe88b43d6c4f2f0ec9adf]]]　　　4.2.4 [Batch version] Implementation of cross-entropy error

[[[00000000000000001663---1dc68c7ece53a96e1c6e29fd9a8e50a5b8f1cca37c31a59d70ca885023813c23]]]　　　4.2.5 Why set the loss function?

[[[00000000000000001664---0de47c2e970e7f9486e4812a0fbb0d482e1532b4ebad1e75fa41e89a18995da1]]]　　4.3 Numerical differentiation

[[[00000000000000001665---c94f3e65a45f14102398e35475e787ff1bca70196a89e3ffdcd8905e4528879c]]]　　　4.3.1 Differentiation

[[[00000000000000001666---3ae73b2c9003dea51e196c814b65db3c11894e5be9493e59b28d1bed707d2e23]]]　　　4.3.2 Examples of numerical differentiation

[[[00000000000000001667---c451b63c4bbabb69fb893cdf653c4933272cd9c29d20fae9ad9c1431e319fb84]]]　　　4.3.3 Partial differentiation

[[[00000000000000001668---355f4afd13d1d624798ed71a049b28bdcaa6f3786786ef81f30c4b30058dc46a]]]　　4.4 Gradient

[[[00000000000000001669---07e551051bbdd67b5d246c1258b8d34b6c0ef3a975c69a371aab8602a91411c7]]]　　　4.4.1 Gradient method

[[[00000000000000001670---62e8b34ea99fed39fec9a68343c594abecbca1319dcc800a5b8df44bdead9d1e]]]　　　4.4.2 Gradients for Neural Networks

[[[00000000000000001671---08cf46639882044276e288924a3d98481e18a4f7b1e3202c06f320ef00538a29]]]　　4.5 Implementation of Learning Algorithm

[[[00000000000000001672---a91efd4caa79bc5ac9e2701022705d5fbfd2f3aa1a636b09745601242171165e]]]　　　4.5.1 A class of two-layer neural networks

[[[00000000000000001673---dd6294bd6eeb9dfaac2da8013839d94768f8499aeb90e59c32d0a15b4289497f]]]　　　4.5.2 Implementation of mini-batch learning

[[[00000000000000001674---24e16c266c6a761954612a7fb5884d408b7b7ae551827b66443dfb3a8cfa4c34]]]　　　4.5.3 Evaluation with test data

[[[00000000000000001675---c3a9d8e0214478c3191967de476da1b6f3e40e01a013a8985301dc9e8faad53a]]]　　4.6 Summary

[[[00000000000000001676---2dc6f503bfc79e09d006452d2a83206212ffbac4c87abcc60eeb4549a94dbf09]]]　Chapter 5 Backpropagation

[[[00000000000000001677---3ea8932720567c730c525985ae010a787ea8502628e453d1481ff72ef7e0f081]]]　　5.1 Computation graph

[[[00000000000000001678---678515358b3fb2ba96a966cbb835961d78c3ea57c506297a0b32ce5b0dcf89e0]]]　　　5.1.1 Solving with Computational Graphs

[[[00000000000000001679---4577400b7961dd5b7c2c2fe0a2cf25b21c54194bf3408a5d1465fa6b70f38659]]]　　　5.1.2 Local Computation

[[[00000000000000001680---b538e5e7130146b9d05cda1d8e5d16fa5da1b56b947ed9dab542f121f50f40b2]]]　　　5.1.3 Why Solve with Computational Graphs?

[[[00000000000000001681---b57344774ae43cc38b744217148151a83f8d940b0288fe6d30c71c24cfc574b9]]]　　5.2 Chain rule

[[[00000000000000001682---63c0861b083b6275a6b483f8cbc1cdbc7c2a2bb17c2c81969189dd48e3016165]]]　　　5.2.1 Backpropagation of computational graphs

[[[00000000000000001683---adc700e85cca6baef01042e0d3c3cbbaba0286821ff9f0db775a7bbda5a92b03]]]　　　5.2.2 What is the chain rule?

[[[00000000000000001684---6d0e818878e62ce325907444801263c3f30126cef141b614b1d5db5f80dc4e7a]]]　　　5.2.3 Chain rules and computational graphs

[[[00000000000000001685---14fa91b3b2a287c637014a6b5757eebfd90ff0d49b0f1dc0988abbb7fa0462e6]]]　　5.3 Backpropagation

[[[00000000000000001686---fab6e96ce64c1ad6e9dcc2c57149b39ae30112cfbdd37b228c4f5668a61141c2]]]　　　5.3.1 Backpropagation of Sum Nodes

[[[00000000000000001687---4d32f1def9a6f410bdc2ee26bd942df40e9b073dc46e2ac8d30af9f0d1d9939a]]]　　　5.3.2 Backpropagation of multiplication nodes

[[[00000000000000001688---59ffb2b7218c104e1588e333e41cb42a25378ddbd448524bc13c5aba18a0ffdd]]]　　　5.3.3 Apple example

[[[00000000000000001689---13b047378ebd0bce87b3ef509489e4610acdf565221484717739d8f4ddc32084]]]　　5.4 Simple layer implementation

[[[00000000000000001690---2c088b0e654116562aa3b1ec082b5c3e19ef58e7c89ac7ab5cebf78604f3c179]]]　　　5.4.1 Implementation of multiplication layer

[[[00000000000000001691---4d2e3af888890e299a7ef9a9dcd963b56d7696b13cb5a2dcfdb1d8ffa3403dd0]]]　　　5.4.2 Implementation of additive layer

[[[00000000000000001692---8a1b118d3dc2435865bc3a69ff4fd12415b15d15efcfb4380463ae0c9bde60f9]]]　　5.5 Implementation of Activation Function Layer

[[[00000000000000001693---2d6ada08fa0ab3d9b93dd439562e278e0f911b35b770f131e2fa61fe574e4183]]]　　　5.5.1 ReLU layer

[[[00000000000000001694---7af29fda36e736cc8003b76e3dd6b9495564bf027165ee3ebae0f01c1f78c397]]]　　　5.5.2 Sigmoid layer

[[[00000000000000001695---6c142d001f1e0f19449d3cc2cffa4ca3510a5f0f485ad4dbd1b8715df815955e]]]　　5.6 Implementation of Affine/Softmax layer

[[[00000000000000001696---86f21d029e475d75e4bb9b6f6ab85b502f0b93a5771a25cf8dcb39d51b9325ad]]]　　　5.6.1 Affine Layer

[[[00000000000000001697---ae40cb60b56570cf6cef234b7706a95b42639f49f980db9208436767e0cd6795]]]　　　5.6.2 Batch Affine Layer

[[[00000000000000001698---d969c5b9eb9bde32c75e8be35cfe0e8de75afce99d3429fc574fd1c9dd5ed7e8]]]　　　5.6.3 Softmax-with-Loss layer

[[[00000000000000001699---5bbc303a91e235a926064e809ce92f32381796754f5c2081c092bfe991ee7b24]]]　　5.7 Implementation of backpropagation

[[[00000000000000001700---0445ca58790a0a3b9013dc017085699801c70da2b80024f7827b525203a0b4a4]]]　　　5.7.1 Overall diagram of neural network training

[[[00000000000000001701---9b3fc3a443508823dd93af72a03518929e3e82eaf314ed0d5c096f9eb5437867]]]　　　5.7.2 Implementation of neural network for backpropagation

[[[00000000000000001702---93abab629b00ecd5fcbfe7f58e3afc0da42b41b4f9fe5922b1d8c17346a3cbf6]]]　　　5.7.3 Backpropagation Gradient Check

[[[00000000000000001703---824b3d13a642f3d30371d2e7aec61e0593d60db7037cb9104abc38ddedaa9bd9]]]　　　5.7.4 Training using backpropagation

[[[00000000000000001704---3c0b68dd1372f9327ceb64efb1c93427d5b8eb49118b2e52f1003f455b4bd2b0]]]　　5.8 Summary

[[[00000000000000001705---16ca8d86a6e3959c7baf3b8fcf5b16f413763d3ac727ce4a9736aafa675bf888]]]　Chapter 6 Learning Techniques

[[[00000000000000001706---6ad1c92458ab115cf852bcd9f1add5cf8b6cbcbcfea8912150fc49cea533d577]]]　　6.1 Updating parameters

[[[00000000000000001707---c42ae417bd76574387a29949a862aa4f57720eb0a770cff658fbec95130bbb52]]]　　　6.1.1 Adventurer's Tale

[[[00000000000000001708---dfb9401cdbec1659ca1e42cd79780ef633b073c40afd6bece37b98c10a9b2960]]]　　　6.1.3 Disadvantages of SGD

[[[00000000000000001709---d24203390efb8a663a39bd587bc9b0eaa4b336ac9a4fb13ff59be2f2f536bb49]]]　　　6.1.7 Which update method to use?

[[[00000000000000001710---8a58181ba5d3a409a18c912d6074901b45fa0f84edd931cfbbc8250f85da07c7]]]　　　6.1.8 Comparison of update methods with MNIST dataset

[[[00000000000000001711---a00e234d31df5d03bd7963590c14fa696fb092cfbbb105a2a84197226feb2770]]]　　6.2 Initial Weights

[[[00000000000000001712---223df5f21400393ca49f68b49c6a2365697aab85220c3784c11d7a1862d888b0]]]　　　6.2.1 Initialize weights to 0?

[[[00000000000000001713---a1512e712b0c5ae3cdbceab8229961dbbd3acb9c2875e9c883f61d7301a6b695]]]　　　6.2.2 Activation Distribution of Hidden Layers

[[[00000000000000001714---0e609409908e4530430caf0a26317b46ac47b5f8d4c8b327d4b442920ec57fb0]]]　　　6.2.3 Initial Weights for ReLU

[[[00000000000000001715---d309a7f56dea56a4bc5a9d9906c0e97d3e0c774900ab8df8dbc30c7c2dd6115c]]]　　　6.2.4 Comparison of initial weights from the MNIST dataset

[[[00000000000000001716---0479a7361aa6f6cde42663f456f6978d060cd419fb6cb66a8a1677d692fb5c8e]]]　　　6.3.1 Batch Normalization Algorithm

[[[00000000000000001717---fbc84e315929bcd73292b0e37217b339ca7d726659ee1ec35638ceede29ffbce]]]　　　6.3.2 Evaluating Batch Normalization

[[[00000000000000001718---d19d88b4fc69c503a4eb01bb5efa51dc2696fca39d0427faad2d3b59b76f0bd3]]]　　6.4 Regularization

[[[00000000000000001719---15de39ec3d28ee16137cb265ff4e4296db1ac35a9e17170d3f8ba1f75d1c4c5e]]]　　　6.4.1 Overfitting

[[[00000000000000001720---6c579d58e3aef8ccd2eb99338a66a5c87d036a99b6f09470a0b12b212780e48e]]]　　6.5 Validation of hyperparameters

[[[00000000000000001721---bd2987b82c3b5529373a265df0bf654b43b4e461d5f1dc1de7a5954ae957141d]]]　　　6.5.1 Validation data

[[[00000000000000001722---8ea147255380a92baaa81280a03b64cf96496ded67944897dd7f767bcf4dc0eb]]]　　　6.5.2 Hyperparameter optimization

[[[00000000000000001723---b09106350d326a79f49ab82ef176634913b6fb3ade11d6ae26405fb8a9765686]]]　　　6.5.3 Implementing hyperparameter optimization

[[[00000000000000001724---bd6b7f11ef97f57139e54084fce81459a867cbfd6f4e912773a73333286fccc4]]]　　6.6 Summary

[[[00000000000000001725---dc0b2bb8fea5f7a5854e12c11bc00006985c8167e93d078e6c79cbf91bf294e1]]]　Chapter 7 Convolutional Neural Networks

[[[00000000000000001726---c43c8894ec9c0761f736c8aca6c519afa071c421c59444edd097185b7801e9bf]]]　　7.1 Overall structure

[[[00000000000000001727---3587867a4f3876281788f1a7da52a09fdfd85f08c11b921eddb255e507115592]]]　　7.2 Convolutional Layers

[[[00000000000000001728---a208fd06aca5bf74b70b03224c2aa5d7892d8b03cc5914090e239d27b3c5ba73]]]　　　7.2.1 Problems of Fully Connected Layers

[[[00000000000000001729---512e5c03eccd8008ad0cdba003206a557ce24cebc2dbbfabdc00b6e83bb927d9]]]　　　7.2.2 Convolution operation

[[[00000000000000001730---3624909d759641c60a29004b65cfedfb4045140aee783b7b285ebcad117916e9]]]　　　7.2.3 Padding

[[[00000000000000001731---99f47102806c68cf19bb59e15678231f5eaf06358b9f84f947bbfef1497eb0a3]]]　　　7.2.4 Stride

[[[00000000000000001732---d7bdef2cb4473bd6e31460dd7db60b6f1a16f3f1faeff6dc108f94efe5cf97d1]]]　　　7.2.5 Convolution operation of 3D data

[[[00000000000000001733---c643f651942f7f55d11f855100f196dffb4d662111f1b2ce4ef2f38b497a5749]]]　　　7.2.6 Thinking in Blocks

[[[00000000000000001734---bcd7cac4795ddc9d191f5b9c8826d237af5d005d063f8433e29c4c9f8d523914]]]　　　7.2.7 Batch processing

[[[00000000000000001735---9343e6d0c7c9ad2d795d81563adbd346a37cf82b62fb4a471ad1979951d23100]]]　　7.3 Pooling layer

[[[00000000000000001736---f2ea2fe7ce4caef7c884e9a23e153230a32d47733aeed17c766b328597771c37]]]　　　7.3.1 Characteristics of the pooling layer

[[[00000000000000001737---2f8bacf335692d77607f5d0d8ea5a0894d3a45e17bfc428110f3fbebd4dc896b]]]　　7.4 Implementation of Convolution/Pooling Layer

[[[00000000000000001738---4178222bafc0c188ee5905834341439ed834ff3ea86ff51c70020de1e436a4d9]]]　　　7.4.1 4D Arrays

[[[00000000000000001739---0a28baa8fcc32850ea23ee1a78906d8566abd1871f046c908708419e812fc91b]]]　　　7.4.2 Expansion with im2col

[[[00000000000000001740---4f8cd7fec4576827a878c69ff72fe028869dfcc08f2cd5aadc3afcc762cfbb43]]]　　　7.4.3 Implementing the Convolution Layer

[[[00000000000000001741---0ec98c0467aa155d600deac3075b0b55843b92996bd23c8fcf7b616a6fc1aee7]]]　　　7.4.4 Implementation of Pooling Layer

[[[00000000000000001742---d836fdf1447ef4e3e77fccb9e32e33c0f7f3979e41ae6734c9af2cd75f1d995c]]]　　7.5 Implementation of CNN

[[[00000000000000001743---16a8887d9b2c49114c406dd318eb05a7aa2f1743ba682ed3d0ede6f468e4aabf]]]　　7.6 Visualization of CNN

[[[00000000000000001744---733077050d2a44d066b3dc216c7539e3c539571204154cb22ee7f7808cf4e17c]]]　　　7.6.1 Visualization of first layer weights

[[[00000000000000001745---ff3c1a8d282fb6d97b02138b38c93b3886f285ad30849e939a81c8c1c3d5a1e9]]]　　　7.6.2 Information extraction by hierarchical structure

[[[00000000000000001746---f7260b9193db851f5a29ca263b43db15db12b8b7a85b81eeabd4dae5ef109a06]]]　　7.7 Representative CNN

[[[00000000000000001747---e612212e868cd4a9e760b385f0eb71d94b41c2633cf886acf10d1fa202727ed0]]]　　7.8 Summary

[[[00000000000000001748---2dbef1113584d8504215b339697bd950c337b5153b8353af8ff9368772bd8228]]]　Chapter 8 Deep Learning

[[[00000000000000001749---1f558501397549f221257f833e249645b3f1cdb240684676f5b54d4fa44e8f2a]]]　　8.1 Deeper network

[[[00000000000000001750---20d89d20a6a7737980bba7cc14ead9d5a5c156ea3ac05a8b883fbcf6c712a0f9]]]　　　8.1.1 To a deeper network

[[[00000000000000001751---4b169bc01638dc661c1e4896f3a6d11b716ffd834fdbc97e8ecc125fd65e7c2f]]]　　　8.1.2 To further improve recognition accuracy

[[[00000000000000001752---4472327a62671b512151db36248b0c2a6d395899883b6fedfd0cedb5e6e5dd55]]]　　　8.1.3 Motivation for Deepening Layers

[[[00000000000000001753---e922479e38852f8a6cdfd21e5073e822809257d1e24211ee48a7783be2134853]]]　　8.2 A short history of deep learning

[[[00000000000000001754---3854674fdf59c29b498ab0def67515fe7ea85f50842cdd3c7396788654512c8b]]]　　8.3 Acceleration of deep learning

[[[00000000000000001755---f79f66c30f21768dbee587f38cab3ef9778e27230e585661b87091ba1089d097]]]　　　8.3.1 Problems to be addressed

[[[00000000000000001756---2fa19289652db049f385fbeef6d9c80b97f4372c0091b698891cdac65ee275f1]]]　　　8.3.2 Acceleration with GPU

[[[00000000000000001757---330b06ac85bc4d6a85aa8b4292d1f054dcbdc629e0abf532e60b633424872460]]]　　　8.3.3 Distributed Learning

[[[00000000000000001758---a4a6a62d5335fb464b2d83b0e06a27304d154df13f87d6dac02232be38d8782f]]]　　　8.3.4 Bit Reduction in Arithmetic Precision

[[[00000000000000001759---a6d616287060cd5a96764902afdeb6966012f5b0ed69c37d37786ce056313204]]]　　8.4 Practical examples of deep learning

[[[00000000000000001760---5afb56c8d10f6d033c13dde0fb390423a995ea17babff192612804727138c9ff]]]　　　8.4.1 Object detection

[[[00000000000000001761---326474cd4ea3a299421264e381adfc1369b31916e2bf024e22baea08040ba558]]]　　　8.4.2 Segmentation

[[[00000000000000001762---5c0a09d5b1d1576a666a8afe4316fe4b4013a1a6384669e1aacc0689f07b9e1f]]]　　　8.4.3 Image caption generation

[[[00000000000000001763---2471de2c5439e124dbab86741bc7df18e1fb4d4beb7371a90e6777fe3791317a]]]　　8.5 The future of deep learning

[[[00000000000000001764---5affb87e03d3b62a6b9c9452233d42f4f674b3b3c91c93826a217285e4e2d66d]]]　　　8.5.1 Image style conversion

[[[00000000000000001765---ac015dddcfbdc7779fdc7fd819c7a2abcc6c85c3b1aeb583e0be65b5a55879de]]]　　　8.5.2 Image generation

[[[00000000000000001766---cb64f7789daa05ac0f28a377113b316dcd15b64222034e408bc21525150c1dd2]]]　　　8.5.3 Automated driving

[[[00000000000000001767---706ab6bcf30513412349e6f1165eee0c4db6326950ae5430d73849238da91837]]]　　　8.5.4 Deep Q-Network (reinforcement learning)

[[[00000000000000001768---163b44d324a4f96a7d26f3a401651d9ee1bf47459e2be6ff9e72d7b7db71de66]]]　　8.6 Summary

[[[00000000000000001769---dc8bb876d27f45229dbbe52431ccee267001c56d729ac653d491c02a73995724]]]　Appendix A Computation graph of Softmax-with-Loss layer

[[[00000000000000001770---a1d311c73f26ead82e47dcae3ed1ef2c86c843d445d729f7cc397d37311b4b9f]]]　　A.1 Forward Propagation

[[[00000000000000001771---124fb8ff25f84e28444a4d1fc73f4e11d1a4cb2cd7b40bad236159a7959f2a81]]]　　A.2 Backpropagation

[[[00000000000000001772---f8b983cb70d98b65b764061746464bcc5b884f4c6eeb93bfa40928555da8566d]]]　　A.3 Summary

[[[00000000000000001773---7d1b2ce73e1cc85cd8553303b8d164b9926a375fcfcc2b2f9c962f6f08260cd6]]]　References

[[[00000000000000001774---4805a7bbe583f23aebdce5018eef624abfd7c03cdf9dfc2721c2b0d77f1b9aac]]]　　　Calculation graph (backpropagation method)

[[[00000000000000001775---48617ae39898901831752a62908396fee36c6a2add09962a8e221dbd46f56cbc]]]　　　Deep Learning Online Class (Document)

[[[00000000000000001776---0bfdc7221f6ac50672f21d1b09452a398d865588f33f769ec8e19f81ed4e44b3]]]　　　How to update parameters

[[[00000000000000001777---9fc94e96b9ae9d269e7cdcb2a23a55f06dd83af699860789fd1cedc824db97e8]]]　　　Initial value of weight parameter

[[[00000000000000001778---6e010b0724133f6242f41808ced0bdf7541a77d543a5a6a35d07ab0426fb00b2]]]　　　Hyperparameter optimization

[[[00000000000000001779---876593ba3efadf75c7c7b53b3d37175c7d38488e23cdc52be6ad358b4d41a6d0]]]　　　CNN visualization

[[[00000000000000001780---90bf241641d18cbf474cfe0972519fb5791cc515b1648ccd56cdef6d90e131ec]]]　　　Typical network

[[[00000000000000001781---463eef310000460ae1969134ac9184f2794000ee442c7772373145e5ad0227cc]]]　　　data set

[[[00000000000000001782---2680279b59711c941e352e8162d76d75793179e8dee7c8617a663bd65d28ca9e]]]　　　Calculation speedup

[[[00000000000000001783---3498b908853981faa5cd07bf86fca949345beef8117395e82d496b5405ba96f4]]]　　　Accuracy Ranking and Best Accuracy Methods for the MNIST Dataset

[[[00000000000000001784---0039e94daaa7aebbe37fd6ed2f7c23c947e7214bec5d7e22a640d424b5edf0a1]]]　　　Applications of deep learning

[[[00000000000000001785---78c748b750c5565a6695bfce45017c02cb814212b08090570bb3e600dcbfc48f]]]　About the author

[[[00000000000000001786---cbd795697fe2923c1bfa79339686212ecf39db44832ae3daabbbe8854954d406]]]　colophon

[[[00000000000000001787---f1346ad5781c9c4ee349e1ac33c0d22499e89abbeffaf60a56caff66fe5e8c77]]]Foreword

[[[00000000000000001788---b6d1a3fc4631b0cba5ef512f214c214431e320fa927e316cae63bacf6fd321af]]]The sci-fi world has become a reality—artificial intelligence has beaten Shogi and chess champions, and recently even Go champions. Smartphones can understand human speech, and real-time “machine translation” is possible in video calls. 'Collision-free cars' equipped with cameras are protecting human lives, and self-driving cars are showing signs of being put to practical use. If we look around us like this, we can see that artificial intelligence is capable of performing tasks that were once thought to be possible only by humans, and is even trying to surpass humans. Our world seems to be changing to a new world with the development of artificial intelligence.

[[[00000000000000001789---8360180b8919da7ce6cb4b5bd682237015960eb1fc6e8336721cc2963870da63]]]A technology called 'deep learning' plays an important role behind the scenes of such a rapidly developing world. Researchers around the world have praised deep learning as a revolutionary technology, with some laudging it as a once-in-a-decade breakthrough. In fact, this new term deep learning is attracting attention not only to researchers and engineers, but also to the point that it is introduced in news and magazines as a term well known to the general public.

[[[00000000000000001790---1605fe1b103dc74b9548ecd8613a51965bb1b4fa541ce4c3586b5a2c66f59d25]]]This book is based on the theme of 'deep learning,' which is attracting a lot of attention. The purpose is to have people understand deep learning technology as deeply as possible. For that reason, the concept of this book is to “make from scratch”.

[[[00000000000000001791---d7e7b8eedcfb2ffad5f62a878e5fed97224832606be698533a8444a6e4cd9b2a]]]The feature of this book is that it tries to approach the essence of deep learning through the process of 'making'. Through the process of implementing a deep learning program, we will explain the necessary technology without omitting (as much as possible). In addition, by providing a program that actually works, we have taken into consideration that various experiments can be performed at hand by the reader.

[[[00000000000000001792---a102a917d453b98b14dfcfa769b971c7ebff60b1a862d115a0fb8289f8ad7a93]]]Creating deep learning involves a lot of trials, and I think it will take a considerable amount of time, but there should also be a lot of learning and discoveries. And the work of making is fun and exciting without any extra value. Through the work of 'creating' in this book, I hope that you will become familiar with the technology used in deep learning, and (if possible) enjoy it.

[[[00000000000000001793---0a9d4cd289b12cfa07bfed67edd1f031390a46cdea35dfc0efe182f72b58a877]]]Well, deep learning is already working everywhere in the world. Deep learning is working even in smartphones that everyone has. Deep learning is at work in the cars that drive themselves and in the servers that power web services. Deep learning continues to dance quietly today, where many people don't realize it. And from now on, deep learning dance will become even more vivid. I would like to start this book with the hope that this book will help you to understand the technology related to deep learning and be fascinated by the dance of deep learning.

[[[00000000000000001794---d2004be5323098a9f156f4ac1af1be45f6918e3fbfbdcefc3736282f1379c237]]]Concept of this book

[[[00000000000000001795---72ad697e48ad60f45c022a1eb131854f9f565614b2bf16b83d16c92fabd9f94b]]]This book is about 'deep learning'. We will explain the knowledge necessary to understand deep learning, starting from the basics and accumulating one by one. I will explain in as simple terms as possible what deep learning is, what features it has, and what principles it operates on. However, the purpose is not just to explain the outline of the technology, but to take it a step further and provide a deeper understanding. That is one of the features of this book.

[[[00000000000000001796---b6a2616d61a44f8e0237b3ad085febec19e0e2bc716aa46cdc0dd3538142c00f]]]So, what should we do to understand “deeper” about deep learning? The best way to do that, in my opinion, is to actually build one. Creating a working program from scratch and thinking about it while reading the source code—I believe that such work is important in correctly understanding deep learning (or, for that matter, some technology that appears to be advanced). No doubt. Here, I used the word 'from scratch', which means that I do not rely on external off-the-shelf products (libraries, tools, etc.) as much as possible. In other words, the goal of this book is to create state-of-the-art deep learning by starting with the minimum knowledge that you can understand, without using black boxes whose contents you do not understand as much as possible. And through the process of making it, I would like you to have a deeper understanding of deep learning.

[[[00000000000000001797---36835d6b02eafbf442161b0429618945bf86ad2a4a340f8acc9463981f5eaee4]]]If you compare this book to a car book, this book is not a car instruction book. The focus is not on how to drive a car, but on how the car works. To help them understand how a car works, open the hood of the car, pick up each part, examine it, and move it around. Then, we extract the essence of the car in the simplest possible way and build it up like a plastic model. The goal of this book is to make you familiar with car technology through the process of making a car, with the feeling that you can actually make a car.

[[[00000000000000001798---6f6ef5be697cbfa76eaa26f27db26eaea19b66c5e06c7f00d2dea4e56d0bf224]]]This book uses a programming language called Python to create deep learning. Python is a very popular and easy programming language for beginners. It is especially suitable for making prototypes, so you can immediately try out your ideas and conduct various experiments while viewing the results. In this book, while explaining the theoretical aspects of deep learning, we will implement programs in Python and conduct various experiments.

[[[00000000000000001799---37ee79d779dce4bf0d2075372aad3b129e09e3f8e78eac6cac52b8faf3e26ef1]]]Reading the source code and running it often makes my understanding clearer when I can't understand it with just a formula or a theoretical explanation. Many people must have experienced the process of reading the source code to understand the flow of technology when they were unsure of formulas. This book is a book that emphasizes 'engineering' to try to understand deep learning through actually making it - putting it into code. There are a lot of formulas, but just as much source code from a programmer's point of view.

[[[00000000000000001800---693d169124007b34f875ccf1d20bda013accd1e1eef6f640e03cd447e97312ec]]]Who is this book for?

[[[00000000000000001801---7ac03d197cbca4f915a81ede8f00e5cc36c020da0bd5fec5b7c8e2069a8a0e46]]]In this book, we will give you a deep understanding of deep learning through hands-on implementation. Here's what the book does, to make it clearer who the book is for:

[[[00000000000000001802---113359002adaa982f8d6f9ecc2da35b81dadaf1c0ac83016123a1201355c218f]]]Using only a minimum of external libraries, we will implement a deep learning program from scratch using Python.

[[[00000000000000001803---546ddc8d703cb64411f583cb8cbafbb0f635113d4c71f4b685bb94e16f3dc8f2]]]I will explain how to use Python so that even those who are new to Python can understand it.

[[[00000000000000001804---b206e7fbbf338752d7537fa19965baaaf550cc15d94c4e663dbcb5981c33f06e]]]Along with working Python source code, it provides a learning environment where readers can experiment.

[[[00000000000000001805---5ca4cceebabc299eb4f719e00c19ebf786f3c86ff88d9652153a3ff4480807a6]]]Start with a simple machine learning problem and eventually implement a system that recognizes images with high accuracy.

[[[00000000000000001806---88a034023e0be867ee8156c0dff33b2c70a17f20b85e0062ea9c5cea76924f93]]]We will explain the theory of deep learning and neural networks in an easy-to-understand manner.

[[[00000000000000001807---81f61835076ee3d4ee9701964153685de867f4e15d9770c0bb3d2a8f03a82a83]]]We will explain techniques that seem complicated at first glance, such as backpropagation and convolution operations, so that you can understand them at the implementation level.

[[[00000000000000001808---96e48a52e47079ec194ed6a989c4e1f0c2a76ab3dc5d8a05155eb205c0008059]]]We will introduce practical techniques that are useful for deep learning, such as how to determine learning coefficients and initial values for weights.

[[[00000000000000001809---0304b9e3f6308be507e30b097f67abb031768c53f68bae13641ba20e91a74a5a]]]We will also discuss and implement recent trends such as Batch Normalization, Dropout and Adam.

[[[00000000000000001810---0dc5eec955ab69a750d70e55c019d121944579f753c455cbd3d578f1d7334c17]]]We will also discuss “why” issues such as why deep learning is superior, why deeper layers increase recognition accuracy, and why hidden layers are important.

[[[00000000000000001811---fe81a4f0e89a5f5c2d7557ff6c7bfc5eb036192097fc3e2ce1cc23f90de6523c]]]We will also introduce deep learning application examples such as autonomous driving, image generation, and reinforcement learning.

[[[00000000000000001812---e1f5b5c62ec25fcf106d39a562d1c67d712622b6eac579e2c85e394e0e158cdc]]]Who is this book for?

[[[00000000000000001813---8c21b9a5c7da1d73acdfc422e1cc17012ae0659e16a388597a7ff77fc21a4be2]]]It is also important to be clear about who the book is for. Here's a list of what this book doesn't do:

[[[00000000000000001814---aaea5c825ca990eaedd98d2a00962c8e97e7098b9aa5d8985cd36c991772dd89]]]We do not provide detailed explanations or introductions to the latest research on deep learning.

[[[00000000000000001815---a62cc943728389b144528692467e47767c6639bdbccc387765e0604dd64c0f79]]]I will not explain how to use deep learning frameworks such as Caffe, TensorFlow, and Chainer.

[[[00000000000000001816---2b20687b0c7141c6861107447ce04965743a38804c4c7702b37e84073503205b]]]I will not give a detailed theoretical explanation of deep learning, especially neural networks.

[[[00000000000000001817---0169e8c6c2b27b000c788f26efb041c21bb7e4e4c3afa9dc9f08f46a06486556]]]I won't go into detail about tuning to improve recognition accuracy with deep learning.

[[[00000000000000001818---b9df3c949008c55c3444ab6a52c2612a607ec4d1185ccb027e86f01adb0ca938]]]We do not implement GPUs to speed up deep learning.

[[[00000000000000001819---3519e8a28e8e388e5ae95666e034f15d80f18035e3e1d940b118611d3b7f9038]]]This book mainly deals with image recognition. It does not cover examples such as natural language processing or speech recognition.

[[[00000000000000001820---853dedcd636efed0327eda46526e056b1482b428cbb859fd609c59927e122755]]]As such, this book does not cover recent research or theoretical details. But by the time you've finished reading this book, your next step will be the latest papers and theoretical technical books on neural networks.

[[[00000000000000001821---8665111aa4a6a98df018f81d43a56f948d9e817dcc293d865d04307eddf224ce]]]This book focuses on image recognition. Mainly, you will learn the techniques necessary for image recognition using deep learning. Things like natural language processing and speech recognition are outside the scope of this book.

[[[00000000000000001822---25022560c0fa88cd76c107064722c1fda8e4d663d966aac076bce448bf69e242]]]How to read this manual

[[[00000000000000001823---98d88a3a526bc9646a98378cc3db0f3d532ae5267b8ccdee2f5710a8baaa93bd]]]When learning new knowledge, it's easy to forget the explanation just by listening to it. “Forget what you have heard, remember what you have seen, and understand what you have done†1”. In this book, after explaining a certain theme, we frequently prepare a place where you can put it into practice—source code that can be executed as a program.

[[[00000000000000001824---094f0b663f1929f2d9e141326d8cf00f44ad05064e0d95118465408a62f14c02]]]This book provides the Python source code. You can actually run the source code at your fingertips. By thinking for yourself while reading the source code, and implementing and trying new things that come to your mind, you can confirm your understanding up to that point. You can also use the source code of this book as a place of trial and error through various experiments.

[[[00000000000000001825---35c8e53bd5659a7084d038d75f6e39e42c06f35a00210da88a3ac9b40276d295]]]This book will proceed with 'theoretical explanation' and 'implementation by Python' as two wheels. Therefore, it is recommended to prepare an environment that allows programming. The computer used in this book can be Windows, Mac, or Linux. How to install and use Python is explained in Chapter 1, Introduction to Python. Also, the program used in this book can be downloaded from the following GitHub repository.

[[[00000000000000001826---77e27cfa6a10c3585033f3acc1ae18de1f2977311940074ff5b524df637746f0]]][†1] Xunzi's words.

[[[00000000000000001827---663b207608253feef0e4cbf39b643bc28d78dcb75a1d32658e524a569342aa9e]]]Let's get started!

[[[00000000000000001828---d072041ea4e7233ef558e76089a7acb6fd2c4a10a853e4b0c9fcff358428c662]]]That's the end of the introduction. I hope that the explanations so far have given you an idea of what this book will do, and that you'll think, 'Okay, let's read a little further.'

[[[00000000000000001829---1d1c527e6f3aef9077eeed8bf2797464448c0e1910f1d31813e25d4511346d7f]]]By the way, recently, many libraries related to deep learning have been released, and everyone can use them easily. In fact, it is not difficult to run deep learning programs using such libraries. So why take the time to build deep learning from scratch? One of the reasons is that there are many things to learn in the process of making things.

[[[00000000000000001830---fc5da9001f57c75de9ea40d23f9be93f90fe66f9de4b9f60622ab106a65c27bd]]]In the process of making things, various experiments are done. Sometimes I hold my head and stop and think, 'Why is it like that?' Such time-consuming work becomes valuable knowledge for deep understanding of the technology. The knowledge you've acquired over time will definitely come in handy whether you're using existing libraries, reading cutting-edge papers, or creating your own original system. And, best of all, it's simply fun to create (and why else?).

[[[00000000000000001831---31b53fe753bb9531f64d6a26e7e0276bbca21883f5ee2cf69744022b46ba1c5f]]]Ready to go. Let's embark on a journey to create deep learning!

[[[00000000000000001832---32ab2a02a0d4b95b0a2ededc4dfdc60d2b0051008128f92fbc152e0e8facf0b8]]]Acknowledgments

[[[00000000000000001833---a197cd1d0de6184a9802feff6951265c010c1a1e83849c68db1b39a67471784c]]]First of all, I would like to thank the researchers and engineers who have pushed forward the research of technologies related to deep learning, such as machine learning and computer science. It is thanks to them that I was able to write this book. I would also like to thank those who have published useful information in books, websites, etc. In particular, I learned a lot from the open lecture 'CS231n' [5] at Stanford University about the spirit of generously providing useful technology and information.

[[[00000000000000001834---32236a8074e2315a50636f8bd44f8d5d4fb146933c8299a032e944b3a0dfb980]]]The following people have contributed to the writing of this book: Mr. Tetsuro Kato, Mr. Shinya Kita, Mr. Yuka Tobinaga, Mr. Kota Nakano, Mr. Masatatsu Nakamura, Mr. Teruhiro Hayashi, Mr. Ryo Yamamoto of teamLab Co., Ltd. Kenji Muto and Moe Masuko from Top Studio Co., Ltd. Kenji Nomura from Flickfit Inc. Mr. Hidetaka Tanno, JSPS Postdoctoral Fellow at the University of Texas at Austin. I would like to thank the people whose names I have mentioned here for reading the manuscript of this book and giving me a lot of advice. I would like to thank you for being here. Please note that any inadequacies or errors in this document are the sole responsibility of the author.

[[[00000000000000001835---886d00d196bb9e38f883377a0c8b935ea33f58db3db54283bbb3ca1274e77197]]]Finally, I would like to thank Mr. Naoki Miyagawa of O'Reilly Japan Co., Ltd. for his unwavering support over the roughly one and a half years from conception to completion of this book. thank you very much.

[[[00000000000000001836---8fac5522f17dc6f34e8dc2c04b6b145305f38d441f1f893f7ee38c1aa80780c1]]]September 1, 2016

[[[00000000000000001837---b035edd8672762cb270a81ac48bf45f2b02c7a631a1fe74d3a58fed6b8a8c4bd]]]Yasutake Saitoh

[[[00000000000000001838---476e512d3f22afdc336217483f037bcbe4fbaa5ef4a6c56f14f7f7cfcb4e5454]]]Notational rules

[[[00000000000000001839---30e569f8abc53f20a07c0598be9b8623658b8c37b5b37b40a9a69d7e6a6ba030]]]This document follows the typographical conventions described below.

[[[00000000000000001840---eaa3a1768a21aebf4c749f1933cd17b82875c8382de3e31f2e796a64729c15bd]]]bold

[[[00000000000000001841---7627be7c0fffeeba7455369bffe7e56c44fd561f79bcdca0ab4b03e003e61053]]]Represents new terms, emphasis and keyword phrases.

[[[00000000000000001842---0146b007473307a94b91a89c8c2f6849565f6e675e0fe665cf774251e7b94f75]]]Equal width

[[[00000000000000001843---7dbab4d12d7482897a8df2c32d5551ea07f137050f51d4382e74138b8cad3d67]]]Program code, commands, arrays, elements, statements, options, switches, variables, attributes, keys, functions, types, classes, namespaces, methods, modules, properties, parameters, values, objects, events, event handlers, XML tags , HTML tags, macros, file contents, and output from commands. It is also used when referring to that fragment (variables, functions, keywords, etc.) from within the text.

[[[00000000000000001844---576a3c3df75ae76aa331767cd3e6346541668bccbf1fb67114cd74b02d4fd08f]]]monospaced bold

[[[00000000000000001845---a18891419f3bfee392801649c081187ccca66c2216eec5454f689c91bcbaf135]]]Represents commands or text that you enter. It is also used for code highlighting.

[[[00000000000000001846---a8ad620408c5d0124855d9313f70c2d9497e8efa6f4436fd3d2936a6a0d84790]]]monospace italic

[[[00000000000000001847---ba938b96cb30883f2b1e89b6c5b63d61b577bafcb9315f3cc16497f1e304c89c]]]Represents a character string that must be replaced according to the user's environment, etc.

[[[00000000000000001848---52d33f0a012b4029eb0de3ecfd6655a60cc14548f486039f88d08f1ff193a592]]]Indicates a hint, suggestion, or additional information about something interesting.

[[[00000000000000001849---852388668b84435a5944b94c94f6e4912d1b0a0f468808655f1e125ec1cf75d3]]]Represents cautions or warnings, such as library bugs or common problems.

[[[00000000000000001850---3f4ba0664b5911aa7e85d2a0bed8e833b6c0f07636c0b05d7f28a3c2718ff197]]]opinions and questions

[[[00000000000000001851---25800ed37c8613ea755e1eaeb3f6b2a5c3614cd58d8f632f35faf9ae8cfe5017]]]We have made every effort to verify and confirm the contents of this document, but you may notice errors, inaccuracies, misleading or confusing expressions, and simple typographical errors. If so, please let us know so we can improve it in future editions. Suggestions for future revisions are also welcome. Contact information is as follows:

[[[00000000000000001852---5120b30e23f0646f3a418cbb6d18df0283e91b171be2b9c3a910b3aff3d0337e]]]O'Reilly Japan Co., Ltd.

[[[00000000000000001853---ec8d2613e28e64bb50245bc847105532b2de636be27692fcc83ae4d8ad1114b0]]]E-mail japan@oreilly.co.jp

[[[00000000000000001854---27022ad01a7c677d2c3b78e89be1b554229f1fdbcb01807b95d083bd5405e0bb]]]The web page for this document can be accessed at the following address:

[[[00000000000000001855---c7fc1eac054daea71feb57312103dfc70aa95e8c774c6e5e2cc1baa8f0273cc5]]]For additional information about O'Reilly, please visit the O'Reilly website at:

[[[00000000000000001856---1ca7db8b130185f960036f8742d18957992cee63848e22d9c9b2549ef754b844]]]http://www.oreilly.com/ (English)

[[[00000000000000001857---3a0824baa1752fb7403fd9483c25c1f2909dbae9da80b9699f1c258f4cc88ea5]]]● Author introduction

[[[00000000000000001858---d31b420fe643a16f31d75537faed0ea20e90bc39398603d746f318068220bfa7]]]Kouki Saito

[[[00000000000000001859---13bc85f7c6bd9e95d7f7700fc4ee72cb4d6893194d1caa9344b3bf182d6d7b9e]]]
Born 1984 in Tsushima, Nagasaki Prefecture. Graduated from the Faculty of Engineering, Tokyo Institute of Technology. Currently engaged in research and development related to computer vision and machine learning at a company. His translations include 'Practical Python 3', 'Computer System Theory and Implementation', and 'Practical Machine Learning Systems' (O'Reilly Japan).


[[[00000000000000001860---edc3efb149a25b9613ce36ac49d50fa08fbda9e7b7120a27b83d2c9a69b24a3f]]]References

[[[00000000000000001861---e529d17e46f019c644222a8bd7b79799d8d3f7c37eb5c0fd2b09cd6db3c63530]]][1] Bill Lubanovic: 'Introducing Python' O'Reilly Media, 2014

[[[00000000000000001862---559ae312bd3a366327bb09ef82079f895be335f611267d2b595b2f1d3b0f5a87]]][2] Wes McKinney: 'Python for Data Analysis' O'Reilly Media, 2012 Open capital, translated by Daisuke Nogami, published by O'Reilly Japan)

[[[00000000000000001863---362fb2bfe6a2ae5fb5dc518ad8f4e8f72ce6c3ab56b6732c255d0991239d909e]]]Calculation graph (backpropagation method)

[[[00000000000000001864---10541dea36a695ec68c85d09402d5462b262fa54be162029821baad7893c3739]]]Deep Learning Online Class (Document)

[[[00000000000000001865---2a5997b0b6f9ea25f674d2a0ef861ce1c1188bb70cca39f74294a53ec66db1f2]]]How to update parameters

[[[00000000000000001866---c15ac45f852f627e5a4b383088bdcb57c7d5f26bc1a91dd7944dc344f56a88aa]]]Initial value of weight parameter

[[[00000000000000001867---5ee4b1dac9a66cf9a5151a88f0ee96be698869f280bf19d62a27ed758168de39]]]Hyperparameter optimization

[[[00000000000000001868---c5cecf3e5d8134b817bdc77748065d553213e1e5dc3acc2ac6c6507e3a861d00]]]CNN visualization

[[[00000000000000001869---a11b7bb363416c4d6a0a4df0400081f2469a1a4d42424066e3ee4a6a16cf1ba9]]]Typical network

[[[00000000000000001870---0b60a0b5dc474cf01ded0b4409ef47e9158affa6f900136a791ddfd5a8651a7f]]]data set

[[[00000000000000001871---7273383eab249b6d24008b164342047de21da0489aeb36abc6c5dfe2d37bea91]]]Calculation speedup

[[[00000000000000001872---30a0c2f5a2ff58396b4e8e445dc168e01c8bee9765832c838897553984dd8a2d]]]Accuracy Ranking and Best Accuracy Methods for the MNIST Dataset

[[[00000000000000001873---693dbe28e842fb3bc9413635a0d317aed8a1ed96e8f177c144471baa82ca6e49]]]Applications of deep learning

[[[00000000000000001874---1c730b625c1e38795f23a2ad626ab6abb0cf204565b688e7387052eb57ca49c1]]]Chapter 8

[[[00000000000000001875---de2e114ac520846bce4190fb24a533cbcd9467c0839a0a63a214117f85b88170]]]deep learning

[[[00000000000000001876---b3cf6d0177c0f8630a953caedb54cc0333e25636fada6ae974827b9151b5eb46]]]Deep learning is a deep neural network with deep layers. Based on the network explained so far, you can create a deep network by simply stacking layers. However, deep networks also present challenges. In this chapter, we will look at the properties, challenges, and possibilities of deep learning. In addition, we will give a bird's-eye view of current deep learning.

[[[00000000000000001877---88fb8bab209c1f6096d702e743d183508b8791b318f488d896c404ffc1a41065]]]network deeper

[[[00000000000000001878---f1a83a394ab3c2304183d89ad9c9652d4986e1d1adb9e5989a13035c1477729f]]]You've learned a lot about neural networks so far. For example, various layers that make up a neural network, effective techniques for learning, CNN that is particularly effective for image systems, and parameter optimization methods. All of them are important technologies in deep learning. Here, I would like to consolidate the techniques I have learned so far, create a deep network, and challenge handwritten digit recognition on the MNIST dataset.

[[[00000000000000001879---e5277b2210d2314550a052864738c14ebf9d6444e76ed896252a92b23bf9cba5]]]To a deeper network

[[[00000000000000001880---23eb444b3cee72eec99f751912c12124e0aa0bdf57ab15b5d8804ee9ed24d4b1]]]As soon as possible, I would like to create a CNN consisting of the network configuration shown in Figure 8-1—a deeper network than before. This network is based on the VGG network described in the next section.

[[[00000000000000001881---24f34b25c7c61bb4e90b868f6f74167c4f480f8757a66dca89a3ae5a5affb129]]]
Figure 8-1 Deep CNN for handwritten digit recognition


[[[00000000000000001882---a401e4c88caa6837379052af6124f2204a2aeead7461654fa53337e3ce1a60d2]]]As shown in Figure 8-1, the layers are deeper than the networks we have implemented so far. The convolution layers used here are all small 3 × 3 filters, and the number of channels increases as the layers get deeper (the number of channels in the convolution layers is 16, 16, 32, 32 , 64, 64, and so on). Also, as shown in the figure, a pooling layer is inserted to gradually reduce the spatial size of the intermediate data. And the Dropout layer is used in the latter fully connected layer.

[[[00000000000000001883---e9bfb96bcc12cff854cae92c1faaae79ea36c7bbc5155f50babb391db9a788b0]]]The network uses the 'initial value of He' as the initial value of the weights, and uses Adam to update the weight parameters. In summary, this network has the following features:

[[[00000000000000001884---c88e8771e70ce3dc9c84603aa908e3a1a1f99c5054415a482c8b044235324e26]]]Convolutional layer with 3x3 small filters

[[[00000000000000001885---68ce06027e30609eaf07a76f68c7dc850f87f9c40e974836be8923851b9c0174]]]The activation function is ReLU

[[[00000000000000001886---d824141c2257716290a1ab8ab23a95e19e9d46ad777aecd9dc8c668dee2f02b7]]]Use Dropout layer after fully connected layer

[[[00000000000000001887---0210a8fbf18a410ad7f48a44002d5117b9c1560e63f3576b0ebcb11316bca561]]]Optimization by Adam

[[[00000000000000001888---1321edc61d3d4f3ecb8a8f9c23d039cdd6a5805c1ea983824f56fbfc5361e983]]]Use 'initial value of He' as initial value for weights

[[[00000000000000001889---bf82c6e3b65060cf0df4265f26ff155b83262e3743202982ec178b4de8365eb3]]]As you can see from these characteristics, the network in Figure 8-1 uses many of the neural network techniques that we have learned so far. Let's use this network for training. As a result, the recognition accuracy of this network is 99.38% †1. This can be said to be a very good performance!

[[[00000000000000001890---fd703c82a2773157f4615287a6a0864e81fb3808688216378d3d0fa301b9a21a]]][†1] Final recognition accuracy may vary slightly. However, in our network, the results will generally exceed 99%.

[[[00000000000000001891---3ed55bebeee45d8e380c36b9305c1e3768be253e7aded9d57b13e54798f4ae02]]]The source code implementing the network in Figure 8-1 can be found at ch08/deep_convnet.py. Also, the training code is available in ch08/train_deepnet.py. With those codes, we can reproduce the training we did here, but training a deep network takes a lot of time (probably more than half a day). In this book, the learned weight parameters are given as ch08/deep_convnet_params.pkl. The previous deep_convnet.py has a function to read learned parameters, so please use it as appropriate.

[[[00000000000000001892---61c5d7c7d147921bff8db0ce2c77bc5a7d22def75739715e4ea39e589d6d30d1]]]The false recognition rate for the network in Figure 8-1 is only 0.62%. Here, let's actually see what kind of image was misrecognised. Figure 8-2 shows an example of an actual misrecognition.

[[[00000000000000001893---dcd8ad0b4353739bd6f32a2a5f448fc2213c8574318bee58185e0359c6ebfee7]]]
Figure 8-2 Examples of incorrectly recognized images: The correct label is shown in the upper left of each image, and the inference result of this network is shown in the lower right.


[[[00000000000000001894---79a0b0c6c87bb5dd313d4a8244f9bc812060e8687d1da293abef4c004bf840e5]]]As you can see from Figure 8-2, these images are difficult for us humans to judge. In fact, we can see that there are many cases where it is difficult to judge what numbers are, and there are many images that we also make 'recognition errors'. For example, the top left image (the correct answer is 6) looks like a 0, and the image next to it (the correct answer is 3) does look like a 5. Overall, the combination of ``1'' and ``7'', ``0'' and ``6'', and ``3'' and ``5'' seems to be confusing, but looking at such examples, I can understand why I misunderstood. I think.

[[[00000000000000001895---f6ad7cbd75669d9d05c26b24ef0a06702fd6cd05b23abc4053ed55d1039b344f]]]The deep CNN this time is highly accurate, but it makes the same 'recognition errors' as humans do, even for images that are incorrectly recognized. From this point of view, you can feel the great potential of deep CNN.

[[[00000000000000001896---111c2bc9a594ff4a02f4cb8d4e4a310f51b16dcdde0da5a8372c2227d373d81f]]]To further improve recognition accuracy

[[[00000000000000001897---046d09670d95b8e7d8e006c93b7e599937d39ac4bba77adfcadde0593262b105]]]A website titled 'What is the class of this image?' [32] lists the recognition accuracy of methods that have been published in papers and other publications for various data sets in a ranking format. (Figure 8-3).

[[[00000000000000001898---b35e8b52fd99d260656fffcc0a629764e1466feb35b51d393132f8502f4b5fe8]]]
Figure 8-3 Ranking of each method for the MNIST dataset (quoted from Reference [32]: as of June 2016)


[[[00000000000000001899---7b579aef5743f220b08e6686a71016dbd8f642ade5e96e1e4ab4d29af8bd5444]]]Looking at the ranking results in Figure 8-3, the keywords 'Neural Networks', 'Deep' and 'Convolutional' stand out. In fact, many of the top ranking methods are CNN-based. Incidentally, the best recognition accuracy for the MNIST dataset as of June 2016 is 99.79% (0.21% false recognition rate), and the method is also based on CNN [33]. However, the CNN used there is not a very deep network (a network with two convolutional layers and two fully connected layers).

[[[00000000000000001900---ba136c011d2d4d81c783e9abc782fdcbb99444df22ddb3bfe0c85ef2dce106c3]]]For the MNIST dataset, we get the best results (for now) without going too deep into the layers. This is probably because the network does not need to be so expressive for the relatively simple problem of handwritten digits. Therefore, it can be said that the benefits of deepening the layers are small. In large-scale general object recognition, which will be introduced later, the problem becomes complicated, so we can see that increasing the depth of the layer greatly contributes to the improvement of recognition accuracy.

[[[00000000000000001901---8df4f0eb73b66402f0640eeac2d539bd460d0caf13322c08f17fb7e33662ba22]]]By referring to the top-ranked methods above, you will be able to discover techniques and hints for further improving recognition accuracy. For example, ensemble learning, learning rate decay, and data augmentation contribute to the improvement of recognition accuracy. In particular, data augmentation is a simple technique, but it is a particularly effective method for improving recognition accuracy.

[[[00000000000000001902---c400a56b775e2f848da782a7905416e9f5a4e65d4f72d32dc6702c774ca0058f]]]Data Augmentation “artificially” augments the input images (training images) with an algorithm. Specifically, as shown in Figure 8-4, the input image is rotated, moved vertically and horizontally, or otherwise slightly changed to increase the number of images. This is a particularly useful measure when the number of datasets is limited.

[[[00000000000000001903---70dbd4ebdce51eecee654100b4c3f4f593e8512619b7015ffd5b796f80216a1c]]]
Figure 8-4 Example of Data Augmentation


[[[00000000000000001904---7864ad65fa81a2b832116c743c7f4efbc7fc5bf1b6d5dd99fe61613c01c14501]]]Data Augmentation can augment images in many ways other than the transformation shown in Figure 8-4. For example, 'crop processing' that cuts out part of the image, 'flip processing†2' that flips left and right. Also, for general images, it is effective to change appearance such as brightness and change scale such as enlargement/reduction. In any case, if data augmentation can successfully increase the number of training images, the recognition accuracy of deep learning can be improved. This may seem like a simple 'trick', but it often yields good results. We won't implement Data Augmentation here, but this 'trick' is easy to implement, so if you're interested, give it a try.

[[[00000000000000001905---74cea15fad6d8a3d077034a45caf5b9283db03b4a55cc86bfe2bd3aa0ab7d162]]][†2] Flip processing is effective only when image symmetry does not need to be considered.

[[[00000000000000001906---e92019a9fd132bd023bb8762375836f6db17a78a8b26eae2b8b1607792dd298b]]]Motivation for deepening layers

[[[00000000000000001907---ffe63f7255d7d8e34181308d1536d093b4860fff82c2986acad0f5dec826e365]]]Theoretically, not much is known about the importance of 'deepening the layers'. Although the theoretical side is currently sparse, there are several (albeit somewhat intuitive) explanations from previous research and experiments. Here, I would like to give some data and explanations to support the importance of 'deepening the layers'.

[[[00000000000000001908---f34ba211caa76b7742c8ff9b0e129395d2d7ec015690ea55735a901d59d48c3f]]]First of all, the importance of deepening the layers can be understood from the results of large-scale image recognition competitions represented by ILSVRC (see the next section for details). The results of such competitions show that many of the recent top methods are deep learning methods, and the trend is toward deeper layers of networks. In other words, it can be read that the recognition performance has improved in proportion to increasing the depth of the layer.

[[[00000000000000001909---5332f97f7471f52629a338d02d49f1754c19b5879faed6e1acd65ccc04134e3a]]]Next, I will discuss the benefits of deepening the layers. One advantage of using deeper layers is that the number of parameters in the network can be reduced. More precisely, a network with deep layers can achieve the same level of expressiveness (or more) with fewer parameters than a network without deep layers. This can be easily understood by focusing on the filter size in the convolution operation. For example, Figure 8-5 shows a convolutional layer consisting of 5x5 filters.

[[[00000000000000001910---203fa39041c2708a20651ca303537cfcb2eba0b209fc43ad9cde2c786f09c183]]]
Figure 8-5 Example of a 5x5 convolution operation


[[[00000000000000001911---9b2b4bdf5ed6394446fc8c606dc8923b87046c648c02cccb8e3909a79603d33f]]]The point I want you to pay attention to here is from which region of the input data each node of the output data is calculated. It goes without saying that in the example in Figure 8-5, each output node is calculated from a 5x5 area of input data. Next, let us consider the case of repeating the 3 × 3 convolution operation twice, as shown in Figure 8-6. In this case, each output node is calculated from a 3x3 area in the intermediate data. Then, which area of the previous input data is the 3×3 area of the intermediate data calculated from? If you look closely at Figure 8-6, you can see that it corresponds to a 5x5 area. In other words, the output data in Figure 8-6 is calculated by 'looking' at the 5x5 area of the input data.

[[[00000000000000001912---35a41b568e7765203d4de87b0a03ac16f0c214b2699ff5ebd0c905059e1b13f0]]]
Figure 8-6 Example of repeating a 3×3 convolutional layer twice


[[[00000000000000001913---83892760da66f1ed88ba6bd760168a28492764c22ac7b0e0304387a3987c2479]]]The area of one 5×5 convolution operation can be covered by two 3×3 convolution operations. Moreover, while the former has 25 (5×5) parameters, the latter has a total of 18 (2×3×3) parameters. And the difference in the number of parameters increases as the layer becomes deeper. For example, if you repeat a 3×3 convolution operation three times, the total number of parameters will be 27, but a 7×7 filter is required to “see” the same region in one convolution operation. , and the number of parameters at that time is 49.

[[[00000000000000001914---791e74f696318731fc863a94fa1af8950dedab7b4f6f3d35ce02faed4ba184f9]]]The advantage of deepening the network by stacking small filters is that the number of parameters can be reduced and the receptive field can be widely covered (the receptive field is the local spatial region that causes changes in neurons). ). Furthermore, by layering, activation functions such as ReLU are sandwiched between convolutional layers, further improving the expressive power of the network. This is because the activation function imposes a 'nonlinear' force on the network, and the superposition of the nonlinear functions allows for more complex representations.

[[[00000000000000001915---cdbb13fe5866dba0153d037d9fe1099e2624dfaf356c701ca68026a584a02dd0]]]Learning efficiency is also one of the advantages of deep layers. This means that deepening the layers reduces the amount of training data and enables faster learning than when the layers are not deepened. To (intuitively) understand this, it is helpful to recall what was discussed in 7.6 Visualizing CNNs. Section 7.6 explained that the convolutional layers of CNN extract information hierarchically. Specifically, in the previous convolutional layer, neurons respond to simple shapes such as edges, and as the layers get deeper, they become hierarchically complex, such as textures and parts of objects. Did.

[[[00000000000000001916---ae9552ca3345bbad97a4d92e56b3729a084a6af0edeefd872bd8889c3ee100f0]]]With the hierarchical structure of such a network in mind, let us consider the problem of recognizing a 'dog'. To solve this problem with a shallow network, the convolutional layer would need to 'understand' many of the 'dog' features at once. There are various types of 'dogs', and how they look will change greatly depending on the environment in which they are shot. Therefore, in order to understand the characteristics of 'dogs', training data with many variations is required, and as a result, a lot of time is required for learning.

[[[00000000000000001917---8f4ce5e6e98d76769e41c0b9959386f1b451b8779a69c5f5810cc65a0cb32b63]]]However, deepening the network allows us to hierarchically decompose the problem to be learned. So the problem that each layer has to learn can be approached as a simpler problem. This means, for example, that the first layer only needs to focus on learning edges, and it can learn efficiently with less training data. This is because there are many images with edges compared to images with 'dogs', and the edge pattern has a simpler structure than the 'dog' pattern.

[[[00000000000000001918---d4b8bd030350683777ba1c238b0d53c1b38a5e3b7b81de2f9eb4f81b1067db78]]]It is also important to be able to pass information hierarchically by making the layers deeper. For example, the layer that follows the edge extraction layer can use edge information, so it can be expected to learn more advanced patterns efficiently. In other words, by making the layers deeper, it is possible to decompose the problems that each layer should learn into 'simple problems that are easy to solve', and it is expected that learning will be efficient.

[[[00000000000000001919---a1fd099374bb7644a968424ecb1a604f45c7a8c36cab8c459fc5695daba070fd]]]The above is an explanation that reinforces the importance of deepening the layers. However, it should be noted here that the deepening of layers in recent years has been brought about by new technologies and environments—such as big data and computer power—that enable correct learning even with deeper layers. Let me emphasize.

[[[00000000000000001920---78d3fb1e50d7b7f70e8bf509bdb449241fda01c9c4a57a2e53276ed98f4b1274]]]A short history of deep learning

[[[00000000000000001921---bac66201f1dd6e5271e08562e17ad2fe1354f3f159fbab6028e07ae091b26126]]]It is said that the large-scale image recognition competition ILSVRC (ImageNet Large Scale Visual Recognition Challenge) held in 2012 was the catalyst for deep learning to attract the attention it has today. In that year's competition, a deep learning method—commonly known as AlexNet—won an overwhelming victory, completely changing the way we approached image recognition. Indeed, deep learning counterattacked in 2012, which was a turning point, and since then, deep learning has always taken the lead in the competition. Here, I would like to take a look at the recent trends in deep learning, centering on the large-scale image recognition competition called ILSVRC.

[[[00000000000000001922---859121158068284714fc32fb543682e66d6b63922a9de3c9af8d388ae71355a1]]]ImageNet [25] is a dataset of over 1 million images. As shown in Figure 8-7, it contains different types of images, each with an associated label (class name). Using this huge dataset, an image recognition competition called ILSVRC is held every year.

[[[00000000000000001923---5c32fc6726a03a4631ccb7cb4b42728eca40d355f67639d624701179e8401abd]]]
Figure 8-7 Example of large-scale dataset ImageNet data (quoted from Reference [25])


[[[00000000000000001924---b4fa20c8a727bc55549073cf5e7f602a09775a02423060e7219ba3a6f3597917]]]There are several test items in the ILSVRC competition, one of which is 'classification' (in the 'classification' division, 1,000 classes are classified and compete for recognition accuracy). . Let's take a look at the recent ILSVRC classification results. Figure 8-8 shows the results of the winning teams from 2010 to recent years for the ILSVRC classification. Here, if the correct answer is included in the top 5 classes, it is considered 'correct', and the misrecognition rate at that time is represented by a bar graph.

[[[00000000000000001925---849193218cbad6f72f74ecc628e882f1e049054125b5692cecd8914827db70d3]]]
Figure 8-8 Changes in results of excellent teams in ILSVRC: vertical axis is misrecognition rate, horizontal axis is each year. The team name or method name is shown in parentheses on the horizontal axis.


[[[00000000000000001926---1e202d3c1d049eaff98a74bfa5bfdb1897347a25121c8398657cb49a61d34911]]]What is noteworthy about the graph in Figure 8-8 is that since 2012, deep learning methods have always been at the top. In fact, we can see that AlexNet in 2012 significantly reduced the false recognition rate. Since then, deep learning methods have steadily improved their accuracy. In particular, ResNet in 2015—a deep network with more than 150 layers—has reduced the recognition error rate to 3.5%. By the way, it is said that this result even exceeded the recognition ability of general humans.

[[[00000000000000001927---599a54422ae607fbd15a5a3ebf0103ab23ebf58e44407ed4739edfa3215ef716]]]Deep learning has achieved excellent results over the past few years, and VGG, GoogLeNet, and ResNet are among the most famous networks. You will come across these networks in various places related to deep learning. Here's a quick introduction to these three well-known networks.

[[[00000000000000001928---3d15af971899882024caecc34c7310f0dabc12f5d344bd815c934d2ab64add93]]]VGG is a “basic” CNN consisting of convolutional and pooling layers. However, as shown in Figure 8-9, it is characterized by a total of 16 layers (or 19 layers) with weights (convolutional layers and fully connected layers) to make it deep (depending on the depth of the layer). may be called 'VGG16' or 'VGG19', depending on the type).

[[[00000000000000001929---a46cef8a62761398fe5367baf7bc33a5b580f03310bb12fd557261649708f5e5]]]
Figure 8-9 VGG (created with reference to Reference [22])


[[[00000000000000001930---a46a7a82f8053bfb8d7565bfd68dcc9f0e8babf3abf76732fa154d1f015dddb1]]]A notable point in VGG is that it continuously performs convolution layers with 3×3 small filters. As shown in the figure, we repeat the process of 2 to 4 consecutive convolution layers and halving the size with pooling layers. And finally, output the result through a fully connected layer.

[[[00000000000000001931---2e1707ba21682eac4e01c6fe59517a5ca68b9037153cdfdb4ba108f819bb9db5]]]VGG finished second in the 2014 competition (Next GoogLeNet was the 2014 winner). In terms of performance, it did not match GoogLeNet, which ranked first, but VGG has a very simple configuration and is highly applicable, so many engineers prefer to use VGG-based networks.

[[[00000000000000001932---be54e850bd73ef7ed3e2d162abbaa4de19695faa255e62a8bc3bd4ba93e72a9c]]]Figure 8-10 shows the network configuration of GoogLeNet. The rectangles in the figure represent layers such as convolution layers and pooling layers.

[[[00000000000000001933---dc52e79adc9892c53b1b1b46fd4ff9553addd359387e7cfb032dd91730128c42]]]
Figure 8-10 GoogLeNet (cited from Reference [23])


[[[00000000000000001934---74e911970e9613e8f5df2ac3dc0d113d19f50c45e925584d9712a3d833d846d4]]]As far as the diagram is concerned, the network configuration looks very complicated, but it is basically the same configuration as the CNN we have seen so far. However, GoogLeNet is characterized by the fact that the network has depth (spread) not only in the vertical direction but also in the horizontal direction.

[[[00000000000000001935---405b7f6eebbc45751c7b1643fd04b72e4a86181e24fcc5ee904fd42f3b50ff69]]]GoogLeNet has a 'width' in the horizontal direction. This is called the 'inception structure' and is based on the structure shown in Figure 8-11.

[[[00000000000000001936---b49e4f292e5d227184093d1db31e3588503a7b4218e2ca9aa1099ec18f113514]]]
Figure 8-11 Inception structure of GoogLeNet (cited from Reference [23])


[[[00000000000000001937---62b4064676a62c4f2606dfa208d1abc0a0a7ec6f4362278cf7df8ffa8d877fa2]]]The Inception structure applies multiple filters (and pooling) of different sizes and combines the results, as shown in Figure 8-11. The feature of GoogLeNet is to use this inception structure as one building block (component). Also, GoogLeNet uses convolutional layers with filters of size 1×1 in many places. This 1 × 1 convolution operation can contribute to parameter reduction and processing speedup by reducing the size in the channel direction (see the original paper [23] for details).

[[[00000000000000001938---5fe4601cd67af55ce9d3762fab5c2cb721d8eb5939fdcdd76a2e21419c59d6e3]]]ResNet [24] is a network developed by a team at Microsoft. The feature is in the 'gimmick' that allows you to create deeper layers than ever before.

[[[00000000000000001939---56bcfdf43087ef1097c2aa33916d3ccc96a286adf5856b6d1c53b7cfd37ef046]]]We've known for some time that deeper layers are important for improving performance. However, in deep learning, if the layers are too deep, the learning will not go well and the final performance will often be poor. ResNet introduces a 'skip structure' (also called 'shortcut' or 'bypass') to solve such problems. By introducing this skip structure, it became possible to improve the performance in proportion to increasing the depth of the layer (of course, there is a limit to the depth of the layer).

[[[00000000000000001940---91f65b8bc4f5eff4704cbb06389b404e06d132f83d6757b2da54ee8794e15200]]]A skip structure is a structure in which input data is passed across convolutional layers—skipped—and added to the output, as shown in Figure 8-12.

[[[00000000000000001941---a292e7644360a5800573ade7fa8e94e79cc406261fb6e474ff25992e4d4d00d4]]]
Figure 8-12 Components of ResNet (quoted from Reference [24]): Here “weight layer” refers to the convolutional layer


[[[00000000000000001942---8427b39ede9235783346bc5d264b27005795befc1c402c61a3236b2c13e9f192]]]In Figure 8-12, in two consecutive convolutional layers, the input x is skipped to the output two layers ahead. The point is that instead of the output of two convolutional layers, the skip structure is used. By incorporating such a skip structure, it is possible to learn efficiently even if the layers are deep. This is because during backpropagation, the signal propagates without attenuation due to the skip structure.

[[[00000000000000001943---865877e57e3737112ea5237bfd4f8e19d571cc183bf59c0520e207c18b3e0e91]]]Since the skip structure only flows the input data “as is”, even during backpropagation, the gradient from the upstream flows “as is” downstream. The point here is to let it flow “as is” without any modification to the gradient from the upstream. Therefore, we can expect that 'meaningful gradients' will be transmitted to the previous layer without worrying about the gradient becoming too small (or too large) due to the skip structure. It is expected that this skip structure will alleviate the vanishing gradient problem in which the gradient becomes smaller as the layer becomes deeper.

[[[00000000000000001944---121784086b4b500b7aad78843d592bdef225bcfe2a94d4582eb7cc29c27a5d6f]]]Based on the VGG network described above, ResNet incorporates a skip structure and deepens the layers. The result should look like Figure 8-13.

[[[00000000000000001945---f167a0a1cc61188863ebef6012ce537b6aeb191cf826ef78461abec0071c6001]]]
Figure 8-13 ResNet (quoted from Reference [24]): Blocks correspond to 3 × 3 convolutional layers. Features skip structure across layers


[[[00000000000000001946---81cd34bf67803ff0649c501fd21e1540efb697621b32e52e46687cc10689b3e0]]]As shown in Figure 8-13, ResNet skips every second convolutional layer and joins them to create deeper layers. Experiments have shown that the recognition accuracy continues to improve even when the depth is increased to 150 layers or more. In the ILSVRC competition, we achieved an astonishing 3.5% misrecognition rate (the misrecognition rate when the correct answer is included in the top 5 classes).

[[[00000000000000001947---40ca1475762ea0ac6173deb22a33199845bce3f17067ede58e76cbd602d1994e]]]In practice, it is often practiced to make effective use of weight data learned using a huge dataset of ImageNet. This is called transfer learning, where (part of) the learned weights are copied to another neural network and retrained. For example, prepare a network with the same configuration as VGG, set the learned weights as initial values, and perform re-training (fine tuning) on a new data set. Transfer learning is a particularly effective technique when you have a small dataset at hand.

[[[00000000000000001948---26de6a29331f2b72e3a868734dff7da1f1b6d6823a63ac27c8bf8518f8c035d6]]]Acceleration of deep learning

[[[00000000000000001949---dc1d193411e558bfb47e5c760cc31b344dae9a2f7927c51f4d6f88c121ffcc53]]]Deep learning requires a large amount of computation due to big data and the increasing scale of networks. Up until now, we have used CPUs to perform calculations, but the reality is that it is unsatisfactory to tackle deep learning with CPUs alone. In fact, if you look around, many deep learning frameworks support GPUs (Graphics Processing Units), which are capable of processing large amounts of calculations at high speed. Recent frameworks have also begun to support distributed learning on multiple GPUs and multiple machines. Here, we will focus on speeding up calculations in deep learning. Note that our deep learning implementation ends in Section 8.1, and we do not perform any acceleration (such as GPU support) as described here.

[[[00000000000000001950---d9c2699ee47423f591537856cd8869a0e547024d14aa3f5569f92cf928a85835]]]problem to be addressed

[[[00000000000000001951---2896164c5f68460a5d3ed00120182659782ab1ce5f9af4047abdc3787c49fc10]]]Before moving on to talking about speeding up deep learning, let's take a look at what kind of processing time is spent in deep learning. Figure 8-14 shows a pie chart of the time spent in each layer for AlexNet forward processing.

[[[00000000000000001952---57c400e4638d1655db62d43c95beda15c4acefc66e09daf7bc06f9440b7af971]]]
Figure 8-14 Time ratio of each layer in forward processing of AlexNet: when using GPU on the left and CPU on the right. In the figure, “conv” corresponds to the convolutional layer, “pool” to the pooling layer, “fc” to the fully connected layer, and “norm” to the normalization layer (cited from [26]).


[[[00000000000000001953---fbde1c89512f696fef04675ed53e1bcc94c196d0762572c382c918250c3f60b2]]]As you can see, AlexNet spends a lot of time in convolutional layers. In fact, the total processing time for the convolutional layers reaches 95% of the total time on the GPU and 89% of the total time on the CPU! Therefore, the issue in deep learning is how to perform the operations performed in the convolutional layer quickly and efficiently. Also, although the results in Figure 8-14 are for inference, a lot of time is spent in convolutional layers during training as well.

[[[00000000000000001954---f73db3bb0d5f8470b4deda59362a15930b9736bf8b3fc2a1139e175344c02255]]]As explained in '7.2 Convolutional Layers', the operations performed in the convolutional layer can be traced back to the 'product-accumulate operation'. Therefore, the subject of speeding up deep learning is how to calculate a large number of 'product-sum operations' quickly and efficiently.

[[[00000000000000001955---7d76c7c4b48fb3e1b20468fcb271194f79b79fbecfbb8f6ea57f24178676ebc2]]]GPU acceleration

[[[00000000000000001956---a1023dec0d051c2ad21ede640028b47663897552124c5fcf30d3a6e747ff27f0]]]GPUs were originally used as dedicated boards for graphics. Recently, however, GPUs are used not only for graphics processing, but also for general-purpose numerical calculations. Since GPUs can perform parallel numerical calculations at high speed, the aim of GPU computing is to utilize its overwhelming power for various purposes. Note that GPU computing is the general-purpose numerical computation performed by the GPU.

[[[00000000000000001957---4166a1f06994ab48713c85b096acf7aaf80c7feb4c7a1e059f1c952fae98d5da]]]Deep learning requires doing a lot of multiply-accumulate operations (or large matrix multiplications). Such massively parallel operations are what GPUs are good at (conversely, CPUs are good at sequential, complex calculations). Therefore, in deep learning operations, GPUs can be used to achieve amazing speedups compared to CPUs alone. Now let's look at an example of how much speedup can be achieved with a GPU. Figure 8-15 below shows the results of comparing the time required to train AlexNet on CPU and GPU.

[[[00000000000000001958---f6967e2a9e9ff907c50bfd2aa2ea6c68c355b840950fdb40ba8fe08f2e5edd72]]]
Figure 8-15 Results of comparing the time required for AlexNet training between the CPU '16-core Xeon CPU' and the GPU 'Titan series' (quoted from Reference [27])


[[[00000000000000001959---3b612161e1c17b1717e83ae0fecce20223c8fbdfd9a2e69a26b18f091fe62bae]]]As you can see from the figure, the time required by CPU can be shortened from 40 days or more to 6 days by GPU. again. The figure shows that further speedup can be achieved by using a library optimized for deep learning called cuDNN.

[[[00000000000000001960---4cdacf93e7bfff548c9e19402a3bc366e5bf99dba7ec4648af59453ee1d6f1de]]]By the way, GPUs are mainly provided by two companies, NVIDIA and AMD. Both GPUs can be used for general-purpose math, but NVIDIA's GPU is the 'friend' for deep learning. In fact, many deep learning frameworks can benefit from NVIDIA GPUs alone. This is because CUDA, an integrated development environment for GPU computing provided by NVIDIA, is used in the deep learning framework. cuDNN, which appears in Figure 8-15, is a library that runs on CUDA and implements functions optimized for deep learning.

[[[00000000000000001961---af674f16cd8820d0bb20f49310363dc7b0ce955398f876ca3eee790fe4307019]]]The operations in the convolutional layers could be converted into large matrix products by im2col. Implementation of this im2col method is a convenient implementation method for GPU. This is because GPUs are good at calculating large chunks at once, rather than calculating in small units. In other words, im2col makes it easy to bring out the full potential of the GPU by calculating it as a product of huge matrices.

[[[00000000000000001962---225593cc37724ee4a7c98b438968a020cb0ac9f94c78a81cffd141d28877a83f]]]distributed learning

[[[00000000000000001963---ab7cb90c7ae097e763718e126099df5d34d52a5507382693bf64d09e8f0229a7]]]GPUs can significantly speed up deep learning operations, but deep networks still require time on the order of days or weeks for training. And as we have seen, deep learning involves a lot of trial and error. In order to create a good network, it is necessary to try many different things, and this inevitably creates a desire to minimize the time required for a single learning session. That's why the idea of scaling out deep learning -- in other words, 'distributed learning' -- becomes important.

[[[00000000000000001964---4e5fe289569e2e1fe108b67c560076b369d8a9717e2da52b7692a765dbbe51bf]]]In order to further speed up the calculations required for deep learning, it is conceivable to distribute the calculations over multiple GPUs or multiple machines. Currently, several deep learning frameworks that support distributed learning by multiple GPUs and multiple machines are emerging. Among them, Google's TensorFlow and Microsoft's CNTK (Computational Network Toolkit) are being developed with an emphasis on distributed learning. Backed by low-latency, high-throughput networks of huge data centers, distributed learning with these frameworks has shown amazing results.

[[[00000000000000001965---8d44165e1b418c695ed0c717defe516745dda8aee804d509df8e31c85447da37]]]How much faster can we achieve with distributed learning? Figure 8-16 shows the effect of distributed learning with TensorFlow.

[[[00000000000000001966---18ef7e3ef6d0a2b41d28fc1cebc68b984a12b0d8771f607afb0b654da2e2b8ce]]]
Figure 8-16 Effect of distributed learning with TensorFlow: horizontal axis is the number of GPUs, vertical axis is the speedup rate compared to when there is only one GPU (quoted from Reference [28])


[[[00000000000000001967---bbfaed5428ae095984bf84e9f1c950ece2c272af80ab14860bdaf556fad2e6b5]]]As shown in Figure 8-16, we can see that the training speed increases as more GPUs are used. In fact, 100 GPUs (a total of 100 GPUs across multiple machines) appear to be 56x faster than a single GPU! This means that, for example, learning that took seven days can be completed in just three hours, demonstrating the amazing effects of distributed learning.

[[[00000000000000001968---b08e77e7ec78a362531576065fc1be5b23af21e3254b3b9427d0ebd381fab0ec]]]Regarding distributed learning, the theme of 'how to distribute computation' is a very difficult problem. There are many problems that cannot be solved easily, such as communication between machines and synchronization of data. Such hard problems are better left to a good framework like TensorFlow. I won't go into the details of distributed learning here. For the technical content of distributed learning, please refer to the TensorFlow technical paper (white paper) [29].

[[[00000000000000001969---805f6ced6e45a7158f8b86db246262322b1eeb9aa80d9656b78544abb65f7f1c]]]Arithmetic precision bit reduction

[[[00000000000000001970---212e4dfb7035ee96496e56e02dd5620678117089cc4232722fa2b0719bdab1af]]]In speeding up deep learning, in addition to computational complexity, memory capacity and bus bandwidth can become bottlenecks. In terms of memory capacity, we have to consider keeping a large amount of weight parameters and intermediate data in memory. Also, in terms of bus bandwidth, when the amount of data flowing through the GPU (or CPU) bus increases and exceeds a certain limit, it becomes a bottleneck. Assuming such a case, it is desirable to reduce the number of bits of data flowing through the network as much as possible.

[[[00000000000000001971---ff96b5bfd672e1ab3c106727c155a22218159efa255713e477b2bf289ad1ab71]]]Computers mainly use 64-bit and 32-bit floating point numbers to represent real numbers. Using more bits to represent numbers reduces the impact of errors in numerical calculations, but increases the processing cost and memory usage of calculations, and places a burden on the bus bandwidth.

[[[00000000000000001972---7691370d2f4ec49c1f1dd7d2f52fc2148af80c426debec435d98646379de82cc]]]Regarding numerical precision (how many bits of data are used to represent a number), what we know about deep learning is that deep learning does not require that many bits of numerical precision. This is one of the important properties of neural networks. This property is due to the robustness of neural networks. Robustness here means, for example, that a neural network has robust properties such that even if a small amount of noise is superimposed on the input image, the output result does not change. Thanks to such robustness, it can be considered that even if the data flowing through the network is 'degraded', it will have little impact on the output results.

[[[00000000000000001973---d8e4541495ae820ffe48895cdad7d8e9086fa418171ee4bd5aa84641beed2be6]]]There are formats such as 32-bit single-precision floating-point numbers and 64-bit double-precision floating-point numbers to represent decimal numbers on computers. It has been shown that even floating point numbers (half float) can be trained without problems [30]. In fact, NVIDIA's next-generation GPU Pascal architecture also supports half-precision floating-point arithmetic, so half-precision floating-point numbers are expected to be used as standard from now on.

[[[00000000000000001974---114ad387fde238fea68075110e49ac875eb2bfc0e37c96a18be00685563510cf]]]NVIDIA's Maxwell generation GPUs supported half-precision floating-point numbers as storage (a function to hold data), but the calculation itself was not performed at 16 bits. The next-generation Pascal architecture uses 16 bits, including arithmetic, so simply performing calculations with half-precision floating-point numbers can be expected to be roughly twice as fast as previous-generation GPUs.

[[[00000000000000001975---4756e1bd5f3b2673417c8b5cec4b67baf1cf46a0c5d729710cad7468e19a675f]]]Until now, deep learning implementations have not paid attention to numerical precision, but Python generally uses 64-bit floating point numbers. NumPy provides a 16-bit half-precision floating-point number type (but only a 16-bit type for storage, the operations themselves are not done in 16-bit). It is easy to show that using NumPy's half-precision floating point numbers does not reduce recognition accuracy. See ch08/half_float_network.py for those interested.

[[[00000000000000001976---b3e661e9d186fe5b36fe1a3b9d286a6566b33c2a9127dd64371eca84a4072b3d]]]Several studies have been conducted on the theme of reducing the number of bits in deep learning. Recently, a method called “Binarized Neural Networks”, which expresses weights and intermediate data with 1 bit, has been proposed [31]. The theme of reducing bits to speed up deep learning is an area that we must keep an eye on in the future, and it will become an important theme especially when using deep learning for embedded systems.

[[[00000000000000001977---29b959fbb10037d6d09efb886657bf03e994aaa54abb676f4bc56d39205be61d]]]Practical examples of deep learning

[[[00000000000000001978---dc8ccf443a89113f6a4da1da59b6aca645040be882d5a7daf3df22635e415086]]]As an example of using deep learning so far, we have focused on class classification of images such as recognition of handwritten digits, which is called 'object recognition'. However, deep learning can be applied to various problems other than object recognition. In addition, deep learning exhibits excellent performance for many problems, such as images, voice, and natural language, although the fields are different. Here, I would like to introduce some of the things (applications) that deep learning can do, mainly in the field of computer vision.

[[[00000000000000001979---8cc36a76a3bd97b331c1776e70777bd0b4e3434d21c06b2f5af0aa2f4175125a]]]object detection

[[[00000000000000001980---b6a7b8d6f35aa975d2887ef46960960fd929e6de5f15d9227ee57cc2e1f540bb]]]Object detection is a class classification problem that includes identifying the position of an object in an image. Identify the type of object and the position of the object in the image, as shown in Figure 8-17.

[[[00000000000000001981---b61173e0c622fed6f4990b9270ba1eb0c8c8a01a95c129bb92b76b0c9fa723ed]]]
Figure 8-17 Example of object detection (cited from Reference [34])


[[[00000000000000001982---4d7393f9a6c2e2e38f98d21ce3e667b59158870169a7af4993e4ccf839ebabde]]]As you can see in Figure 8-17, object detection is a more difficult problem than object recognition. The object recognition that we have seen so far targets the entire image, but in object detection, it is necessary to identify the position of the class from within the image. Moreover, there may be multiple objects.

[[[00000000000000001983---2f123cc7a91fc0becfe0cd417f0d0a418038a3594b88c1d03f3b191918e04e15]]]Several CNN-based methods have been proposed for such object detection problems. Those methods show very good performance, which shows that deep learning is effective even for object detection problems.

[[[00000000000000001984---8e31f16ba5b0734fd7766965e70541f0fc9362fe1cc67a5a9449567cec181318]]]There are several methods for object detection using CNN, and among them, the method called R-CNN [35] is famous. Figure 8-18 shows the processing flow of R-CNN.

[[[00000000000000001985---92161aa8ed18e2362ce5e2a8b2ff32ef8aa358b1bf8edcfd8f8be39ee3a3c430]]]
Figure 8-18 R-CNN processing flow (cited from Reference [35])


[[[00000000000000001986---f6fea3c4b212bc3797acf30a0f6e9b418d7d3133b11fbd2918ad9ad442ec6f79]]]What we would like you to pay attention to in Figure 8-18 are the processing parts of '2. Extract region proposals' and '3. Compute CNN features' in the figure. It first finds object-like regions (somehow) and then applies CNN to the extracted regions to classify them. In R-CNN, the actual processing flow is somewhat complicated, such as transforming the image into a square and using SVM (support vector machine) for classification, but from a broader perspective, the above two processes—candidates It consists of region extraction and CNN——.

[[[00000000000000001987---ea8b4dcf5bc9a85655f8965824ea4d1d63258322c692ce0aba0003715de27b15]]]The first half of R-CNN processing, 'candidate region extraction (processing to find objects that look like objects),' can use various methods cultivated in computer vision. The R-CNN paper uses a technique called Selective Search. Recently, a method called “Faster R-CNN” [36] has been proposed, in which even this candidate region extraction is performed by CNN. Faster R-CNN performs all processing with one CNN, so high-speed processing is possible.

[[[00000000000000001988---2854e80f7f4f9045a3248248e1ee27617fe2a10c0039c76e39e6e212a68f8891]]]segmentation

[[[00000000000000001989---7fa7a591b315718346538e1daafff633677341dd930a024ebe1da92edd0971c5]]]Segmentation is the problem of classifying images at the pixel level. Training is performed using teacher data colored by object on a pixel-by-pixel basis, as shown in Figure 8-19. Then, during inference, class classification is performed for all pixels of the input image.

[[[00000000000000001990---f3a7644e8e0fecc42c23fe17181b239b3425b5b145b66c4eef978310d6df5abf]]]
Figure 8-19 Example of segmentation (cited from Reference [34]): Input image on the left, labeling image for the teacher on the right


[[[00000000000000001991---24a3140b113da189209615eed324407a2b24afc0ca1d18e18ed949dfcd14b34e]]]By the way, the neural network we have implemented so far has performed class classification for the entire image. How can we get this down to the pixel level?

[[[00000000000000001992---e0c0724c3ab83628b001d81b1c4b25686180635bb3b876f9963e946fc4d3b6c1]]]With a neural network, the simplest way to do segmentation would be to go through all the pixels and make an inference on each pixel. For example, you might have a network that classifies the pixel in the center of a rectangular region, and then perform inference on all pixels. As you can imagine, such a method requires forward processing for as many pixels as there are pixels, which takes a lot of time (more accurately, it is a waste of time to recalculate many regions in the convolution operation). The problem is that the A method called FCN (Fully Convolutional Network) [37] has been proposed as a method to improve such computational waste. It classifies all pixels in one forward process (see Figure 8-20).

[[[00000000000000001993---34837b21e2f1e241aeabce5df3bc010746d41960c78511466ccd034bb00138db]]]
Figure 8-20 Overall view of FCN (cited from Reference [37])


[[[00000000000000001994---0612c56eaaf55248b1577fd6f702085c6ebc8fed158572d2ac3c35a525a8c063]]]A literal translation of FCN's Fully Convolutional Network means 'a network that consists entirely of convolutional layers.' This is because a general CNN contains a fully connected layer, whereas in an FCN, the fully connected layer is replaced with a 'convolutional layer that does the same thing'. In the fully connected layer of the network used for object recognition, the spatial volume of the intermediate data was processed as a row of nodes, but in the network composed only of convolutional layers, the spatial volume is preserved and the final data is processed. can be processed up to the output of

[[[00000000000000001995---60769982431384af307a438371b6b7412882a4d45d656d7c756db144f08659a7]]]Also, as a feature of FCN, as shown in Figure 8-20, it introduces processing to expand the spatial size at the end. Through this enlargement process, the reduced intermediate data can be enlarged at once to the same size as the input image. The enlargement processing performed at the end of FCN is enlargement by bilinear interpolation (bilinear enlargement). In FCN, this bilinear expansion is achieved by deconvolution (see the FCN paper [37] for details).

[[[00000000000000001996---d812d9c783949e06ae85c5f5d5839bafdb0e0a779fc35143049c8c6fc072906e]]]A fully connected layer connects the output to all the inputs. This exact same configuration of connections can also be achieved with convolutional layers. For example, a fully connected layer for data with input size 32×10×10 (32 channels, height 10, width 10) can be replaced with a convolutional layer with filter size 32×10×10. If the number of output nodes in the fully connected layer is 100, the same processing can be achieved in the convolutional layer by preparing 100 filters of 32×10×10. Thus, a fully connected layer can be replaced with a convolutional layer that does the same thing.

[[[00000000000000001997---a71dd5c8c56d26521b2da1ad1dcdcc9bbbc975468f9f7189e8c385539fa858bb]]]image caption generation

[[[00000000000000001998---5b63d2f8738f572bb07341cf019e2b94a0a0d83654276b1cbd396bf674029613]]]There is an interesting research that fuses computer vision and natural language. As shown in Fig. 8-21, this research automatically generates sentences (image captions) that describe the image given an image.

[[[00000000000000001999---ec9b2265d83bef4204e0ebc8d64b083db66855ea8423e143221c2b1bd147b225]]]
Figure 8-21 Example of image caption generation by deep learning (cited from Reference [38])


[[[00000000000000002000---13f626b16cd7f354c2fd322e5551153c0fe66c22eaa552dc09f8278adac78c3b]]]Given an image, text representing the content of the image is automatically generated as shown in Figure 8-21. For example, the top left image is the sentence 'A person riding a motorcycle on a dirt road.' (This sentence is automatically generated from the image alone). Indeed, the text content and the image match. What's more, it's surprising that they 'understand' not only that they are riding motorcycles, but also that the roads are unpaved and rough.

[[[00000000000000002001---b5f70eb40295832dd8b7d2fd4ddc161099853ae6eaf8a3e84b8781e3ffbd6ae0]]]A typical method for generating image captions using deep learning is a model called NIC (Neural Image Caption). As shown in Figure 8-22, NIC consists of deep CNN and RNN (Recurrent Neural Network) for handling natural language. RNN is a network with recursive connections and is often used for continuous data such as natural language and time series data.

[[[00000000000000002002---44cb966a3746a93c7964c77f327313108c8dab30339eeff6a9189daf5a369826]]]
Figure 8-22 Overall configuration of Neural Image Caption (NIC) (quoted from Reference [38])


[[[00000000000000002003---2884eb4406a86174a4fa6b81a15e426015f4d0090a2feb98eede74f742fc7856]]]NIC extracts features from images by CNN and passes the features to RNN. The RNN 'recursively' generates text using the features extracted by the CNN as initial values. I won't go into any more technical details here, but basically the NIC is a simple combination of two neural networks -- a CNN and an RNN. The result is amazingly accurate image caption generation. Processing by combining multiple types of information, such as images and natural language, is called multimodal processing. Multimodal processing is an area that has received a lot of attention in recent years.

[[[00000000000000002004---0874c94ddfafd7a8471ca915ce4579b127c8cc4be98dddd804608a559c7a963f]]]The R in RNN stands for Recurrent. This recursion refers to the recursive network structure of neural networks. Due to this recursive structure, RNNs are characterized by being influenced by previously generated information—in other words, remembering past information. For example, after generating the word 'I', the word to be generated next is influenced by the word 'I' and generates the word 'wa'. Then, influenced by the words 'I am' generated so far, the next word 'sleep' is generated, and so on. For continuous data such as natural language and time series data, RNN works to remember past information.

[[[00000000000000002005---b49ddbb6e4a2f1979e0284b223c612c051d74974bd97d14eb0ed6b292f13d78e]]]The future of deep learning

[[[00000000000000002006---2c097d61352ca66dc51a5571ce91e1e6273f5d36a58e70424f2a7710ad106189]]]Deep learning has come to be used not only in conventional fields but also in various fields. Here, I would like to introduce some research that gives us a sense of the possibilities of deep learning and its future.

[[[00000000000000002007---58ce0d9f3a69c20787e4a99aeb2fa0077386405278317e8109c3c62c1e911486]]]image style conversion

[[[00000000000000002008---bf0a40629f3d5c743495636aa9a6d98230afc13789f96f3f95b66b287715870d]]]There is research that uses deep learning to “paint” pictures like an artist. The example shown in Figure 8-23 below is a study that inputs two images and generates a new image. One of the two images is called the 'content image' and the other is the 'style image'.

[[[00000000000000002009---6c0c034c07051f0dec568cef14f22ed52d45c006ee2f501d8b3a8e2ee2e969aa]]]
Figure 8-23 Example of image style conversion based on the paper 'A Neural Algorithm of Artistic Style': Upper left is 'style image', upper right is 'content image', lower image is newly generated image ] quoted)


[[[00000000000000002010---cfcf4f74adbdce474e697bcc5d6a7d424d7aeb38c2d48a2eca7d11a75932518f]]]As shown in Figure 8-23, you can specify the Van Gogh drawing style to apply to the content image, and deep learning will draw a new painting exactly as specified. This is the research of the paper 'A Neural Algorithm of Artistic Style' [39], which attracted a lot of attention around the world as soon as it was published.

[[[00000000000000002011---272faad939d43951edce5a4d60395c4f8448668cb12d8ecc03d9f67c2a8aed82]]]A detailed description of this study is not provided here. If we only describe the outline of the technology, the above method learns so that the intermediate data of the network approaches the intermediate data of the 'content image'. By doing so, we can make the input image resemble the shape of the content image. We also introduce the concept of style matrices to absorb styles from 'style images'. By learning to reduce the deviation of the style matrix, it is possible to bring the input image closer to Van Gogh's style.

[[[00000000000000002012---f3e8f313576275272e515921dc3fdfb5454492c662017e01575a1b370a2e84bb]]]image generation

[[[00000000000000002013---f40ee9e53ac957bb8b5b4f127959898af3cfe9df2444210dad4fe6623b0a1e40]]]The image style conversion example above took two images as input when generating a new image. On the other hand, apart from such research, there is also research that draws a new image without needing any images when generating a new image (learning is performed using a large number of images first). but you don't need any images to 'draw' a new image.) For example, deep learning can generate an image of a “bedroom” from scratch. The image shown in Fig. 8-24 is an example of a bedroom image generated by a method called DCGAN (Deep Convolutional Generative Adversarial Network) [41].

[[[00000000000000002014---c8550fe5c54a1c2943a4144ca419bd70fc37ea4e8a7d246e060aec43f884ff8a]]]
Figure 8-24 Bedroom image newly generated by DCGAN (quoted from Reference [41])


[[[00000000000000002015---94bf148af940da96550489185e9fd936e2886725f8e80a77bc6e09cb101aa28f]]]The images in Figure 8-24 may look like real photographs, but these images are newly generated images by DCGAN. In other words, the images drawn by DCGAN are images that no one has seen yet (images that do not exist in the training data), and are newly generated images from scratch.

[[[00000000000000002016---a0d3d9c45ccfd70c4085922e320e04eb63c0df44eae411c4123e9c6c2b4e9697]]]Now, DCGAN, which draws images with quality that can be mistaken for the real thing, DCGAN models the process of image generation. Train the model with a large number of images (for example, a large number of images of a bedroom). Once trained, the model can then be used to generate new images.

[[[00000000000000002017---37a498c3fbd9531f7486b3f598faf443bb3bed6a6ca85cce20763b25098a14c8]]]Deep learning is used in DCGAN. The main point of DCGAN technology is that it utilizes two neural networks called Generator and Discriminator. The Generator creates a lifelike image, and the Discriminator decides whether it's real - whether it's generated by the Generator or actually captured. In this way, by making them compete and learn, the Generator learns more elaborate techniques for deceiving images, and the Discriminator grows like an appraiser who can discern with higher accuracy. I will continue. The interesting thing about the technology called GAN (Generative Adversarial Network) is that both parties grow through friendly rivalry. A Generator that has grown through such friendly rivalry will eventually acquire the ability to draw images that can be mistaken for the real thing (or may grow in such a way).

[[[00000000000000002018---440a4db0b010b350922a25671e528b82a5547809e38638b75f66ee7aa68b8979]]]The machine learning problem we've seen so far has been a type of problem called supervised learning. Like handwritten digit recognition, it uses a dataset in which image data and teacher labels are paired. However, the problem addressed here is given no training data, just a large number of images (collections of images). This is a problem called unsupervised learning. Unsupervised learning is a field that has been researched for a relatively long time (Deep Belief Network, Deep Boltzmann Machine, etc. are famous), but I get the impression that there is not much research being done in recent years. In the future, as methods such as DCGAN using deep learning gain more attention, we may be able to expect further development of unsupervised learning.

[[[00000000000000002019---2d95dc9ebba14357945533870cf1e4a072e3c9936a7d5ea8d85c8a189bc3d1b7]]]self-driving

[[[00000000000000002020---337cc56ef630b1c2f5ef888ed2c797b96dd9c255125e1492e8ad952854514631]]]Autonomous driving technology, in which computers drive cars instead of humans, has become a reality. Not only automakers, but also IT companies, universities, and research institutes are competing to make autonomous driving a reality. Autonomous driving can only be realized by combining the strengths of various technologies, such as path plan technology that determines traffic routes and sensing technology such as cameras and lasers. It is said that the technology to correctly recognize is an important issue. This is because it is a very difficult problem to correctly recognize the ever-changing environment and the endless traffic of cars and people.

[[[00000000000000002021---3a68ba30a23c75dba5072586ad57a08dfab82581c6cdcafd55c023df71105451]]]If it becomes possible to correctly recognize the driving area robustly in various environments, the realization of autonomous driving may not be far away. And recently, the power of deep learning is expected to be used in technology that recognizes the surrounding environment. For example, a CNN-based network called SegNet [42] can recognize the track environment with high accuracy, as shown in Figure 8-25.

[[[00000000000000002022---efcf095589b91099b797eb827f119bdccf802231b31541b3f4c3333452bce746]]]
Figure 8-25 Example of image segmentation by deep learning: Roads, cars, buildings, sidewalks, etc. are recognized with high accuracy (quoted from Reference [43])


[[[00000000000000002023---3f712416c1fcf31413631060529ff40e7172b135a9f9ba5da749ef6408bd0cf7]]]As shown in Figure 8-25, segmentation (pixel-level determination) is performed on the input image. Looking at the results, it can be seen that roads, buildings, sidewalks, trees, cars, motorcycles, etc. can be distinguished to some extent accurately. If such recognition technology is further improved in precision and speed through deep learning, the practical application of autonomous driving may not be far away.

[[[00000000000000002024---bda0dbf7d7e985f34d13e3ace90e183c72ee279193dfb4b5d81baf167b3ec00b]]]Deep Q-Network (reinforcement learning)

[[[00000000000000002025---ff2766c6c3698c5fec3cf9fb32cb01b3f7988602e71b8eafe527f996e6843e46]]]Just as humans learn through trial and error—for example, how to ride a bicycle—there are fields in which computers can learn autonomously through the process of trial and error. This is a field different from “supervised learning,” where a “teacher” teaches alongside, and is called reinforcement learning.

[[[00000000000000002026---eaf3821fc529e327b2dd280c46f16a77b8cee3120d3a6447caff4dba72b1ca53]]]In reinforcement learning, the basic framework is that something called an agent selects an action according to the situation of the environment, and the environment changes according to the action. A change in the environment rewards the agent in some way. The purpose of reinforcement learning is to determine the agent's course of action so that better rewards can be obtained (Figure 8-26).

[[[00000000000000002027---ca22813b2dcecbcf926feb7a11481b15ebb69acd3909685a50040172300f7269]]]
Figure 8-26 Basic Framework of Reinforcement Learning: Agents Autonomously Learn for Better Rewards


[[[00000000000000002028---66964d5e3926469f62d028fa4ee30c20c7265ff1a6d5f63ac56e8c77902a47fe]]]The schematic diagram shown in Figure 8-26 is the basic framework of reinforcement learning, but the point to note here is that the reward is not a fixed reward, but a 'probable reward'. For example, if you consider the video game Super Mario Bros., it is not always clear how much reward you get by moving Mario to the right. In that case, it is necessary to determine the 'probable reward' by working backwards from clear indicators such as game scores (collected coins, defeated enemies, etc.) and game overs. If this is supervised learning, each action can be correctly evaluated by the “teacher”.

[[[00000000000000002029---a74a840b89dfd8cb8c01980b9905aca4e5a35a1b6f85cac0cd66213f71c8a8c2]]]As a method of reinforcement learning using deep learning, there is a method called Deep Q-Network (commonly known as DQN) [44]. It is based on a reinforcement learning algorithm called Q-learning. I will omit the details of Q-learning, but Q-learning determines a function called the optimal action value function in order to determine the optimal action. DQN uses deep learning (CNN) to approximate the function.

[[[00000000000000002030---4f948883d7512ff7920ff123f48217e2cd1579bbbf61af0de61e2173618def9d]]]DQN research has reported examples of automatically learning video games and achieving a level of operation that surpasses that of humans. As shown in Figure 8-27, the CNN used in DQN takes game image frames (four consecutive frames) as input, and finally outputs the movement of the game controller (joystick movement amount, presence or absence of button operation). ), output the “value” of that action.

[[[00000000000000002031---a7fc326fb3d2f0ec1e74992017ec8a05ef77d4fc58be57d1fa9fbdab10febec4]]]
Fig. 8-27 Learning video game operations by Deep Q-Network. The input is an image of a video game, and through trial and error, it learns the handling of a game controller (joystick) that puts a professional to shame (cited from Reference [44]).


[[[00000000000000002032---90ed45b74e50c7175aefa8fcfd0357c2df77f09a947639d294594d6085aa870a]]]Until now, when learning video games, etc., it was common to extract the game state (character locations, etc.) in advance. However, in DQN, the input data is only video game images, as shown in Figure 8-27. This is a notable point of DQN, and it can be said that it greatly enhances the applicability of DQN. This is because you don't need to change the settings for each game, you just give DQN the image of the game. In fact, DQN was able to learn many games such as 'Pac-Man' and 'Atari' with the same configuration, and in many games it was able to beat people.

[[[00000000000000002033---81325a70cddbbd1748d3b010910b47152d4b9312275ad58c840f77bc97cb5356]]]The news that AlphaGo [45], an artificial intelligence, has beaten the Go champion has attracted a lot of attention. Deep learning and reinforcement learning are also used inside this technology called AlphaGo. In AlphaGo, it seems that 30 million professional game records were given to it to learn, and AlphaGo itself played against itself over and over again to accumulate learning. Both AlphaGo and DQN are research done by Google's Deep Mind. We will keep an eye on Deep Mind's activities in the future.

[[[00000000000000002034---7f7ad40ba94a2507fb7fe55ea8aff92c6ece28879685607e5eb7cc261a4ecd72]]]summary

[[[00000000000000002035---b8f7cf231dc602b17faf22dbfc41babe032d3031e7e0a4213f8af60317da98ed]]]In this chapter, we implemented a (slightly) deep CNN and obtained highly accurate recognition results exceeding 99% in handwritten digit recognition. He also talked about his motivation for making the network deep, and explained that recent deep learning is heading in the deep direction. He also introduced trends in deep learning, examples of practical applications, research on speeding up, and examples of research that gives a sense of the future.

[[[00000000000000002036---c4a43af7030b7ffa93774afb040f1ab5c93d23ca99cd6e1695b6044be7f7ffb8]]]In the field of deep learning, there are still many things we do not understand, and new research is being published one after another. Researchers and engineers around the world will continue to actively research, and technology that is currently unimaginable will be realized.

[[[00000000000000002037---44bdd8a0d57ca113e48653d3a6bf65e1736aa844343b5a651506e59d9da85394]]]Until the end Thank you for reading. As an author, I would be more than happy if the readers deepened their understanding of deep learning through this book and realized how interesting deep learning is.

[[[00000000000000002038---19850c73ec605a12530fa271fcc972171b998181be314b2c4c58825fcf2e154b]]]What we learned in this chapter

[[[00000000000000002039---bffcc0556fa1ab109cfd5119a472c5e5d618b99d79668606c91119f2859e17cc]]]For many problems, deepening the network can be expected to improve performance.

[[[00000000000000002040---091fd613c3db2ebf0168db613718c20dd83751c4c8db8fe74b84fb6a20966710]]]The recent trends in the image recognition competition called ILSVRC are that deep learning methods dominate the top ranks, and the networks used are also deepening.

[[[00000000000000002041---0fd79095409543d6bbffb43b8230ebfc719fdb8ee3ee1f626368253ea2b4858f]]]Famous networks include VGG, GoogLeNet and ResNet.

[[[00000000000000002042---818c7169c3a589a5cbc9efa20eeca77af6db0637dc97396890b6fe4d8b031e1a]]]Deep learning can be accelerated by GPU, distributed learning, and reduction of bit precision.

[[[00000000000000002043---7913e7292186775ee77282c47cc60d9e6c3f6b8a1993f0e23373402190e35cdd]]]Deep learning (neural network) can be used not only for object recognition, but also for object detection and segmentation.

[[[00000000000000002044---52c78e3f080c049c219f7a3bbf16d5ad30f764a05ba90cac3581515fdf0ecfd5]]]Applications using deep learning include image caption generation, image generation, and reinforcement learning. Recently, the use of deep learning for autonomous driving is also expected.